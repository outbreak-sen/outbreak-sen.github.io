<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>论文阅读_MoVieS | This is a 部落格 of outbreak_sen</title><meta name="author" content="outbreak_sen"><meta name="copyright" content="outbreak_sen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="基本信息    项目 内容     论文标题 MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second一秒钟内实现运动感知 4D 动态视图合成   作者 Chenguo Lin1∗, Yuchen Lin1,3∗, Panwang Pan2†,Yifan Yu2, Honglei Yan2, Katerina Fragkiadaki3">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读_MoVieS">
<meta property="og:url" content="http://outbreak-sen.github.io/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoVieS/index.html">
<meta property="og:site_name" content="This is a 部落格 of outbreak_sen">
<meta property="og:description" content="基本信息    项目 内容     论文标题 MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second一秒钟内实现运动感知 4D 动态视图合成   作者 Chenguo Lin1∗, Yuchen Lin1,3∗, Panwang Pan2†,Yifan Yu2, Honglei Yan2, Katerina Fragkiadaki3">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://outbreak-sen.github.io/img/head.png">
<meta property="article:published_time" content="2025-12-03T05:57:16.000Z">
<meta property="article:modified_time" content="2025-12-03T06:11:20.415Z">
<meta property="article:author" content="outbreak_sen">
<meta property="article:tag" content="Muilt View Stereo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://outbreak-sen.github.io/img/head.png"><link rel="shortcut icon" href="/img/h_beautygirl.png"><link rel="canonical" href="http://outbreak-sen.github.io/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoVieS/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文阅读_MoVieS',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="This is a 部落格 of outbreak_sen" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg" style="background-image: url(/img/v_beautygirl0.jpeg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/head.png" onerror="onerror=null;src='./img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">148</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-camera-retro"></i><span> 树洞</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 作品与鉴赏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/h_beautygirl.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/h_beautygirl.png" alt="Logo"><span class="site-name">This is a 部落格 of outbreak_sen</span></a><a class="nav-page-title" href="/"><span class="site-name">论文阅读_MoVieS</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-camera-retro"></i><span> 树洞</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 作品与鉴赏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">论文阅读_MoVieS</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-03T05:57:16.000Z" title="发表于 2025-12-03 13:57:16">2025-12-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-12-03T06:11:20.415Z" title="更新于 2025-12-03 14:11:20">2025-12-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="基本信息">基本信息</h2>
<table>
<thead>
<tr>
<th style="text-align:left">项目</th>
<th style="text-align:left">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>论文标题</strong></td>
<td style="text-align:left">MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second<br>一秒钟内实现运动感知 4D 动态视图合成</td>
</tr>
<tr>
<td style="text-align:left"><strong>作者</strong></td>
<td style="text-align:left">Chenguo Lin1∗, Yuchen Lin1,3∗, Panwang Pan2†,<br>Yifan Yu2, Honglei Yan2, Katerina Fragkiadaki3, Yadong Mu<br><br>∗：平等贡献;†：项目负责人;‡：通讯作者。</td>
</tr>
<tr>
<td style="text-align:left"><strong>作者单位</strong></td>
<td style="text-align:left">北京大学、字节跳动、卡内基梅隆大学</td>
</tr>
<tr>
<td style="text-align:left"><strong>时间</strong></td>
<td style="text-align:left">20250714axiv</td>
</tr>
<tr>
<td style="text-align:left"><strong>发表会议/期刊</strong></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<h2 id="方法概览">方法概览</h2>
<table>
<thead>
<tr>
<th>特点</th>
<th>文章性质</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>输入</strong></td>
<td>单目视频</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td>4D 动态新颖视图：</td>
</tr>
<tr>
<td><strong>所属领域</strong></td>
<td>新视角生成</td>
</tr>
<tr>
<td><strong>一句话总结做了什么</strong></td>
<td>设计了前馈模型可在一秒钟内从单目视频中合成动态高斯然后合成4D 动态新颖视图，首次允许对外观、几何形状和运动进行统一建模</td>
</tr>
</tbody>
</table>
<h3 id="摘要">摘要</h3>
<h3 id="引言">引言</h3>
<h3 id="创新点">创新点</h3>
<ol>
<li><strong>在VGGT基础上</strong>，MoVieS，这是第一个前馈框架，它联合对外观、几何形状和运动进行建模，以从单目视频中感知 4D 场景。</li>
<li><strong>提出动态飞溅像素将动态三维场景表示为可渲染的变形三维粒子，桥接新颖的视图合成和动态几何重建：</strong> 每个输入像素都映射到一个 3D 高斯图元，其 3D 位置由预测深度决定。为了对动力学进行建模，MoVieS 将每个像素的运动位移回归到任意查询时间戳，从而能够对每个飞溅像素进行时间跟踪。这种设计有助于跨摄像机视点和时间帧对 3D 几何体和外观进行连贯重建。</li>
<li><strong>MoVieS 为 4D 重建提供了强大的性能和数量级的加速，并且自然地以零样本方式实现了广泛的应用：</strong> 在各种 4D 感知任务中都取得了有竞争力的性能，同时比现有技术水平快了几个数量级。此外，通过作为代理任务的新颖视图综合，MoVieS 能够通过稀疏跟踪监督实现密集运动理解。这自然会产生各种零样本应用，进一步拓宽我们方法的潜力。</li>
</ol>
<h3 id="相关工作">相关工作</h3>
<ol>
<li>Feed-forward 3D Reconstruction
<ol>
<li>DUSt3R率先将规范空间中的像素对齐点图从图像对直接回归。随后的工作通过结合特征匹配[49]、支持多视图输入[50、51、52、53]、适应流视频[54、55]或与 3DGS 桥接视图合成[56、57、52、53]来改进该框架</li>
<li>VGGT通过使用更强大的图像编码器和多个特定于任务的头来预测从少至一个到数百个视图的所有关键 3D 属性。</li>
</ol>
</li>
<li>Dynamic Geometry Reconstruction动态几何重建
<ol>
<li><strong>一种方式是工程性的</strong>：以即插即用的方式将 DUSt3R 框架扩展到动态设置[58]，或者通过结合单眼深度[4,61]、光流[62]或二维点跟踪[19]来利用基础模型。</li>
<li><strong>另一种方法是做动态点图</strong>：动态点图[63]是一项并行工作，通过预测每个视点在另一个时间戳处的点图，提出了一种时不变的 DUSt3R 变体。
<ol>
<li>DynaDUSt3R为模型动态几何体增加了像素级运动监督。然而<strong>仅限于两帧输入，并且仅生成点云，而没有高质量的视觉重建。</strong></li>
<li><strong>CUT3R超越两个视图使用递归模型从静态和动态场景的流视频中增量更新场景表示。</strong></li>
<li>其他方法将动态重建视为条件视频生成，微调扩散模型以概率估计点图。但是，这些要求每个视频多个网络通行证。</li>
</ol>
</li>
</ol>
</li>
<li>Dynamic Novel View Synthesis
<ol>
<li>早期的尝试利用神经辐射场NERF来表示动态场景，无论是来自多视图视频还是单目视频。</li>
<li>3DGS作为一种更高效的可渲染表示，已应用于<strong>使用具有时间维度或附加可变形场的 4D 基元进行动态视图合成。</strong> 利用场景运动的低维性质表达了运动，并学习了单目帧的高斯轨迹。<strong>然而这些方法是从头开始训练的，需要迭代优化才能适应场景。现成的点跟踪或光流模型对于提供监督信号也是必不可少的。</strong></li>
<li>与我们最相关的工作是 <strong>BTimer和 NutWorld，它们都利用前馈方法从单目视频中估计 3DGS 属性。</strong> 然而，BTimer 在不对帧关系进行建模的情况下预测每个时间戳的独立高斯块，并且需要一个增强器模块来实现平滑的中间帧。NutWorld 对高斯运动进行建模，但缺乏明确的监督，严重依赖预训练的深度和流动，并使用正交相机，这可能会进一步导致投影失真。</li>
</ol>
</li>
</ol>
<h3 id="方法">方法</h3>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="IMG-20250914210337717.png" alt="">总体：一个大规模的预训练 Transformer 主干之上独立编码每个视频帧，并通过注意力聚合其信息，可<strong>同时预测外观、几何形状和运动。（1）深度头估计每个输入帧的深度，（2）飞溅头预测每像素 3D 高斯外观属性，例如颜色和不透明度，用于新颖的视图渲染，（3） 运动头估计高斯图元朝向目标时间戳的时间条件运动，使我们能够跟踪其时间演变。</strong></p>
<h4 id="3-1-dynamic-splatter-pixel">3.1 Dynamic Splatter Pixel</h4>
<p>将动态场景分解为一组静态高斯基元及其相应的变形场。</p>
<ol>
<li>一个视频输入，第i帧的每个像素和一个Splatter Pixel g对应，这样一个g也是在第1帧的坐标系下表示的，这样一个g有{x,a}两个属性，x是规范空间canonical space的位置，a是一个11维度的特征，有4维旋转四元数q，3维尺度s，1维不透明度α，3维颜色。但是这是静态的</li>
<li>额外的时间相关的场（time-dependent deformation field）来表征运动，一个g有一个对应的场属性m(t)，m(t)={Δx(t),Δa(t)}，Δx(t)是t时刻规范空间canonical space的运动向量是一个变速运动，Δa(t)是t时刻a的变化。<strong>那也就是说每个时刻t的x和a都是0时刻加一个直接的增量而不是t-1时刻的增量？没错</strong></li>
<li>这不就是说在t时刻，一个高斯的性质是x ← x + ∆x(t), a ← a + ∆a(t)</li>
<li><strong>在实践中发现仅使缩放和旋转属性与时间相关，即 ∆a（t）是一个7维的，不需要不透明度颜色的变化，足以表示动态飞溅像素。这就效果足够了</strong><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_SpatialTrackerV2/IMG-20250914221809366.png" alt=""></li>
</ol>
<h4 id="3-2-movies-unify-appearance-geometry-and-motion">3.2 MoVieS: Unify Appearance, Geometry and Motion</h4>
<h5 id="3-2-1-feature-backbone">3.2.1 Feature Backbone</h5>
<ol>
<li>输入一个视频，视频是一个t个时刻，视角P，相机内参K，一共N帧I的输入</li>
<li>每一帧I通过预训练的Encoder获得特征</li>
<li>相机参数通过两种方法嵌入
<ol>
<li>Plücker embedding: 相机位姿P和相机内参K通过空间加法对图像特征进行下采样并与图像特征融合，提供了相机几何形状的密集且空间对齐的编码</li>
<li>Camera token：相机位姿P和相机内参K都经过线性层生成一个相机令牌，附加到图像令牌的序列中。通过注意力与图像令牌进行全局交互，从而实现更全面的特征推理。</li>
<li>消融实验的结果：</li>
</ol>
</li>
<li>使用正弦位置编码对每个时间 t∈ [0， 1]进行编码，以生成一个时间标记，然后将其与上述图像和相机标记连接起来。</li>
<li>使用 VGGT的几何预训练注意力块来实现跨视频帧的图像标记之间的交互</li>
</ol>
<h5 id="3-2-2-prediction-heads">3.2.2 Prediction Heads</h5>
<p>token输入三个并行的DPT head，分别估计<strong>深度，高斯特征，变化场</strong>，这里讲了其他名字外观，几何形状和运动。</p>
<ol>
<li>. Depth and Splatter Head：深度头是通过VGGT的深度图进一步微调，高斯特征头是从零训练的</li>
<li>Motion Head：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_SpatialTrackerV2/IMG-20250914221809423.png" alt="">
<ol>
<li>通过在应用DPT卷积之前，通过自适应层归一化将正弦编码的查询时间t注入图像token，从而实现时间变化。<strong>什么意思</strong></li>
<li>对于N个输入帧和M个查询时间戳<strong>什么意思</strong>，这生成了形状为M × N × 3 × H × W的运动图。</li>
</ol>
</li>
</ol>
<h5 id="训练">训练</h5>
<p>如何训练和推理：MoVieS 可以<strong>在具有静态和动场景的大规模数据集以及点跟踪数据集上</strong>进行训练。在推理时，MoVieS 拍摄<strong>单目视频</strong>，无论是描绘静态还是动态场景，并重建每像素 3D 高斯基元及其在任何目标时间戳处的运动属性，从而在单个模型中实现新颖的视图合成、深度估计和 3D 点跟踪。</p>
<h5 id="损失函数：">损失函数：</h5>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_SpatialTrackerV2/IMG-20250914221809468.png" alt=""></p>
<ol>
<li>Depth and Rendering Losses ：深度损失计算为预测深度图和真实深度图之间的均方误差 （MSE） 及其空间梯度。深度损失计算为预测3dgs图和真实rgb图之间的像素 （MSE）和perceptual loss<strong>这个感知损失是什么？</strong>。</li>
<li>Motion Loss： 在3D 点跟踪数据集，真实的 ∆x 定义为任意两帧之间每个跟踪点的 3D 位移。由于所有 3D 点都是在世界坐标中定义的，并且大多数跟踪点保持静态，这意味着它们相应的运动矢量趋于零。我们在预测运动和真实运动之间应用逐点 L1 损失，以在过滤掉输入帧中不可见的点后提高稀疏性。此外，为了补充直接的点对点对齐，引入了分布损耗，鼓励预测的运动矢量在每帧内保留内部相对距离结构。最终运动损耗定义为逐点和分布级监督的组合，就是下面这个公式。</li>
<li>Normalization ：与 VGGT类似，通过从每个 3D 点到规范世界坐标系原点的平均欧几里得距离来归一化 3D 场景比例。因此与其他一些重建方法不同，我们不对深度或运动损失进行额外的归一化。为了简单起见，我们还省略了置信度感知权重。</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://outbreak-sen.github.io">outbreak_sen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://outbreak-sen.github.io/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoVieS/">http://outbreak-sen.github.io/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoVieS/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://outbreak-sen.github.io" target="_blank">This is a 部落格 of outbreak_sen</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Muilt-View-Stereo/">Muilt View Stereo</a></div><div class="post-share"><div class="social-share" data-image="/./img/head.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoSca/" title="论文阅读_MoSca"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">论文阅读_MoSca</div></div><div class="info-2"><div class="info-item-1">基本信息    项目 内容     论文标题 MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds   作者 Jiahui Lei1 Yĳia Weng2 Adam W. Harley2 Leonidas Guibas2 Kostas Daniilidis1,3   作者单位 宾夕法尼亚大学 斯坦福大学      Archimedes, Athena RC   时间 20241129axiv   发表会议/期刊     方法概览    特点 文章性质     输入 无位姿单目视频   输出 可渲染的动态场景，表示为一组动态高斯分布，并在相机参数未知的情况下恢复其焦距和位姿。   所属领域 4D重建   一句话总结做了什么 MoSca 从任意单目视频中重建可渲染的动态场景。核心思想是将2D视频输入提升为一种新颖的4D动态场景表示形式命名为运动骨架（Motion Scaffolds,...</div></div></div></a><a class="pagination-related" href="/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_Probe3D/" title="论文阅读_Probe3D"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">论文阅读_Probe3D</div></div><div class="info-2"><div class="info-item-1">Probe3D 探究2D的大模型能不能利用在3D的任务中，用于depth，normal，match任务 比较模型 DeIT MAE DINO CLIP SAM StableDiffusion DINO v2 都是ViT-B构型，StableDiffution是UNet 监督方法不一样， StableDiffusion,DINO v2两个方法最好 DPT head是什么 DUSt3R CROCO是一个MAE的结构，利用了多视角信息来猜Mask的内容 相对位姿估计，直接用三维点最小而成不行，因为离群点噪声太大，所以现在都用ransec+pnp MVS的时候相对位姿直接用最小二乘就可以了，因为图足够多了 FlowMap 利用光流做deep SFM TransFormer  Bert Bert是将文章分割出空格，然后预测空格中文字，是一个无监督的 ViT 把图片分割成16*16方块 MAE 2021年arxiv，Masked Autoencoders Are Scalabel Vison Learners,何凯明 *是同等贡献的意思 十字号是project...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/12/03/#%20%E4%B8%89%E7%BB%B4%E8%A7%86%E8%A7%89%E5%87%A0%E4%BD%95%E5%A4%A7%E6%95%B4%E7%90%86/" title=""><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2"></div></div><div class="info-2"><div class="info-item-1">三维视觉几何大整理 </div></div></div></a><a class="pagination-related" href="/2025/06/01/AlexNet/" title="AlexNet"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-01</div><div class="info-item-2">AlexNet</div></div><div class="info-2"><div class="info-item-1">李沐-AlexNet和卷积基础 ImageNet Classification With Deep Convolutional Neural Networks 俄罗斯人Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton 2012 在谷歌实习时候见到过这个人，汇报了这个工作。首个真正意义上的深度卷积神经网络 摘要 ImageNet是一个很大的数据集超过1500万张在超过22,000个类别，取其中一部分1000个类 在Imageet上top-1错误率37.5%，top-5错误率17.0%...</div></div></div></a><a class="pagination-related" href="/2025/12/03/Bark%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/" title="Bark模型微调"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2">Bark模型微调</div></div><div class="info-2"><div class="info-item-1">Bark模型微调 TTS模型/文本到语音（TTS）生成模型 以下开放的、已支持训练的 TTS 模型：    模型名 是否支持训练 特点 架构类型     SpeechT5（HuggingFace） ✅ 支持 TTS、VC、ASR，多任务训练    Coqui-TTS（强烈推荐） ✅ 支持 Tacotron2/FastSpeech2/VITS    ESPnet（工业级框架） ✅ 支持多种语音模型，配置稍复杂    YourTTS, VITS, GlowTTS ✅ Coqui-TTS/ESPnet 中均支持    VITS   VAE + GAN + flow   Bark   GPT decoder-only   Tacotron2   encoder-decoder + attention    EnCodec 解码器 EnCodec 是由 Facebook FAIR 开源的 神经压缩音频模型，可以高效地将音频压缩成离散 token，再解压回高质量语音。 类似于 VQ-VAE（Vector Quantized Variational...</div></div></div></a><a class="pagination-related" href="/2025/12/03/CUDA%20%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%9D%A5%E6%BA%90/" title="CUDA 环境的两种来源"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2">CUDA 环境的两种来源</div></div><div class="info-2"><div class="info-item-1">🧩 一、CUDA 环境的两种来源 CUDA（Compute Unified Device Architecture）分为两部分：    类型 功能 通常位置 谁提供     CUDA Toolkit（开发套件） 编译 CUDA 程序、包含 nvcc、头文件、静态库 /usr/local/cuda-* 你自己系统安装   CUDA Runtime（运行时库） 运行 PyTorch / TensorFlow / cuDNN 等程序 通常是 .so 动态库 PyTorch（或 conda 包）自动安装    👉 也就是说：  系统 CUDA Toolkit：给开发者编译用（比如写 CUDA C++、编译自定义算子）。 conda/pip CUDA Runtime：给 PyTorch 运行用，不依赖系统 CUDA。   ⚙️ 二、本地 CUDA 与 conda CUDA 的区别    对比项 系统 CUDA Toolkit conda CUDA runtime     用途 编译代码、开发 运行 PyTorch、推理训练   是否随 PyTorch 一起安装 否 是（通过...</div></div></div></a><a class="pagination-related" href="/2025/06/20/FoundationStereo/" title="FoundationStereo"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-20</div><div class="info-item-2">FoundationStereo</div></div><div class="info-2"><div class="info-item-1">FoundationStereo NVIDIA 2025 摘要（有本事别微调刷榜，我就是要做zero-shot） 通过每个域的微调，深度立体匹配在基准数据集上取得了巨大进步。然而，实现强大的零镜头泛化（其他计算机视觉任务中基础模型的标志）对于立体匹配来说仍然具有挑战性。为此，我们首先构建了一个大规模（1M 立体对）合成训练数据集，具有较大的多样性和高照片级真实感，然后是一个自动自我管理管道来去除模棱两可的样本。然后，我们设计了许多网络架构组件来增强可扩展性，包括一个侧调功能主干，它适应了视觉基础模型中丰富的单目先验，以减轻 sim-to-real 的差距，以及用于有效成本量过滤的远程上下文推理。 引言 近半个世纪前第一个立体匹配算法出现，我们已经走过了漫长的道路。，最近的立体算法可以取得惊人的结果，几乎使最具挑战性的基准测试饱和。然而，对目标域的数据集进行微调仍然是获得竞争结果的首选方法。鉴于通过scaling...</div></div></div></a><a class="pagination-related" href="/2025/12/03/Label%E8%BD%AF%E4%BB%B6%E8%B0%83%E7%A0%94%E5%92%8C%E4%BD%BF%E7%94%A8/" title="Label软件调研和使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2">Label软件调研和使用</div></div><div class="info-2"><div class="info-item-1">Label软件调研和使用 注释 2D 人体姿势的任务涉及在图像中识别和标记人体上的关键点。 首先进行一个人体数据集格式的调研 有几个人体数据集比如coco17点，coco-wholebody133点，Halpe136点，然后对应每种数据集格式有不同的model权重，和不同的config文件，即用什么估计，估计出来几个点，然后经过我的调研，17个点就足以描述项目了，腰部的旋转就是脖子和腰部的夹角角度嘛，所以我现在要找一个做coco数据集标注的软件，其实市面上大多数还是coco数据集的，然后只不过一开始我觉得骨架不一致给吓倒了。 PoseAnnotation（真难用） https://github.com/MiraPurkrabek/PoseAnnotator 该工具主要针对 COCO 样式的注释实现，因此需要其文件结构。每个数据集应有 3 个子文件夹 annotations、val2017 和可选的 train2017 但我们为我们的用例创建了一些自定义姿势格式。如果您使用 option --pose-format coco_with_thumbs...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/head.png" onerror="this.onerror=null;this.src='/./img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">outbreak_sen</div><div class="author-info-description">an interesting man</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">148</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/outbreak-sen" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/outbreakrmb" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="/1023786231" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-text">基本信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%A6%82%E8%A7%88"><span class="toc-text">方法概览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-text">引言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-text">创新点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-dynamic-splatter-pixel"><span class="toc-text">3.1 Dynamic Splatter Pixel</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-movies-unify-appearance-geometry-and-motion"><span class="toc-text">3.2 MoVieS: Unify Appearance, Geometry and Motion</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-1-feature-backbone"><span class="toc-text">3.2.1 Feature Backbone</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-2-prediction-heads"><span class="toc-text">3.2.2 Prediction Heads</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-text">训练</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-text">损失函数：</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoGe%202/" title="论文阅读_MoGe 2">论文阅读_MoGe 2</a><time datetime="2025-12-03T06:04:18.000Z" title="发表于 2025-12-03 14:04:18">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE/" title="论文阅读_变分自编码器VAE">论文阅读_变分自编码器VAE</a><time datetime="2025-12-03T06:01:57.000Z" title="发表于 2025-12-03 14:01:57">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/Multi%20View%20Stereo/" title="Multi View Stereo">Multi View Stereo</a><time datetime="2025-12-03T05:57:28.000Z" title="发表于 2025-12-03 13:57:28">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_SFM/" title="学习笔记_SFM">学习笔记_SFM</a><time datetime="2025-12-03T05:57:28.000Z" title="发表于 2025-12-03 13:57:28">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/" title="学习笔记_位置编码">学习笔记_位置编码</a><time datetime="2025-12-03T05:57:28.000Z" title="发表于 2025-12-03 13:57:28">2025-12-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By outbreak_sen</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>