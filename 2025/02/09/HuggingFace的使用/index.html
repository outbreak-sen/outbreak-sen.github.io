<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>HuggingFace的模型和数据集dataset | This is a 部落格 of outbreak_sen</title><meta name="author" content="outbreak_sen"><meta name="copyright" content="outbreak_sen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="HuggingFace的模型和数据集dataset 微调数据集：wikitext-103-v1 模型：BigBirdPegasusForCausalLM 如何下载模型和数据集并调用 这里的模型和数据集是需要在huggingface上找到专门的名称的，然后有多种下载方法，默认会下载到.cache&#x2F;huggingface&#x2F;hub&#x2F;,但是后面.cache可能会被清空。加载的时候，直接传入地址即可   通">
<meta property="og:type" content="article">
<meta property="og:title" content="HuggingFace的模型和数据集dataset">
<meta property="og:url" content="http://outbreak-sen.github.io/2025/02/09/HuggingFace%E7%9A%84%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="This is a 部落格 of outbreak_sen">
<meta property="og:description" content="HuggingFace的模型和数据集dataset 微调数据集：wikitext-103-v1 模型：BigBirdPegasusForCausalLM 如何下载模型和数据集并调用 这里的模型和数据集是需要在huggingface上找到专门的名称的，然后有多种下载方法，默认会下载到.cache&#x2F;huggingface&#x2F;hub&#x2F;,但是后面.cache可能会被清空。加载的时候，直接传入地址即可   通">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://outbreak-sen.github.io/img/head.png">
<meta property="article:published_time" content="2025-02-09T08:10:15.000Z">
<meta property="article:modified_time" content="2025-03-19T09:12:40.069Z">
<meta property="article:author" content="outbreak_sen">
<meta property="article:tag" content="huggingface">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://outbreak-sen.github.io/img/head.png"><link rel="shortcut icon" href="/img/h_beautygirl.png"><link rel="canonical" href="http://outbreak-sen.github.io/2025/02/09/HuggingFace%E7%9A%84%E4%BD%BF%E7%94%A8/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HuggingFace的模型和数据集dataset',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="This is a 部落格 of outbreak_sen" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg" style="background-image: url(/img/v_beautygirl0.jpeg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/head.png" onerror="onerror=null;src='./img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">151</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-camera-retro"></i><span> 树洞</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 作品与鉴赏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/h_beautygirl.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/h_beautygirl.png" alt="Logo"><span class="site-name">This is a 部落格 of outbreak_sen</span></a><a class="nav-page-title" href="/"><span class="site-name">HuggingFace的模型和数据集dataset</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-camera-retro"></i><span> 树洞</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 作品与鉴赏</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">HuggingFace的模型和数据集dataset</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-02-09T08:10:15.000Z" title="发表于 2025-02-09 16:10:15">2025-02-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-19T09:12:40.069Z" title="更新于 2025-03-19 17:12:40">2025-03-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>HuggingFace的模型和数据集dataset</h1>
<p>微调数据集：wikitext-103-v1</p>
<p>模型：BigBirdPegasusForCausalLM</p>
<h2 id="如何下载模型和数据集并调用">如何下载模型和数据集并调用</h2>
<p>这里的模型和数据集是需要在huggingface上找到专门的名称的，然后有多种下载方法，默认会下载到.cache/huggingface/hub/,但是后面.cache可能会被清空。加载的时候，直接传入地址即可</p>
<ol>
<li>
<p>通过 huggingface model hub 网页的下载按钮进行下载。模型项目页的 <code>Files</code> 栏中可以获取文件的下载链接。<strong>无需登录</strong>直接点击下载</p>
</li>
<li>
<p>通过 huggingface 的 huggingface_hub 工具进行下载</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pip install huggingface_hub</span><br><span class="line">huggingface-cli download internlm/internlm2-chat-7b</span><br><span class="line"># 但是直接这么下载还是网络超时，所以使用镜像</span><br><span class="line">python -m pip install huggingface_hub</span><br><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line">huggingface-cli download --resume-download gpt2 --local-dir gpt2</span><br><span class="line">	可选参数 --resume-download （已废弃）现在默认断点续传</span><br><span class="line">	可选参数 --local-dir-use-symlinks False 因为huggingface的工具链默认会使用符号链接来存储下载的文件，导致--local-dir指定的目录中都是一些“链接文件”，真实模型则存储在~/.cache/huggingface下，如果不喜欢这个可以用 --local-dir-use-symlinks False取消这个逻辑。 但是这样的话每次调用的时候都必须输入绝对路径了。</span><br><span class="line">huggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitext</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用 huggingface 的 transformers 库实例化模型进而将模型下载到缓存目录。就是说写代码什么时候需要什么时候下载，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from transformers import AutoTokenizer, AutoModelForCausalLM</span><br><span class="line">import os</span><br><span class="line"># 设置 HF_ENDPOINT 环境变量</span><br><span class="line">os.environ[&quot;HF_ENDPOINT&quot;] = &quot;https://hf-mirror.com&quot;</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(&quot;/home/&#123;username&#125;/huggingface/internlm2-chat-7b&quot;, trust_remote_code=True)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(&quot;/home/&#123;username&#125;/huggingface/internlm2-chat-7b&quot;, torch_dtype=torch.float16, trust_remote_code=True).cuda()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用**<a target="_blank" rel="noopener" href="https://gist.github.com/padeoe/697678ab8e528b85a2a7bddafea1fa4f">hfd</a>** 是国人开发的 huggingface 专用下载工具，基于成熟工具 <code>aria2</code>，可以做到稳定高速下载不断线。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://hf-mirror.com/hfd/hfd.shchmod a+x hfd.sh</span><br><span class="line">chmod a+x hfd.sh</span><br><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line">./hfd.sh gpt2</span><br><span class="line">./hfd.sh wikitext --dataset</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="dataset库的使用">Dataset库的使用</h2>
<p>Dataset库其实也是huggingface的，维护了很多数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">pip install datasets</span><br><span class="line">import os #据说这样可以开启代理 </span><br><span class="line">os.environ[&#x27;HTTP_PROXY&#x27;] = &#x27;http://127.0.0.1:7890&#x27;</span><br><span class="line">os.environ[&#x27;HTTPS_PROXY&#x27;] = &#x27;http://127.0.0.1:7890&#x27;</span><br><span class="line">from datasets import load_dataset</span><br><span class="line">ds = load_dataset(&quot;fancyzhx/ag_news&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看数据集的组成，用feature，然后可以看到分为text和每个text的label，这是一个文本分类任务</span><br><span class="line">ds[&quot;train&quot;].features</span><br><span class="line"># &#123;&#x27;text&#x27;: Value(dtype=&#x27;string&#x27;, id=None),&#x27;label&#x27;: ClassLabel(names=[&#x27;World&#x27;, &#x27;Sports&#x27;, &#x27;Business&#x27;, &#x27;Sci/Tech&#x27;], id=None)&#125;</span><br><span class="line"></span><br><span class="line"># 直接这样也可以输出ds的构成，是分为train和test</span><br><span class="line">ds</span><br><span class="line">print(ds)</span><br><span class="line"># DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 120000</span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 7600</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>filter</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 传入一个lamda函数，其中要求数据的label为2</span><br><span class="line">tmp = ds[&quot;train&quot;].filter(lambda x: x[&quot;label&quot;] == 2)</span><br><span class="line">print(tmp)</span><br><span class="line">print(tmp[0])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>map，对于数据集中的分类进行修改，或者对于内容进行扩充</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">prompt_cls = &quot;&quot;&quot;你是文本分类领域的专家，请你给下述文本分类，把它分到下述类别中：</span><br><span class="line">* World</span><br><span class="line">* Sports</span><br><span class="line">* Business</span><br><span class="line">* Science / Technology&#x27;</span><br><span class="line"></span><br><span class="line">text是待分类的文本，label是文本的类别：</span><br><span class="line">text: &#123;text&#125;</span><br><span class="line">label: </span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"># 这个lamda函数定义了一个把prompt_cls中的text部分替换为输入的text，也可以是text</span><br><span class="line">def trans2llm(item):</span><br><span class="line">    item[&quot;text&quot;] = prompt_cls.format(text=item[&quot;text&quot;])</span><br><span class="line">    return item</span><br><span class="line"></span><br><span class="line">tmp = ds[&quot;test&quot;].map(trans2llm)</span><br><span class="line">print(tmp[0])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>select 数据集采样，随机采样、下标采样等；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ds[&quot;train&quot;].select([0, 10, 20, 30, 40, 50])# 需要加下标</span><br><span class="line"># 如果想要随机取1000个</span><br><span class="line">import random  </span><br><span class="line">numbers = list(range(1000))</span><br><span class="line">random_numbers = random.sample(numbers, 100)</span><br><span class="line">ds[&quot;train&quot;].select(random_numbers)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>concatenate_datasets数据集拼接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from datasets import concatenate_datasets</span><br><span class="line">dataset = concatenate_datasets([true_dataset, false_dataset])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>train_test_split区分训练集和测试集，并且自动加一个纬度划分为test和train</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dataset.train_test_split(train_size=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;wikitext&quot;</span>, <span class="string">&quot;wikitext-103-v1&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(dataset)</span><br><span class="line">dataset = dataset.select(<span class="built_in">range</span>(<span class="number">1000</span>))  <span class="comment"># Use a subset for quick testing</span></span><br><span class="line">train_test_split = dataset.train_test_split(test_size=<span class="number">0.1</span>)</span><br><span class="line"><span class="built_in">print</span>(train_test_split)</span><br><span class="line">train_dataset = train_test_split[<span class="string">&#x27;train&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(train_dataset)</span><br><span class="line">eval_dataset = train_test_split[<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(eval_dataset)</span><br><span class="line"><span class="built_in">print</span>(train_dataset[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;text&#x27;],</span><br><span class="line">    num_rows: 1801350</span><br><span class="line">&#125;)</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;],</span><br><span class="line">        num_rows: 900</span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;],</span><br><span class="line">        num_rows: 100</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;text&#x27;],</span><br><span class="line">    num_rows: 900</span><br><span class="line">&#125;)</span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;text&#x27;],</span><br><span class="line">    num_rows: 100</span><br><span class="line">&#125;)</span><br><span class="line">&#123;&#x27;text&#x27;: &quot; The ship was assigned to the Austro @-@ Hungarian Fleet &#x27;s 1st Battle Squadron after her 1911 commissioning . In 1912 , Zrínyi and her two sister ships conducted two training cruises into the eastern Mediterranean Sea . On the second cruise into the Aegean Sea , conducted from November to December , Zrínyi and her sister ships were accompanied by the cruiser SMS Admiral Spaun and a pair of destroyers . After returning to Pola , the entire fleet mobilized for possible hostilities , as tensions flared in the Balkans . \n&quot;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>add_column添加属性列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset[&quot;train&quot;] = dataset[&quot;train&quot;].add_column(&quot;index&quot;, list(range(786701)))</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>rename_column属性列重命名</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset[&quot;train&quot;] = dataset[&quot;train&quot;].rename_column(&quot;idx&quot;, &quot;file_sent_index&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="train-loss">train loss</h2>
<p>对比微调训练的loss变化</p>
<table>
<thead>
<tr>
<th>epoch</th>
<th>mindnlp+mindspore</th>
<th>transformer+torch（4060）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2.9176</td>
<td>8.7301</td>
</tr>
<tr>
<td>2</td>
<td>2.79</td>
<td>8.1557</td>
</tr>
<tr>
<td>3</td>
<td>2.593</td>
<td>7.7516</td>
</tr>
<tr>
<td>4</td>
<td>2.4875</td>
<td>7.5017</td>
</tr>
<tr>
<td>5</td>
<td>2.3831</td>
<td>7.2614</td>
</tr>
<tr>
<td>6</td>
<td>2.2631</td>
<td>7.0559</td>
</tr>
<tr>
<td>7</td>
<td>2.2369</td>
<td>6.8405</td>
</tr>
<tr>
<td>8</td>
<td>2.1732</td>
<td>6.7297</td>
</tr>
<tr>
<td>9</td>
<td>2.1717</td>
<td>6.7136</td>
</tr>
<tr>
<td>10</td>
<td>2.1833</td>
<td>6.6279</td>
</tr>
</tbody>
</table>
<h2 id="eval-loss">eval loss</h2>
<p>对比评估得分</p>
<table>
<thead>
<tr>
<th>epoch</th>
<th>mindnlp+mindspore</th>
<th>transformer+torch（4060）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2.6390955448150635</td>
<td>6.3235931396484375</td>
</tr>
</tbody>
</table>
<p># 测试样例（包含真实标签）</p>
<p>test_data = [</p>
<p>​    {“text”: “I am a little confused on all of the models of the 88-89 bonnevilles.\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\ndifferences are far as features or performance. I am also curious to\nknow what the book value is for prefereably the 89 model. And how much\nless than book value can you usually get them for. In other words how\nmuch are they in demand this time of year. I have heard that the mid-spring\nearly summer is the best time to buy.”</p>
<p>​     , “true_label”: “rec.autos”},</p>
<p>​    {“text”: “I’m not familiar at all with the format of these X-Face:thingies, but\nafter seeing them in some folks’ headers, I’ve <em>got</em> to <em>see</em> them (and\nmaybe make one of my own)!\n\nI’ve got dpg-viewon my Linux box (which displays uncompressed X-Faces)\nand I’ve managed to compile [un]compface too… but now that I’m <em>looking</em>\nfor them, I can’t seem to find any X-Face:'s in anyones news headers!  :-(\n\nCould you, would you, please send me your X-Face:header\n\nI know* I’ll probably get a little swamped, but I can handle it.\n\n\t…I hope.”</p>
<p>​     , “true_label”: “comp.windows.x”},</p>
<p>​    {“text”: “\nIn a word, yes.\n”</p>
<p>​        , “true_label”: “alt.atheism”},</p>
<p>​    {“text”: “\nThey were attacking the Iraqis to drive them out of Kuwait,\na country whose citizens have close blood and business ties\nto Saudi citizens.  And me thinks if the US had not helped out\nthe Iraqis would have swallowed Saudi Arabia, too (or at \nleast the eastern oilfields).  And no Muslim country was doing\nmuch of anything to help liberate Kuwait and protect Saudi\nArabia; indeed, in some masses of citizens were demonstrating\nin favor of that butcher Saddam (who killed lotsa Muslims),\njust because he was killing, raping, and looting relatively\nrich Muslims and also thumbing his nose at the West.\n\nSo how would have <em>you</em> defended Saudi Arabia and rolled\nback the Iraqi invasion, were you in charge of Saudi Arabia???\n\n\nI think that it is a very good idea to not have governments have an\nofficial religion (de facto or de jure), because with human nature\nlike it is, the ambitious and not the pious will always be the\nones who rise to power.  There are just too many people in this\nworld (or any country) for the citizens to really know if a \nleader is really devout or if he is just a slick operator.\n\n\nYou make it sound like these guys are angels, Ilyess.  (In your\nclarinet posting you edited out some stuff; was it the following???)\nFriday’s New York Times reported that this group definitely is\nmore conservative than even Sheikh Baz and his followers (who\nthink that the House of Saud does not rule the country conservatively\nenough).  The NYT reported that, besides complaining that the\ngovernment was not conservative enough, they have:\n\n\t- asserted that the (approx. 500,000) Shiites in the Kingdom\n\t  are apostates, a charge that under Saudi (and Islamic) law\n\t  brings the death penalty.  \n\n\t  Diplomatic guy (Sheikh bin Jibrin), isn’t he Ilyess?\n\n\t- called for severe punishment of the 40 or so women who\n\t  drove in public a while back to protest the ban on\n\t  women driving.  The guy from the group who said this,\n\t  Abdelhamoud al-Toweijri, said that these women should\n\t  be fired from their jobs, jailed, and branded as\n\t  prostitutes.\n\n\t  Is this what you want to see happen, Ilyess?  I’ve\n\t  heard many Muslims say that the ban on women driving\n\t  has no basis in the Qur’an, the ahadith, etc.\n\t  Yet these folks not only like the ban, they want\n\t  these women falsely called prostitutes?  \n\n\t  If I were you, I’d choose my heroes wisely,\n\t  Ilyess, not just reflexively rally behind\n\t  anyone who hates anyone you hate.\n\n\t- say that women should not be allowed to work.\n\n\t- say that TV and radio are too immoral in the Kingdom.\n\nNow, the House of Saud is neither my least nor my most favorite government\non earth; I think they restrict religious and political reedom a lot, among\nother things.  I just think that the most likely replacements\nfor them are going to be a lot worse for the citizens of the country.\nBut I think the House of Saud is feeling the heat lately.  In the\nlast six months or so I’ve read there have been stepped up harassing\nby the muttawain (religious police—<em>not</em> government) of Western women\nnot fully veiled (something stupid for women to do, IMO, because it\nsends the wrong signals about your morality).  And I’ve read that\nthey’ve cracked down on the few, home-based expartiate religious\ngatherings, and even posted rewards in (government-owned) newspapers\noffering money for anyone who turns in a group of expartiates who\ndare worship in their homes or any other secret place. So the\ngovernment has grown even more intolerant to try to take some of\nthe wind out of the sails of the more-conservative opposition.\nAs unislamic as some of these things are, they’re just a small\ntaste of what would happen if these guys overthrow the House of\nSaud, like they’re trying to in the long run.\n\nIs this really what you (and Rached and others in the general\nwest-is-evil-zionists-rule-hate-west-or-you-are-a-puppet crowd)\nwant, Ilyess?\n”</p>
<p>​     , “true_label”: “talk.politics.mideast”}</p>
<p>]</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://outbreak-sen.github.io">outbreak_sen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://outbreak-sen.github.io/2025/02/09/HuggingFace%E7%9A%84%E4%BD%BF%E7%94%A8/">http://outbreak-sen.github.io/2025/02/09/HuggingFace%E7%9A%84%E4%BD%BF%E7%94%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://outbreak-sen.github.io" target="_blank">This is a 部落格 of outbreak_sen</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/huggingface/">huggingface</a></div><div class="post-share"><div class="social-share" data-image="/./img/head.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/02/09/colmap%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/" title="colmap介绍和使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">colmap介绍和使用</div></div><div class="info-2"><div class="info-item-1">colmap官方教程的笔记 需要CUDA才能稠密重建，否则只能稀疏重建 Colmap论文——《Structure-from-Motion Revisited》论文阅读笔记 Tutorial 传统上，基于图像的3D重建首先使用“运动结构Structure-from-Motion”来恢复场景的稀疏表示和输入图像的相机姿态。然后，此输出用作“多视图立体Multi-View Stereo”的输入，以恢复场景的密集表示。 12345678/path/to/project/...+── images│   +── image1.jpg│   +── image2.jpg│   +── ...│   +── imageN.jpg+── database.db+── project.ini 重建的过程   Structure-from-Motion  是将3D结构从投影重建为一系列图像的过程。输入是从不同视点拍摄的同一对象的一组重叠图像。输出是物体的三维重建，以及所有图像的重建的内在和外在相机参数。 通常，“运动结构”系统将此过程分为三个阶段： 特征检测与提取 特征匹配和几何验证...</div></div></div></a><a class="pagination-related" href="/2025/02/09/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/" title="GAN生成对抗模型入门"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">GAN生成对抗模型入门</div></div><div class="info-2"><div class="info-item-1">GAN笔记 简介 GAN的思想来自零和博弈理论，由两个部分组成，一个是生成器Generator，随机接收一个随机噪声来生成图像。一个是鉴别器Discriminator，判断一张图像是不是“真实的”，输入是一张图像，输出是该图像为真实图像的概率，介于0-1之间，概率值越小认为生成图像不真实的可能性越大。生成器的目标是通过生成接近真实的图像来欺骗判别器，而判别器的目标是尽量辨别出生成器生成的假图像和真实图像的区别。 自编码器（Auto-Encoder)以及变分自编码器（Variational  Auto-Encoder)都是典型的生成器。输入通过Encoder编码成code，然后code通过Decoder重建原图，其中自编码器中的Decoder就是生成器，code可随机取值，产生不同的输出。 自编码器是一种能够通过无监督学习，对输入数据进行特征提取，学习到数据的抽象表示，称为编码过程，编码结果往往维度远小于输入数据，自编码器可以用于降维和特征提取， 变分自编码器（Variational auto-encoder，VAE）是一类重要的生成模型（generative...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/02/26/NLP%E4%BB%BB%E5%8A%A1%E5%BE%AE%E8%B0%83%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="NLP任务微调笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-26</div><div class="info-item-2">NLP任务微调笔记</div></div><div class="info-2"><div class="info-item-1">NLP任务微调笔记 NLP数据集没有像CV一样大量标号的数据集，所以NLP一般是自监督的，有两种自监督的模型：   LM：语言模型，预测下一个词   MLM：带掩码的语言模型，完形填空   每种预训练模型基于不同的技术也分为两种：   Word embddings：  LSTM之类的传统的    Transformer based pretrained model：  Bert：基于encoder，针对Bert的微调，把最后一层重新设计随机初始化，做分类只需要拿出一个然后训练，做QA只需要输出答案的位置 GPT：基于decoder T5：基于encoder和decode    如何做分词 数据集一般是用Unicode进行编码，是对世界所有语言的一种编码，但是我们需要将这些文字变成数字编码的向量，就需要分词 1&quot;我是一个用于测试输出unicode编码的文字&quot;.encode(&#x27;utf-8&#x27;)#可以看到每个字对应的unicode编码...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/./img/head.png" onerror="this.onerror=null;this.src='/./img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">outbreak_sen</div><div class="author-info-description">an interesting man</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">151</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/outbreak-sen" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/outbreakrmb" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="/1023786231" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">HuggingFace的模型和数据集dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B9%B6%E8%B0%83%E7%94%A8"><span class="toc-text">如何下载模型和数据集并调用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dataset%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">Dataset库的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#train-loss"><span class="toc-text">train loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#eval-loss"><span class="toc-text">eval loss</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_MoGe%202/" title="论文阅读_MoGe 2">论文阅读_MoGe 2</a><time datetime="2025-12-03T06:04:18.000Z" title="发表于 2025-12-03 14:04:18">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB_%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE/" title="论文阅读_变分自编码器VAE">论文阅读_变分自编码器VAE</a><time datetime="2025-12-03T06:01:57.000Z" title="发表于 2025-12-03 14:01:57">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/Multi%20View%20Stereo/" title="Multi View Stereo">Multi View Stereo</a><time datetime="2025-12-03T05:57:28.000Z" title="发表于 2025-12-03 13:57:28">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/SFM/" title="SFM">SFM</a><time datetime="2025-12-03T05:57:28.000Z" title="发表于 2025-12-03 13:57:28">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/VSCode%20Python%20Debug%20%E6%95%99%E7%A8%8B/" title="VSCode Python Debug">VSCode Python Debug</a><time datetime="2025-12-03T05:57:28.000Z" title="发表于 2025-12-03 13:57:28">2025-12-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By outbreak_sen</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>