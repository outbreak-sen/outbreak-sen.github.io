<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>This is a 部落格 of outbreak_sen</title>
  
  <subtitle>[object Object]</subtitle>
  <link href="http://outbreak-sen.github.io/atom.xml" rel="self"/>
  
  <link href="http://outbreak-sen.github.io/"/>
  <updated>2025-03-19T09:11:52.583Z</updated>
  <id>http://outbreak-sen.github.io/</id>
  
  <author>
    <name>outbreak_sen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>证券投资</title>
    <link href="http://outbreak-sen.github.io/2025/03/12/%E8%AF%81%E5%88%B8%E6%8A%95%E8%B5%84/"/>
    <id>http://outbreak-sen.github.io/2025/03/12/%E8%AF%81%E5%88%B8%E6%8A%95%E8%B5%84/</id>
    <published>2025-03-12T03:54:34.000Z</published>
    <updated>2025-03-19T09:11:52.583Z</updated>
    
    <content type="html"><![CDATA[<h1>证券投资计划</h1><h1>当前经济环境分析</h1><ul><li><strong>低利率环境</strong>：中国目前处于低利率周期，央行通过降准、降息等手段刺激经济，导致国债收益率较低。</li><li><strong>通胀水平</strong>：当前通胀压力较小（CPI涨幅较低），2%的国债收益率尚能覆盖通胀，但若未来通胀上升，实际收益可能进一步缩水。</li><li><strong>经济复苏不确定性</strong>：中国经济复苏仍面临挑战（如消费疲软、房地产低迷），国债作为避险资产可能受到青睐。</li></ul><h1>信托计划</h1><h1>国债</h1><p>国债主要分为记账式国债和储蓄式国债</p><p>储蓄式国债又分为电子储蓄式国债和凭证式国债</p><p><img src="./%E8%AF%81%E5%88%B8%E6%8A%95%E8%B5%84/image-20250312140814603.png" alt="image-20250312140814603"></p><p><strong>凭证式储蓄国债</strong>：</p><ul><li><p>凭证式的自12年之后没文件了</p></li><li><p>凭证式国债需携带身份证和资金到银行网点办理，<strong>只能在发行当天提前去承销银行网点排队</strong></p></li><li><p>储蓄国债**支持提前兑取，但需支付1‰手续费，并按持有时间分档计息.利率固定，到期一次性还本付息。**例如，2025年3月发行的储蓄国债，3年期利率为1.93%，5年期为2.0%.假设我花10万元购买了国债，年利率是3.8%，如果是电子式国债，第一年可以拿到3800元的利息，我可以用这份利息继续投资，让这份钱也可以产生收益。但如果是凭证式国债，我们只有等到期才能拿到全部利息，就无法让我们的资金发挥最大的作用。</p></li><li><p>银行都承销国债，但是他们的承销比例不同，具体的承销比例一般在国债发行通知里有，一般工行和建行是最高的。不过承销比例高也不意味着这些银行更好买，因为用户也更多。</p></li></ul><p><strong>电子式储蓄国债</strong></p><ul><li><p><a href="https://www.chinabond.com.cn/xxpl/ywzc_fxyfxdh/fxyfxdh_zqzl/zqzl_gz/gz_cxs/cxs_fxwj_ath/202411/t20241107_853939027.html">2024年第九期储蓄国债文件</a>,<strong>2024年第九期期限3年，票面年利率为1.93%,第十期期限5年，票面年利率为2%</strong>,最后有承担单位比例</p></li><li><p>电子式国债可通过网银直接购买</p></li><li><p>电子式国债是<strong>一年一付息</strong>，可以人为地制造复利效果。</p></li></ul><p><strong>记账式国债</strong>：</p><ul><li><p>2025年第五次记账式国债利率1.45&amp;</p></li><li><p>可在银行柜台或证券交易所购买，支持二级市场交易，流动性较高.利率浮动，收益随市场波动</p></li><li><p>可通过<strong>银行或证券交易所</strong>查询实时收益率.转让所得<strong>需按20%税率缴纳个人所得税</strong></p></li></ul><p>超长期国债</p><ul><li>2024年超长期特别国债（六期）（30年期）,续发行国债票面利率与之前发行的同期国债相同，为2.19%。</li></ul><h3 id="如何购买">如何购买</h3><ul><li><p>国债发行时间、利率和额度信息，可<strong>通过财政部官网或承销银行官网\中国人民银行官网查询</strong>,但是我没有找到,但是在<a href="https://www.chinabond.com.cn/">中国债权信息网</a>看到了国债的发行文件,有国债的专栏,可以看到储蓄性和凭证性.还能看到地方性债权和银行金融行债权,可达1.66%</p></li><li><p>在没有持满6个月的情况下，不仅没有利息，还要扣除相应的手续费。</p></li><li><p>一般来说，国债发行时间固定在每月的10日~19日之间，不过也存在不发行的情况。比如每年有三个月份基本不会发行，分别是的1、2、12月份。根据财政部2022年第一季度国债发行计划，最近一次是3月10日，发行的是凭证式国债</p></li><li><p><strong>第一次购买需要开通国债托管账户</strong>,这个托管账户可以在银行网点办理，也可以在网上银行办理。但是各银行有自己的要求，有些银行只有高级用户才可以用网银开，有些银行用网银开需要支付手续费，<strong>线下不需要</strong>。开通了国债托管账户之后，我们就等到<strong>发行日当天8:30之前登录网银，打开国债购买界面</strong>，开始抢购</p></li></ul><h3 id="其他内容">其他内容</h3><ul><li><a href="https://cn.investing.com/">英为财情</a>可查到各国历年债权,<a href="https://cn.investing.com/rates-bonds/world-government-bonds">各国债权收益率</a>,乌克兰的三年期债权收益率低于一年期债权收益率，但是收益率可以达到30%,这种现象被称为“收益率曲线倒挂”（Yield Curve Inversion），通常反映了市场对经济前景的悲观预期。</li><li>2%的年化收益率可能跑不赢通胀（2023年中国CPI同比涨幅约0.9%-1.5%），实际收益有限。</li></ul><h1>微信</h1><p>'大额存单</p><p>银行利息</p><p>等投资品种不是门槛太高就是收益普遍低于5%</p><h2 id="a股市场">A股市场</h2><p><a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=A%E8%82%A1%E5%B8%82%E5%9C%BA&amp;zhida_source=entity">A股市场</a>鱼龙混杂，蓝筹白马股适合大资金投资者，稳健风格投资者，<a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=%E8%82%A1%E6%81%AF%E6%8A%95%E8%B5%84%E8%80%85&amp;zhida_source=entity">股息投资者</a>；成长股适合专业投资者；<a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=%E7%A7%91%E5%88%9B%E7%A7%91%E6%8A%80%E8%82%A1&amp;zhida_source=entity">科创科技股</a>适合职业投资者，适合对投资收益有要求的投资者</p><p>很多股票软件最开始的首页就是涨幅榜和跌幅榜</p><h3 id="怎么分析一只股票">怎么分析一只股票</h3><p>电脑上面就是两个按键<strong>一个是F5,一个是F10</strong>，F5就是<a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90&amp;zhida_source=entity">技术分析</a>板块，F10就是<a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=%E5%9F%BA%E6%9C%AC%E9%9D%A2%E5%88%86%E6%9E%90&amp;zhida_source=entity">基本面分析</a></p><p>F5就是<a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90&amp;zhida_source=entity">技术分析</a>板块</p><p>日线，周线，月线就是技术分析，</p><p>红红绿绿的是k线围绕着k线的是均线下面的是成交量最后的是MACD</p><p>红红绿绿的是k线围绕着k线的是均线下面的是成交量最后的是MACD</p><p>股价上涨技术指标就金叉，下跌就死叉</p><p>涨了就是红k，大涨就是大体积的红k，反之亦然，下跌就是绿k</p><p>成交量也是，涨的就是红，跌的就是绿</p><p>F10就是基本面分析</p><p>基本面分析在下面的股票资料里面</p><p><strong>一，净利润（要稳定增加，因为净利润就是企业的赚钱能力）</strong>**</p><p>二，现金流（不能为负。因为现金流负了有可能企业资金链困难）</p><p>三，<a href="https://zhida.zhihu.com/search?content_id=343862019&amp;content_type=Answer&amp;match_order=1&amp;q=%E5%B8%82%E7%9B%88%E7%8E%87&amp;zhida_source=entity">市盈率</a>（要平稳，因为市盈率波动大证明业绩不稳定）</p><p>四，净资产（要稳定增加，因为净资产是企业的根基）</p><p>五，营业收入（要稳定增加，因为营业收入是企业的规模）**</p><p><strong>了解完了官网以后我相信大家肯定有各种疑问</strong>打开上交所互动易还有、深交所互动易。如果对企业有不清楚的都可以问企业的董秘，如果是可以互动的都会回答，不能透露的就肯定不能回答。有些企业董秘不在意和投资者的互动，这些企业大多是国企，或者是僵尸企业，这样的企业都很难很直接的和高管有一个互动和联系</p><p>**还有一种方法****那就是打电话！**电话也在F10里面的公司概况，有些国企真的不太懂互联网，高管也年纪大，所以他们都是接电话来和投资者沟通的</p><h3 id="股票交易频率">股票交易频率</h3><p>交易频率最影响的其实是交易费，粗略的估算，1万块钱交易费一共在17-24之间，平均20块钱上下。如果是每天交易，按照一年250个交易日来算，交易费5000块钱！**排除掉交易费不算，股票的交易频率多少为好?**交易是需要契机的。</p><ul><li><p>最忌讳的就是情绪化交易，无理由交易</p></li><li><p>交易是被动的，交易的主体是股票和市场，市场和股票发生了变化我们才需要用交易来应对。如果市场没有变化，股票也没有变化，我们什么都不做才是最好的交易。</p></li><li><p>什么情况下要做卖出交易？</p><ul><li>突发的重大利空</li><li>突发的个股利空 这两个是很需要卖出的因素，尤其是个股的利空，重大的个股利空一般会导致个股短期暴跌，只要不是跌停板都可以卖出，因为后期很可能几个月，甚至一年都被这个利空给压制，这是很需要卖出的 市场的利空还好，虽然大部分股票会跌，但是也有30%左右的股票主力比较强或者是经营能力比较强，跌了很快就会涨回来，你可以根据自己的股票情况来选择是否卖出</li><li>达到你的预期涨幅</li><li>有更好的股票调仓换股 你预期一年就是10%的收益，那么既然达到了，你当然可以卖出，这个是很好的纪律，然后就是你发现了更好的股票，你也可以选择卖出换股。</li></ul></li><li><p>什么情况下要做买入交易？</p><ul><li>股市慢慢在走牛</li><li>发现了基本面特别优质且低估的股票 股市慢慢有走牛迹象的时候肯定要做好买入的准备，这个是每个股民都要有的准备，然后就是发现了经营很好，还很便宜的股票，那肯定要准备好买入。 这是最好的两个买入策略，一个是市场一个的个股，都是非常好的买入理由。</li><li>做长期的股息投资</li><li>家庭投资配置仓位，两个是超长线投资者的选择，股息投资说实话99%的投资者从未感受到其魅力，因为很少以后投资者可以持股不动5年以上，股息每年发1-2次，发了以后你再买入股，反复最少3-5次才会有很大的收益累积，对于3年以下持股的投资者，很难感受到股息投资有多么赚钱。家庭投资配置仓位适合大资金投资者，对于有很多闲钱的投资者，可以配置20%的资金到股市，选择最好最安全的一些大型企业配置，一方面可以获得股息，一方面可以长期得到股市的发展收获，这也是最少3-5年以上的投资策略。</li></ul></li></ul><h3 id="挂单教学">挂单教学</h3><p>假如是买入100股，股价1块钱，高于目前股价是9毛9，那么你可以直接买入，甚至看不见单子出现在屏幕上，因为直接成交了，假如你的单子挂的是9毛8，低于当前股价9毛9。那么很可能不会马上成交，你会看见9毛8的价位上面多了100股的单子。 这就是挂单，就是挂出去你要成交的价格。</p><p>电脑端交易是按f12可以挂单交易.</p><p>闪电挂单可以设置的更快！只要双击目前的一个价位，自动下单，不怕来不及挂单，比普通的F12挂单快3倍，比闪电挂单快2倍，可以节约快1分钟的时间，有时候可以有好几个点的差价！</p><p>快捷交易可以让你在下单的时候过滤那些确认的过程，调整到特快</p><p>跟盘是很重要的设置，因为股价会时时刻刻变化，你之前输入的价格会一直改变，如果你不设置自动跟盘，你就要不断的调整买卖价格，太麻烦</p><p>行情刷新设置到1-2秒，不要用默认的5秒，太慢了！会错过短线的机会！</p><p>设置一下闲置60分钟，不然你每次过一段时间交易就会锁屏，很麻烦，锁屏以后要重新输入密码</p><h3 id="暂定年化10-的收益为学会炒股">暂定年化10%的收益为学会炒股</h3><p>最主流的3种赚钱策略</p><p>投资企业的综合实力，赚的是企业成长和社会发展的钱、</p><p>投资股价的差价波动，赚的是筹码博弈和人性博弈的钱</p><p>投资热点题材的利好，赚的是市场上所有无脑韭菜的钱、</p><p><strong>投机+短线应该这样玩</strong>:分析大盘—选热点题材—选行业—选股—分析个股走势—控制仓位—买入—跟踪个股大盘走势—卖出</p><p>短线最短也应该把握4周左右的行情。<strong>最短的操作周期都会预设在4周左右，4周也就是一个月的短线周期</strong>这样的短线周期才能有可操作性和可操作空间 任何盈利概率不高的操作都没有复利的价值，没有复利的价值也就没有去操作的理由，就算是投资也要建立在可复利的原则上进行，这是我对投机的见解</p><p>最好的操作不是由收益的大小决定的，而是由风险的大小决定的</p><p>.风险越大的交易，就越要把仓位控制的越低。满仓对于任何人来说，都是在把风险提高到最大</p><p>投机，投的是机会，不是投风险，多留一点现金，你就在自己创造无限的机会</p><p>投机，投的是机会，不是投风险，多留一点现金，你就在自己创造无限的机会</p><p><strong>长线+价值投资应该这样做</strong>选股—分析行业—分析个股走势—分析大盘—控制仓位—慢慢买入—跟踪个股和大盘走势—决定减仓或加仓</p><p><strong>财务报表要看的是企业的发展前景而非表面的数据</strong>价值投资赚大钱更需要抓住好企业短暂的经营困难期，抓住好企业的周期性机会，这种时候好企业因为业绩不好导致股价暴跌，这就是大机会.这就是最高级的价值投资，因为等你真正看见非常好的财务报表时，股价肯定在高位</p><p>**不管你是什么投资者，长线，短线，价值，波短，各种投资者你都需要重视股本****股本太大代表什么？**市场上股份很多，投资者数量可能很多，资金层面上就会导致筹码很分散，不容易大涨。</p><p><strong>股本小的股票更容易收集筹码，拉升起来更流畅。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;证券投资计划&lt;/h1&gt;
&lt;h1&gt;当前经济环境分析&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;低利率环境&lt;/strong&gt;：中国目前处于低利率周期，央行通过降准、降息等手段刺激经济，导致国债收益率较低。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通胀水平&lt;/strong&gt;：当前通</summary>
      
    
    
    
    <category term="随便学点" scheme="http://outbreak-sen.github.io/categories/%E9%9A%8F%E4%BE%BF%E5%AD%A6%E7%82%B9/"/>
    
    
    <category term="证券投资" scheme="http://outbreak-sen.github.io/tags/%E8%AF%81%E5%88%B8%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>MindNLP模型微调超级笔记</title>
    <link href="http://outbreak-sen.github.io/2025/02/26/MindNLP-bigbird_pegasus%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"/>
    <id>http://outbreak-sen.github.io/2025/02/26/MindNLP-bigbird_pegasus%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</id>
    <published>2025-02-26T07:01:44.000Z</published>
    <updated>2025-03-19T09:14:02.907Z</updated>
    
    <content type="html"><![CDATA[<h1>MindNLP模型微调超级笔记</h1><h2 id="乱七八糟的学习参考">乱七八糟的学习参考</h2><h3 id="已完成的bloom模型微调">已完成的bloom模型微调</h3><p><a href="https://github.com/mindspore-lab/mindnlp/pull/1907">pull链接</a>这里面只有训练的部分结果，然后讲的是实现了bloom-3b在databricks-dolly-15k数据集上面的lora微调，不知道这个pytorch的训练过程是从哪来的，然后发现<strong>lora微调是一种微调方法</strong>，然后这里能够找到他fork的仓库，<strong>在mindNLP仓库是看不到改动的，需要去他提交pullrequst的fork的仓库，然后在这里点击可以到他fork的仓库</strong>，<a href="https://github.com/guyueyuan/mindnlp/tree/intern">fork的仓库</a>，同时可以看到这里fork后的仓库重新创建的分支叫做intern，然后查看commit改冲在哪里，找到发现在这里<a href="https://github.com/guyueyuan/mindnlp/tree/intern">mindnlp</a>/<a href="https://github.com/guyueyuan/mindnlp/tree/intern/llm">llm</a>/<a href="https://github.com/guyueyuan/mindnlp/tree/intern/llm/finetune">finetune</a>/<a href="https://github.com/guyueyuan/mindnlp/tree/intern/llm/finetune/bloom">bloom</a>/<a href="https://github.com/guyueyuan/mindnlp/tree/intern/llm/finetune/bloom/bloom-3b-qlora">bloom-3b-qlora</a>，也就是说任务是微调的话就把代码放在llm/finetune这个目录下，然后对比官方的mindspore的仓库发现确实这里pull requst之后就没有合进去<a href="https://github.com/mindspore-lab/mindnlp/tree/master">mindnlp</a>/<a href="https://github.com/mindspore-lab/mindnlp/tree/master/llm">llm</a>/<a href="https://github.com/mindspore-lab/mindnlp/tree/master/llm/finetune">finetune</a>/bloom</p><p>。总结就是这是提交代码的方法。</p><p>然后这个mindNLP做的是什么？这里面有模型和训练好的参数，clone到本地之后可以用，其中的开源的模型，是华为自己开发的，然后提供了lora和peft微调的工具，之后我们就可以基于这个mindNLP进行操作，和他功能类似的还有huggingface 的transform库</p><ul><li><strong>LoRA</strong> 是一种通过低秩分解实现参数高效微调的技术。</li><li><strong>PEFT</strong> 是一类参数高效微调技术的统称，包括 LoRA、Adapter、Prefix Tuning 等。</li><li>在实际应用中，LoRA 是最常用的 PEFT 方法之一，适合大模型的微调任务。如果你需要快速实现参数高效微调，可以使用 Hugging Face 的 <code>peft</code> 库，结合 LoRA 或其他 PEFT 方法。</li></ul><h3 id="如何进行模型微调">如何进行模型微调</h3><p><a href="https://www.mindspore.cn/tutorials/zh-CN/r1.3/intermediate/image_and_video/fine_tune.html">分割网络MaskRCNN微调，这个好</a></p><p><a href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/cv_mobilenetv2_fine_tune.html">MobileNetV2微调</a></p><p>从头开始训练网络，需要消耗大量的时间与计算能力，模型容易陷入局部极小值和过拟合。</p><p>大部分任务都会选择预训练模型，在其上做微调（也称为Fine Tune）。预训练模型选择的常见的OpenImage、ImageNet、VOC、COCO等公开大型数据集</p><p>不同数据集和任务中特征提取层（卷积层）分布趋于一致，但是特征向量的组合（全连接层）不相同，分类数量（全连接层output_size）通常也不一致。</p><ul><li>在微调时，只加载与训练特征提取层参数，不加载与训练全连接层参数；</li><li>在微调训练模式下，需要将预训练模型加载入<code>backbone_net</code>子网络，并且冻结<code>backbone_net</code>中的参数， param.requires_grad = False，不参与训练。</li><li>在微调与初始训练时，加载与训练 特征提取层参数与全连接层参数。</li></ul><p>根据微调的参数占比分为：</p><ol><li>全量微调（Full Fine-Tuning）</li></ol><p>全量微调利用特定任务数据调整预训练模型的所有参数，以充分适应新任务。它依赖大规模计算资源，但能有效利用预训练模型的通用特征。</p><ol start="2"><li>参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）</li></ol><p>PEFT旨在通过最小化微调参数数量和计算复杂度，实现高效的迁移学习。它仅更新模型中的部分参数，显著降低训练时间和成本，适用于计算资源有限的情况。PEFT技术包括Prefix Tuning、Prompt Tuning、Adapter Tuning等多种方法，可根据任务和模型需求灵活选择。</p><pre><code>Prefix Tuning    方法：在输入前添加可学习的virtual tokens作为Prefix。    特点：仅更新Prefix参数，Transformer其他部分固定。    优点：减少需要更新的参数数量，提高训练效率。Prompt Tuning    方法：在输入层加入prompt tokens。    特点：简化版的Prefix Tuning，无需MLP调整。    优点：随着模型规模增大，效果接近full fine-tuning。P-Tuning    方法：将Prompt转换为可学习的Embedding层，并用MLP+LSTM处理。    特点：解决Prompt构造对下游任务效果的影响。    优点：提供更大的灵活性和更强的表示能力。P-Tuning v2    方法：在多层加入Prompt tokens。    特点：增加可学习参数数量，对模型预测产生更直接影响。    优点：在不同任务和模型规模上实现更好的性能。Adapter Tuning    方法：设计Adapter结构并嵌入Transformer中。    特点：仅对新增的Adapter结构进行微调，原模型参数固定。    优点：保持高效性的同时引入少量额外参数。LoRA    方法：在矩阵相乘模块中引入低秩矩阵来模拟full fine-tuning。    特点：更新语言模型中的关键低秩维度。    优点：实现高效的参数调整，降低计算复杂度。</code></pre><h3 id="因果语言模型-causal-language-model-clm"><strong>因果语言模型（Causal Language Model, CLM）</strong></h3><h4 id="概念">概念</h4><p>因果语言模型是一种生成式模型，用于预测序列中下一个词（或 token）的概率分布。它的特点是：</p><ul><li><strong>自回归（Autoregressive）</strong>：模型根据前面的词生成后面的词，每次生成一个词。</li><li><strong>单向上下文</strong>：模型只能利用当前词之前的上下文信息，而不能利用后面的信息。</li></ul><h4 id="典型应用">典型应用</h4><ul><li><strong>文本生成</strong>：如故事生成、对话生成、代码生成等。</li><li><strong>语言建模</strong>：计算一段文本的概率，或生成符合语言规律的文本。</li></ul><h4 id="示例">示例</h4><ul><li>给定输入序列 <code>[&quot;I&quot;, &quot;love&quot;, &quot;to&quot;]</code>，模型会预测下一个词可能是 <code>&quot;eat&quot;</code>、<code>&quot;play&quot;</code> 等。</li></ul><h4 id="常见模型">常见模型</h4><ul><li><strong>GPT 系列</strong>（如 GPT-2、GPT-3）：OpenAI 开发的因果语言模型。</li><li><strong>Bloom</strong>：BigScience 开发的多语言因果语言模型。</li><li><strong>LLaMA</strong>：Meta 开发的高效因果语言模型。</li></ul><h3 id="分词器-tokenizer"><strong>分词器（Tokenizer）</strong></h3><h4 id="概念">概念</h4><p>分词器是将原始文本转换为模型可以理解的输入格式的工具。它的主要功能包括：</p><ul><li><strong>分词（Tokenization）</strong>：将文本分割成词或子词（subword）。</li><li><strong>编码（Encoding）</strong>：将分词后的结果转换为模型输入的数字 ID（<code>input_ids</code>）。</li><li><strong>解码（Decoding）</strong>：将模型输出的数字 ID 转换回文本。</li></ul><h4 id="分词方式">分词方式</h4><ol><li><p><strong>词级别分词</strong>：</p><ul><li>将文本按空格或标点符号分割成词。</li><li>例如：<code>&quot;I love NLP&quot;</code> → <code>[&quot;I&quot;, &quot;love&quot;, &quot;NLP&quot;]</code>。</li></ul></li><li><p><strong>子词级别分词</strong>：</p><ul><li>将词进一步分割为更小的子词单元，以解决未登录词（OOV）问题。</li><li>例如：<code>&quot;unhappiness&quot;</code> → <code>[&quot;un&quot;, &quot;happiness&quot;]</code>。</li></ul></li><li><p><strong>字符级别分词</strong>：</p><ul><li>将文本分割为单个字符。</li><li>例如：<code>&quot;NLP&quot;</code> → <code>[&quot;N&quot;, &quot;L&quot;, &quot;P&quot;]</code>。</li></ul></li></ol><h4 id="常见分词器">常见分词器</h4><ul><li><strong>Byte-Pair Encoding (BPE)</strong>：如 GPT 系列使用的分词器。</li><li><strong>WordPiece</strong>：如 BERT 使用的分词器。</li><li><strong>SentencePiece</strong>：如 Bloom 和 LLaMA 使用的分词器。</li></ul><hr><h4 id="一个模型对应一个分词器？"><strong>一个模型对应一个分词器？</strong></h4><p><strong>模型和分词器的匹配</strong>：一个模型通常对应一个特定的分词器，分词器的词汇表和分词方式必须与模型一致。是的，<strong>一个模型通常对应一个特定的分词器</strong>。原因如下：</p><h4 id="1-分词器和模型的匹配">（1）分词器和模型的匹配</h4><ul><li>分词器的分词方式和词汇表（vocabulary）必须与模型训练时使用的分词器一致。</li><li>如果分词器不匹配，模型可能无法正确理解输入，导致性能下降。</li></ul><h4 id="2-词汇表的一致性">（2）词汇表的一致性</h4><ul><li>模型的输入是分词器生成的 <code>input_ids</code>，这些 ID 是基于分词器的词汇表映射的。</li><li>如果分词器的词汇表与模型不匹配，<code>input_ids</code> 的映射会出错。</li></ul><h4 id="3-特殊-token-的处理">（3）特殊 token 的处理</h4><ul><li>分词器会添加一些特殊 token（如 <code>[CLS]</code>、<code>[SEP]</code>、<code>[PAD]</code>），这些 token 在模型中有特定的含义。</li><li>如果分词器不匹配，特殊 token 的处理可能会出错。</li></ul><h4 id="示例">示例</h4><ul><li><strong>Bloom 模型</strong>：必须使用 <code>BloomTokenizerFast</code> 或 <code>BloomTokenizer</code>。</li><li><strong>GPT 模型</strong>：必须使用 <code>GPT2Tokenizer</code> 或 <code>GPT2TokenizerFast</code>。</li><li><strong>BERT 模型</strong>：必须使用 <code>BertTokenizer</code> 或 <code>BertTokenizerFast</code>。</li></ul><hr><h4 id="如何加载模型和分词器？"><strong>如何加载模型和分词器？</strong></h4><p>以 Hugging Face 的 <code>transformers</code> 库为例：</p><h4 id="加载模型和分词器">加载模型和分词器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型和分词器</span></span><br><span class="line">model_name = <span class="string">&quot;bigscience/bloom-560m&quot;</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&quot;bert-base-cased&quot;</span>)</span><br><span class="line">tokenizer(<span class="string">&quot;Using a Transformer network is simple&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;&#x27;input_ids&#x27;: [101, 7993, 170, 11303, 1200, 2443, 1110, 3014, 102],</span></span><br><span class="line"><span class="string"> &#x27;token_type_ids&#x27;: [0, 0, 0, 0, 0, 0, 0, 0, 0],</span></span><br><span class="line"><span class="string"> &#x27;attention_mask&#x27;: [1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="使用分词器">使用分词器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分词和编码</span></span><br><span class="line">text = <span class="string">&quot;I love NLP&quot;</span></span><br><span class="line">inputs = tokenizer(text, return_tensors=<span class="string">&quot;pt&quot;</span>)  <span class="comment"># 返回 PyTorch 张量</span></span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br><span class="line"><span class="comment"># 输出：&#123;&#x27;input_ids&#x27;: tensor([[ 100,  123, 4567]]), &#x27;attention_mask&#x27;: tensor([[1, 1, 1]])&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码</span></span><br><span class="line">output_ids = model.generate(inputs[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line">output_text = tokenizer.decode(output_ids[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(output_text)</span><br></pre></td></tr></table></figure><hr><h2 id="开始实践">开始实践</h2><p><strong>支持微调的模型和数据集大型语言模型通过微调可以适应不同任务，而中文微调数据集为模型在中文领域的应用提供了关键资源。</strong></p><p><img src="MindNLP-bigbird_pegasus%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/0441ccee9040588a9eadb3f6562eeefc.png" alt="图片"></p><p>常用中文微调数据集可能包括：</p><pre><code>中文问答数据集（如CMRC 2018、DRCD等），用于训练问答系统。中文情感分析数据集（如ChnSentiCorp、Fudan News等），用于训练情感分类模型。中文文本相似度数据集（如LCQMC、BQ Corpus等），用于训练句子对匹配和相似度判断任务。中文摘要生成数据集（如LCSTS、NLPCC等），用于训练文本摘要生成模型。中文对话数据集（如LCCC、ECDT等），用于训练聊天机器人或对话系统。</code></pre><p><a href="https://hugging-face.cn/docs/transformers/model_doc/bigbird_pegasus#google_vignette">这里有一个huggingface的文档，特别好</a></p><p><a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/dataset.html">mindNLP中有的数据集</a></p><p>这个huggingface支持各种任务</p><h4 id="1-序列分类任务-sequence-classification"><strong>(1) 序列分类任务（Sequence Classification）</strong></h4><ul><li><strong>特点</strong>：将文本分类到预定义的类别（如情感分类、垃圾邮件检测），输出层仅需添加一个分类头，结构简单。</li><li><strong>优势</strong>：<ul><li><strong>计算量小</strong>：仅需调整分类头参数，训练速度快。</li><li><strong>数据要求低</strong>：通常需要较少的标注数据即可达到较好效果。</li><li><strong>显存占用低</strong>：输入文本可截断或填充至固定长度，资源消耗可控911。</li></ul></li><li><strong>推荐场景</strong>：入门级任务，适合快速验证模型微调流程。</li></ul><h4 id="2-条件生成任务-conditional-generation"><strong>(2) 条件生成任务（Conditional Generation）</strong></h4><ul><li><strong>特点</strong>：生成与输入相关的文本（如摘要、翻译），需处理长序列依赖。</li><li><strong>挑战</strong>：<ul><li><strong>自回归生成</strong>：逐词生成需多次前向计算，训练和推理速度较慢。</li><li><strong>显存占用高</strong>：长文本输入需更大的上下文窗口，内存消耗显著增加38。</li></ul></li><li><strong>适用场景</strong>：需生成连贯长文本的任务（如文档摘要）。</li></ul><h4 id="3-问题回答任务-question-answering"><strong>(3) 问题回答任务（Question Answering）</strong></h4><ul><li><strong>特点</strong>：从长文本中定位答案，需同时处理问题和上下文。</li><li><strong>复杂度</strong>：<ul><li><strong>长文本处理</strong>：BigBird的稀疏注意力机制适合长文本，但训练需处理问答对间的复杂交互，计算量较大810。</li><li><strong>数据标注要求高</strong>：需精确的答案位置标注（如SQuAD数据集）。</li></ul></li></ul><h4 id="4-causallm任务-因果语言建模"><strong>(4) CausalLM任务（因果语言建模）</strong></h4><ul><li><strong>特点</strong>：预测下一个词（自回归生成），适用于文本续写或对话生成。</li><li><strong>缺点</strong>：<ul><li><strong>训练效率低</strong>：需处理完整序列的生成，显存和计算资源消耗高。</li><li><strong>长文本挑战</strong>：需结合BigBird的稀疏注意力优化，但整体速度仍低于分类任务810。</li></ul></li></ul><hr><h3 id="2-任务推荐与数据集选择"><strong>2. 任务推荐与数据集选择</strong></h3><h4 id="推荐任务：序列分类任务"><strong>推荐任务：序列分类任务</strong></h4><ul><li><strong>简单性</strong>：仅需调整分类头，无需复杂生成逻辑。</li><li><strong>速度优势</strong>：训练速度快，显存占用低（例如，使用LoRA微调时显存可控制在42G内）9。</li><li><strong>数据集推荐</strong>：<ul><li><strong>IMDb影评分类</strong>：二分类任务（正面/负面情感），适合验证模型基础能力11。</li><li><strong>SMSSpamCollection</strong>：垃圾短信分类（二分类），数据量小（747条/类），适合快速实验11。</li><li><strong>GLUE基准的子任务（如CoLA、MRPC）</strong>：标准化评测集，适合对比模型性能12。</li></ul></li></ul><h4 id="其他任务备选数据集"><strong>其他任务备选数据集</strong></h4><ul><li><strong>条件生成</strong>：CNN/Daily Mail（长文本摘要任务）3。</li><li><strong>问题回答</strong>：SQuAD（斯坦福问答数据集）8。</li><li><strong>CausalLM</strong>：WikiText-103（长文本语言建模）10。</li></ul><h1>模型微调总结</h1><h4 id="开源实习-peft-ia3-seq2seq模型微调"><a href="https://gitee.com/mindspore/community/issues/IAN28H">【开源实习】peft_ia3_seq2seq模型微调</a></h4><p>这个实习的任务是用peft库中的ia3方法，对seq2seq进行微调。代码放在mindnlp/llm/peft]/ia3/seq_2_seq</p><p>然后写了两个ipynb，一个是pytoch的利用transformers库，并且规定使用GPU，另一个使用mindspore，没指定设备，然后写了一个https://hf-mirror.com用于获得数据集。最后有一个md写了mindNLP的准确率没有pytorch的高</p><p>IA3（论文：<strong>Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</strong>），通过学习向量来对激活层加权进行缩放，从而获得更强的性能，同时仅引入相对少量的新参数，如下图左边所示，它的诞生背景是为了改进 LoRA。</p><h4 id="开源实习-peft-lora-seq2seq模型微调"><a href="https://gitee.com/mindspore/community/issues/IAN29M">【开源实习】peft_lora_seq2seq模型微调</a></h4><p>这个这里没有写位置，但是找到在<a href="https://github.com/mindspore-lab/mindnlp/tree/master">mindnlp</a>/<a href="https://github.com/mindspore-lab/mindnlp/tree/master/llm">llm</a>/<a href="https://github.com/mindspore-lab/mindnlp/tree/master/llm/peft">peft</a>/dora/，感觉可抄</p><p>原来任务底下提供了huggingface的微调的文件参考，使用transformers和对应的微调方法进行测试的</p><h4 id="开源实习-dna-lm模型微调"><a href="https://gitee.com/mindspore/community/issues/IAN247">【开源实习】dna_lm模型微调</a></h4><p>利用 PEFT 文库中的参数高效微调技术 （PEFT） 来微调 DNA 语言模型 （DNA-LM）。微调后的 DNA-LM 将用于解决核苷酸基准数据集中的任务。</p><h4 id="开源实习-dora-finetuning模型微调"><a href="https://gitee.com/mindspore/community/issues/IAN239">【开源实习】dora_finetuning模型微调</a></h4><p>Lora想必大家都熟悉，本质上就是<strong>把大矩阵拆成两个小矩阵的乘法</strong>.而<a href="https://zhida.zhihu.com/search?content_id=240315419&amp;content_type=Article&amp;match_order=1&amp;q=DoRA&amp;zhida_source=entity">DoRA</a>（Weight-Decomposed Low-Rank Adaptation）的主要思想是<strong>将预训练权重分解为幅度（magnitude）和方向（direction），并利用LoRA来微调方向矩阵</strong></p><p><a href="https://gitee.com/mindspore/community/issues/IAN1ZS">【开源实习】image_classification_timm_peft_lora模型微调</a></p><p>使用 PEFT 的 🤗 LoRA 来微调图像分类模型，只需使用模型原始可训练参数的 0.77%。LoRA 将低秩的 “update matrices” 添加到底层模型的某些块（在本例中为 attention blocks），并且仅在微调期间训练这些矩阵。在推理过程中，这些更新矩阵将与原始模型参数合并。</p><p><a href="https://gitee.com/mindspore/community/issues/IAN1W9">【开源实习】multilayer_perceptron_lora模型微调</a></p><p>展示了如何将 LoRA  应用于简单的多层感知器，并使用它来训练模型以执行分类任务。PEFT 支持微调任何类型的模型，只要支持的层是支持的。例如，该模型不必是 transformers 模型。</p><p><a href="https://gitee.com/mindspore/community/issues/IAN04F">【开源实习】sequence_classification/fourier ft模型微调</a></p><p>使用 FourierFT 在序列分类任务上微调 Roberta （base）。</p><h2 id="以上是上一期的-主要针对peft库和对应的huggingface例程进行测试peft">以上是上一期的，主要针对PEFT库和对应的huggingface例程进行测试PEFT</h2><h2 id="以下是上一期的-主要针对新的模型进行测试微调">以下是上一期的，主要针对新的模型进行测试微调</h2><h2 id="开源实习-bert模型微调"><a href="https://gitee.com/mindspore/community/issues/IAUP1T">【开源实习】bert模型微调</a></h2><p><a href="https://github.com/mindspore-lab/mindnlp/compare/master...Alemax067:mindnlp:%E3%80%90%E5%BC%80%E6%BA%90%E5%AE%9E%E4%B9%A0%E3%80%91bert%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83">commit记录，但是这里看不到ipynb</a></p><p><a href="https://github.com/Alemax067/mindnlp/blob/%E3%80%90%E5%BC%80%E6%BA%90%E5%AE%9E%E4%B9%A0%E3%80%91bert%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/llm/finetune/bert/bert_finetune_with_Stanford_Sentiment_Tree_Bank.ipynb">看这里吧</a></p><p>修改在llm/finetune/bert/bert_for_classification.py</p><p>给出这样的结果Results</p><h3 id="my-results-on-mindspore">my results on mindspore</h3><table><thead><tr><th>Model Variant</th><th>Accuracy on Dev Set</th></tr></thead><tbody><tr><td>BERT (no finetuning)</td><td>81.25%</td></tr><tr><td>BERT (with finetuning)</td><td>90.07%</td></tr></tbody></table><p>requirements:</p><ul><li>Ascend 910B</li><li>Python 3.9</li><li>MindSpore 2.3.1</li><li>MindNLP 0.4.1</li></ul><h3 id="my-results-on-pytorch">my results on pytorch</h3><table><thead><tr><th>Model Variant</th><th>Accuracy on Dev Set</th></tr></thead><tbody><tr><td>BERT (no finetuning)</td><td>81.03%</td></tr><tr><td>BERT (with finetuning)</td><td>89.84%</td></tr></tbody></table><p>requirements:</p><ul><li>GPU 1080ti</li><li>CUDA 11.1.1</li><li>Python 3.9</li><li>Pytorch 1.10.2</li><li>Transformers 4.45.2</li></ul><h3 id="original-results-from-the-repo">Original results from the repo</h3><table><thead><tr><th>Model Variant</th><th>Accuracy on Dev Set</th></tr></thead><tbody><tr><td>BERT (no finetuning)</td><td>82.59%</td></tr><tr><td>BERT (with finetuning)</td><td>88.29%</td></tr></tbody></table><p>requirements:</p><ul><li>Python 3.6</li><li>Pytorch 1.2.0</li><li>Transformers 2.0.0</li></ul><h2 id="开源实习-blip模型微调"><a href="https://gitee.com/mindspore/community/issues/IAUPL0">【开源实习】blip模型微调</a></h2><p><a href="https://github.com/Alemax067/mindnlp/tree/%E3%80%90%E5%BC%80%E6%BA%90%E5%AE%9E%E4%B9%A0%E3%80%91blip%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/llm/finetune/blip">看这里吧</a></p><p>这个没有写他的transformers的结果来源，而是只有一个mindspore的ipynb，应该还需要一个pytorch的，这里应该是他找到了但是没有贴上来，毕竟把一个pytorch的ipynb放在mindspore的仓库里有点奇怪</p><p>后来去问他</p><p><a href="https://github.com/eeshashetty/captionary-api/blob/main/blip_finetune.ipynb">github的pytorch参考在这，是他自己艘的，然后改动到其他数据集</a></p><p>如果没有这样的pytorch微调的，就自己挑一个数据集用mindspore和pytorchMindspore分别进行训练和评估</p><h3 id="my-results-on-mindspore">my results on mindspore</h3><p>20 epochs:</p><ul><li>train loss: 0.0132</li><li>val loss: 0.0126</li></ul><p>requirements:</p><ul><li>Ascend 910B</li><li>Python 3.9</li><li>MindSpore 2.3.1</li><li>MindNLP 0.4.1</li></ul><h3 id="my-results-on-pytorch">my results on pytorch</h3><p>10 epochs:</p><ul><li>train loss: 0.0135</li><li>val loss: 0.0125</li></ul><p>requirements:</p><ul><li>GPU 1080ti</li><li>CUDA 11.1.1</li><li>Python 3.9</li><li>Pytorch 1.10.2</li><li>Transformers 4.45.2</li></ul><h3 id="original-results-from-the-repo">Original results from the repo</h3><p>20 epochs:</p><ul><li>train loss: 1.3579</li><li>val loss: 1.3584</li></ul><h2 id="开源实习-bloom模型微调"><a href="https://gitee.com/mindspore/community/issues/IAUPL8">【开源实习】bloom模型微调</a></h2><p>实现了bloom-3b在databricks-dolly-15k数据集上面的lora微调，这个文件也很不清晰啊，pytorch的不知道在那</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;MindNLP模型微调超级笔记&lt;/h1&gt;
&lt;h2 id=&quot;乱七八糟的学习参考&quot;&gt;乱七八糟的学习参考&lt;/h2&gt;
&lt;h3 id=&quot;已完成的bloom模型微调&quot;&gt;已完成的bloom模型微调&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/mindspor</summary>
      
    
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="mindspore实习" scheme="http://outbreak-sen.github.io/tags/mindspore%E5%AE%9E%E4%B9%A0/"/>
    
    <category term="mindNLP" scheme="http://outbreak-sen.github.io/tags/mindNLP/"/>
    
  </entry>
  
  <entry>
    <title>NLP任务微调笔记</title>
    <link href="http://outbreak-sen.github.io/2025/02/26/NLP%E4%BB%BB%E5%8A%A1%E5%BE%AE%E8%B0%83%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://outbreak-sen.github.io/2025/02/26/NLP%E4%BB%BB%E5%8A%A1%E5%BE%AE%E8%B0%83%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2025-02-26T07:01:44.000Z</published>
    <updated>2025-03-19T09:15:22.884Z</updated>
    
    <content type="html"><![CDATA[<h1>NLP任务微调笔记</h1><p>NLP数据集没有像CV一样大量标号的数据集，所以NLP一般是自监督的，有两种自监督的模型：</p><ul><li><p>LM：语言模型，预测下一个词</p></li><li><p>MLM：带掩码的语言模型，完形填空</p></li></ul><p>每种预训练模型基于不同的技术也分为两种：</p><ul><li><p>Word embddings：</p><ul><li>LSTM之类的传统的</li></ul></li><li><p>Transformer based pretrained model：</p><ul><li>Bert：基于encoder，针对Bert的微调，把最后一层重新设计随机初始化，做分类只需要拿出一个然后训练，做QA只需要输出答案的位置</li><li>GPT：基于decoder</li><li>T5：基于encoder和decode</li></ul></li></ul><h2 id="如何做分词">如何做分词</h2><p><strong>数据集一般是用Unicode进行编码，是对世界所有语言的一种编码，但是我们需要将这些文字变成数字编码的向量，就需要分词</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;我是一个用于测试输出unicode编码的文字&quot;.encode(&#x27;utf-8&#x27;)#可以看到每个字对应的unicode编码 </span><br></pre></td></tr></table></figure><p>分词Tokenizer：就是把文字变成数字，数字就是token，每个词变成一个编号</p><h3 id="tokenizer分类">Tokenizer分类</h3><p>Tokenizer有多种，其中subword-based是现在最常用的</p><ol><li>Word-based Toeknizers：把每个词一一对应分开，然后将例如“don‘t”引入特殊规则划分为“do”和“not”，这就导致虽然符合人的自然语言知觉，但是规则太多，此表很大，所以一般限制到一万个词，其余的词标记为未知</li><li>Character-baesd ：把一个单词变成一个个字母，love变成l,o,v,e，这样token序列长，单个token信息量低模型性能差，中文的词表更长。</li><li>subword-based Tokenizer：这个合理，dog就是dog，但是dogs为dog+s。tokenization变成token和ization</li></ol><h3 id="常用的subword-tokenizer">常用的subword tokenizer</h3><p>然后subword tokenizer也分为很多类</p><ol><li>Byte-pair encoding（GPT使用的p50k）：BPE方法，首先进行词频统计，然后构建基本此表，根据词表切分词，统计相邻token同时出现的频率，取出新的频率高的组合token替换原先的小token，这样就可以构成新的词表，最后就会获得一个充满高频词单元的词表。看<a href="https://www.bilibili.com/video/BV1Fc411C7sz/?spm_id_from=333.337.search-card.all.click&amp;vd_source=fab8d1d67ff3f15a964074b193e057da">视频21分</a>了解。有个gihub仓库miniBPE不错。同时还有一些出现也很高但是组合到一起没有意义的，那可以用加个正则表达删除这种组合</li><li>Btye-level BPE（GPT2使用的）：BPE的词表太大，改进的方法将字节byte看作基本token</li><li>wordpiece：和BPE类似，每个单词除了第一个字母都会加一个#作为前缀，然后利用联合概率进行token合并，反正就更科学了</li><li>sentencePiece（google）：</li><li>unigram（Bigbird，T5，XLNet）：初始化一个很大的词表，尝试删减然后计算unigram loss，然后使unigramloss下降的不大就山调，逐步删减</li></ol><p><strong>每个模型都有对应的分词器，每个模型的tokenizer不一样，不能随便换</strong>，可查看https://huggingface.co/spaces/Xenova/the-tokenizer-playground看tokenizer的分词效果</p><img src="./NLP任务微调学习笔记/image-20250303114108026.png" alt="image-20250303114108026" style="zoom:50%;" /><h2 id="构建词表">构建词表</h2><p><strong>词表（Vocabulary）是通过使用 Tokenizer 对训练语料进行处理后获得的词（或子词、字符等）与 token 的对应关系。词表中已经定义了 token 与 ID 的映射关系。</strong></p><p><strong>如果你的模型微调任务中已经有一个预训练的 对应Tokenizer，那么这个 Tokenizer 其实包含了对应的词表，那么不需要重新构建词表！</strong></p><p>预训练的 Tokenizer 通常是在大规模语料上训练的，已经包含了足够大的词表（例如 30,000 到 100,000 个 token）。</p><p><strong>如果你想训练一个新模型，但是没有tokenizer，那么就可以使用词表</strong>下面介绍怎么使用词表：</p><ul><li>使用预训练Embedding的词表，如Glove，word2Vec<ul><li>GloVe 的词表主要用于训练词向量（word embeddings），而不是直接用于模型的输入。</li></ul></li><li>使用数据集统计词表：使用from_dataset函数从数据集构建一个Vocab词表</li><li>使用Subword训练得到的词表，直接就获得了，不需要训练获得词表</li></ul><p>如何使用别人训练的词表word2Vec生成input</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"><span class="comment"># 加载预训练的 Word2Vec 模型</span></span><br><span class="line">word2vec_model = KeyedVectors.load_word2vec_format(<span class="string">&quot;path/to/word2vec.bin&quot;</span>, binary=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 获取词表</span></span><br><span class="line">vocab = word2vec_model.key_to_index  <span class="comment"># 单词到索引的映射</span></span><br><span class="line">word_vectors = word2vec_model.vectors  <span class="comment"># 词向量矩阵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 简单的空格分词，转换为小写</span></span><br><span class="line">    <span class="keyword">return</span> text.lower().split()python</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据集</span></span><br><span class="line">data = [</span><br><span class="line">    <span class="string">&quot;I love NLP.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This is a test sentence.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;How are you?&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 对数据集中的每个句子进行分词</span></span><br><span class="line">tokenized_data = [tokenize(text) <span class="keyword">for</span> text <span class="keyword">in</span> data]</span><br><span class="line"><span class="built_in">print</span>(tokenized_data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 获取词向量的维度</span></span><br><span class="line">embedding_dim = word_vectors.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 将单词映射到词向量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">map_tokens_to_vectors</span>(<span class="params">tokens, vocab, word_vectors, embedding_dim</span>):</span><br><span class="line">    vectors = []</span><br><span class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> tokens:</span><br><span class="line">        <span class="keyword">if</span> token <span class="keyword">in</span> vocab:</span><br><span class="line">            <span class="comment"># 如果单词在词表中，获取对应的词向量</span></span><br><span class="line">            vectors.append(word_vectors[vocab[token]])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果单词不在词表中，使用全零向量</span></span><br><span class="line">            vectors.append(np.zeros(embedding_dim))</span><br><span class="line">    <span class="keyword">return</span> np.array(vectors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对分词后的数据进行映射</span></span><br><span class="line">vectorized_data = [map_tokens_to_vectors(tokens, vocab, word_vectors, embedding_dim) <span class="keyword">for</span> tokens <span class="keyword">in</span> tokenized_data]</span><br></pre></td></tr></table></figure><h2 id="如何embedding">如何embedding</h2><p>embedding：做完分词后获得是一堆数字，<strong>embedding现在都成为transformer算法，不用自己来写这部分数据预处理的一部分，所以不用写了</strong></p><p>Embedding layer的作用是将离散的 token ID 映射为连续的向量表示。这些向量通常是可训练的，模型会在训练过程中学习如何将每个 token ID 映射到一个有意义的向量空间中。比如说一个句子里的一个词的向量 是 这个词的token + 词的位置编码</p><img src="./NLP任务微调学习笔记/image-20250303113929963.png" alt="image-20250303113929963" style="zoom:50%;" /><h1>将数据变为数据集（太重点的）</h1><p>AI需要的是问答对数据集，也就是一个数据集里要有问题和答案</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">‘instruction’:这里要有问题</span><br><span class="line">‘input’:这里要有一个数据,</span><br><span class="line">‘output’:这里需要获得输出是什么</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>有各种各样的数据集，然后需要用在不同的任务中，其中任务可以包括以下几种，基础模型都是bigbirdpegasus，但是是用于不同任务的</strong></p><table><thead><tr><th>任务类型</th><th>数据需要包含的集列</th></tr></thead><tbody><tr><td><strong>BigBirdPegasusForConditionalGeneration</strong></td><td><code>input_text</code>, <code>target_text</code></td></tr><tr><td><strong>BigBirdPegasusForSequenceClassification</strong></td><td><code>input_text</code>, <code>label</code></td></tr><tr><td><strong>BigBirdPegasusForQuestionAnswering</strong></td><td><code>context</code>, <code>question</code>, <code>answer</code></td></tr><tr><td><strong>BigBirdPegasusDecoderWrapper</strong></td><td><code>input_text</code>, <code>target_text</code></td></tr><tr><td><strong>BigBirdPegasusForCausalLM因果语言模型（CLM）</strong></td><td><code>input_text</code>, <code>target_text</code>，下一个词是target_text</td></tr><tr><td><strong>Masked Language Modeling掩码语言模型（MLM，比如bert）</strong></td><td><code>input_text</code>, <code>target_text</code>，缺少的词是target_text</td></tr></tbody></table><p>然后<strong>每一种任务的模型需要不同类型的数据集进行训练，需要数据集有对应不同的columes，比如说BigBirdPegasusForConditionalGeneration这个条件生成任务的模型需要数据集包括输入文本(input text)和目标文本(target text)，具体格式如下。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = [</span><br><span class="line">    &#123;&quot;input_text&quot;: &quot;The quick brown fox jumps over the lazy dog.&quot;, &quot;target_text&quot;: &quot;The fox is quick.&quot;&#125;,</span><br><span class="line">    &#123;&quot;input_text&quot;: &quot;In a galaxy far, far away...&quot;, &quot;target_text&quot;: &quot;A long time ago...&quot;&#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><strong>有一些数据集是已经针对这些任务特化好的，比如说SQuAD (Stanford Question Answering Dataset)是针对ConditionalGeneration任务的，不过需要将这个数据集变成我们需要的格式。SQuAD 数据集中的一个例子如下</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;data&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;title&quot;: &quot;Super_Bowl_50&quot;,</span><br><span class="line">            &quot;paragraphs&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;context&quot;: &quot;Super Bowl 50 was an American football game...&quot;,</span><br><span class="line">                    &quot;qas&quot;: [</span><br><span class="line">                        &#123;</span><br><span class="line">                            &quot;question&quot;: &quot;Where did Super Bowl 50 take place?&quot;,</span><br><span class="line">                            &quot;id&quot;: &quot;56be4db0acb8001400a502ec&quot;,</span><br><span class="line">                            &quot;answers&quot;: [</span><br><span class="line">                                &#123;</span><br><span class="line">                                    &quot;text&quot;: &quot;Santa Clara, California&quot;,</span><br><span class="line">                                    &quot;answer_start&quot;: 269</span><br><span class="line">                                &#125;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>databricks-dolly-15k数据集是针微调任务的</strong>，牛逼吧，专门用于微调各种任务的，可以用于问答、分类、摘要各种任务，只需要你自己构造好。数据格式如下:</p><p>按照你的需要变成不同的格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;instruction&#x27;</span>, <span class="string">&#x27;context&#x27;</span>, <span class="string">&#x27;response&#x27;</span>, <span class="string">&#x27;category&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">15011</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment"># instruction用户的指令或任务描述（例如：“写一篇关于气候变化的短文。”）。</span></span><br><span class="line"><span class="comment"># context可选的上下文信息，为模型提供额外的背景知识（例如：“气候变化是全球变暖的主要原因。”）。</span></span><br><span class="line"><span class="comment"># response模型应生成的理想响应（例如：“气候变化是当今世界面临的最大挑战之一...”）。。</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;instruction&quot;</span>: <span class="string">&quot;写一篇关于气候变化的短文。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;context&quot;</span>: <span class="string">&quot;气候变化是全球变暖的主要原因。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;response&quot;</span>: <span class="string">&quot;气候变化是当今世界面临的最大挑战之一。全球变暖导致极端天气事件频发，海平面上升，生态系统受到严重威胁。为了应对气候变化，各国需要采取紧急措施，减少温室气体排放，推动可持续发展。&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>但是还有一些数据集是非特化的</strong>，需要自己构建成需要的数据集格式，比如wikitext只是wiki上的文字一段一段的，这种就根需要自己对数据集进行特化处理</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;text&#x27;: &quot; The ship was assigned to the Austro @-@ Hungarian Fleet &#x27;s 1st Battle Squadron after her 1911 commissioning . In 1912 , Zrínyi and her two sister ships conducted two training cruises into the eastern Mediterranean Sea . On the second cruise into the Aegean Sea , conducted from November to December , Zrínyi and her sister ships were accompanied by the cruiser SMS Admiral Spaun and a pair of destroyers . After returning to Pola , the entire fleet mobilized for possible hostilities , as tensions flared in the Balkans . \n&quot;&#125;</span><br></pre></td></tr></table></figure><h2 id="数据集特化处理工具">数据集特化处理工具</h2><p>我们完全可以自己把一个非特化的数据集转化为特化的数据集，比如把wikitext的每一句话拿出来，然后一句话的最后一个词就是要获得的结果，作为target_ids。但是有更好的工具可以直接把数据集转化为想要的特化的数据集比如dataset中的**<code>DataCollatorForLanguageModeling</code>**</p><p><code>DataCollatorForLanguageModeling</code>** 是 Hugging Face 提供的一个工具，专门用于处理语言模型训练数据。它可以自动将数据集（如 Wikitext-103-v1）划分为 <code>input_ids</code>、<code>attention_mask</code> 和 <code>labels</code>，并且支持因果语言模型（Causal Language Model, CLM）和掩码语言模型（Masked Language Model, MLM）的训练。</p><h3 id="datacollatorforlanguagemodeling-的作用"><strong><code>DataCollatorForLanguageModeling</code> 的作用</strong></h3><ol><li><strong>动态填充</strong>：将批次中的序列填充到相同长度。</li><li><strong>生成 <code>labels</code></strong>：对于因果语言模型，<code>labels</code> 是 <code>input_ids</code> 的偏移版本（即下一个 token 的预测目标）。</li><li><strong>支持 MLM</strong>：如果你使用的是掩码语言模型（如 BERT），它还可以随机掩码 token。</li><li>除了生成input_ids和target_ids之外，还会生成<code>attention_mask</code> ，指示哪些 token 是实际数据，哪些是填充 token。</li></ol><p>DataCollatorForLanguageModeling的工作原理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先已经有两句连续的话了</span></span><br><span class="line"><span class="comment">#  &quot;The quick brown fox&quot;</span></span><br><span class="line"><span class="comment">#     &quot;Jumps over the lazy dog&quot;</span></span><br><span class="line"><span class="comment"># CLM模型的作用是根据之前的文字生成下一个文字</span></span><br><span class="line"><span class="comment"># 首先经过tokenizer</span></span><br><span class="line">input_ids_1 = [<span class="number">1996</span>, <span class="number">4248</span>, <span class="number">2829</span>, <span class="number">4419</span>]  <span class="comment"># &quot;The quick brown fox&quot;</span></span><br><span class="line">input_ids_2 = [<span class="number">12987</span>, <span class="number">345</span>, <span class="number">1996</span>, <span class="number">1234</span>, <span class="number">2345</span>]  <span class="comment"># &quot;Jumps over the lazy dog&quot;</span></span><br><span class="line"><span class="comment"># 然后经过datacollatrorForlanguageodeling之后，-100是用来填充的，可以看到，这样label，也就是target_ids的变化是预测的下一句话</span></span><br><span class="line">input_ids = [</span><br><span class="line">    [<span class="number">1996</span>, <span class="number">4248</span>, <span class="number">2829</span>, <span class="number">4419</span>, -<span class="number">100</span>],  <span class="comment"># &quot;The quick brown fox&quot;</span></span><br><span class="line">    [<span class="number">12987</span>, <span class="number">345</span>, <span class="number">1996</span>, <span class="number">1234</span>, <span class="number">2345</span>]   <span class="comment"># &quot;Jumps over the lazy dog&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">labels = [</span><br><span class="line">    [<span class="number">4248</span>, <span class="number">2829</span>, <span class="number">4419</span>, -<span class="number">100</span>, -<span class="number">100</span>],  <span class="comment"># 预测下一个 token</span></span><br><span class="line">    [<span class="number">345</span>, <span class="number">1996</span>, <span class="number">1234</span>, <span class="number">2345</span>, -<span class="number">100</span>]    <span class="comment"># 预测下一个 token</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>下面讲解DataCollatorForLanguageModeling` 怎么调用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="comment"># 加载 Wikitext 数据集</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;wikitext&quot;</span>, <span class="string">&quot;wikitext-103-v1&quot;</span>)</span><br><span class="line"><span class="comment"># 过滤空行</span></span><br><span class="line">dataset = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x[<span class="string">&quot;text&quot;</span>].strip() != <span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorForLanguageModeling</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line"><span class="comment"># 对数据集进行 Tokenization</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">examples</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;text&quot;</span>], truncation=<span class="literal">True</span>, max_length=<span class="number">512</span>)</span><br><span class="line">tokenized_dataset = dataset.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>, remove_columns=[<span class="string">&quot;text&quot;</span>])</span><br><span class="line"><span class="comment"># 初始化 DataCollator</span></span><br><span class="line">data_collator = DataCollatorForLanguageModeling(</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    mlm=<span class="literal">False</span>,  <span class="comment"># 使用因果语言模型</span></span><br><span class="line">    return_tensors=<span class="string">&quot;pt&quot;</span>  <span class="comment"># 返回 PyTorch 张量</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后按理说可以用于训练，但是这里讲三个方式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 创建 DataLoader，这个DataLoader的作用是为了传入模型使用的，dataloader需要将数据划分为不同的batch，并且打乱顺序等</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    tokenized_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    batch_size=<span class="number">8</span>,</span><br><span class="line">    collate_fn=data_collator,</span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 可以不使用 DataLoader，直接将 Tokenizer 处理后的数据使用 DataCollatorForLanguageModeling 转换为模型训练所需的格式，然后进行训练。不过，这种方式通常适用于小规模数据集或自定义训练循环的场景。</span></span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">batches = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(tokenized_dataset[<span class="string">&quot;train&quot;</span>]), batch_size):</span><br><span class="line">    batch = tokenized_dataset[<span class="string">&quot;train&quot;</span>][i:i + batch_size]</span><br><span class="line">    batches.append(data_collator(batch[<span class="string">&quot;input_ids&quot;</span>]))</span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):  <span class="comment"># 训练 3 个 epoch</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> batches:</span><br><span class="line">        outputs = model(input_ids=batch[<span class="string">&quot;input_ids&quot;</span>], labels=batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loss: <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 如果你需要微调，也可以不使用dataloader，直接将DataCollatorForLanguageModeling处理过的数据传入trainer即可</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>除了 <strong><code>DataCollatorForLanguageModeling</code></strong>，huggingface的transformer还有许多其他 <strong>DataCollator</strong> 工具，可以根据任务需求将数据集转换为模型训练所需的格式。以下是一些常用的 DataCollator 及其适用场景：详细可看这个<a href="https://percent4.github.io/NLP%EF%BC%88%E4%B9%9D%E5%8D%81%E5%9B%9B%EF%BC%89transformers%E6%A8%A1%E5%9D%97%E4%B8%AD%E7%9A%84DataCollator/">各种datacollator</a></p><table><thead><tr><th>DataCollator 类型</th><th>适用任务</th></tr></thead><tbody><tr><td><code>DataCollatorWithPadding</code></td><td>变长序列任务（如文本分类）。</td></tr><tr><td><code>DataCollatorForTokenClassification</code></td><td>序列标注任务（如命名实体识别）。</td></tr><tr><td><code>DataCollatorForSeq2Seq</code></td><td>序列到序列任务（如机器翻译）。</td></tr><tr><td><code>DataCollatorForSOP</code></td><td>句子顺序预测任务（如 ALBERT）。</td></tr><tr><td><code>DataCollatorForWholeWordMask</code></td><td>全词掩码任务（如 BERT）。</td></tr><tr><td><code>DataCollatorForPermutationLanguageModeling</code></td><td>排列语言模型任务（如 XLNet）。</td></tr><tr><td><code>DataCollatorForNextSentencePrediction</code></td><td>下一句预测任务（如 BERT）。</td></tr><tr><td><code>DataCollatorForImageCaptioning</code></td><td>图像描述生成任务。</td></tr></tbody></table><p>也可以自己定义，继承DataCollator</p><p>Mindspore也有datacontrol的工具不过叫做mindspore.dataset.GeneratorDataset，并且需要自己定义，但是也没有transformers里面的工具智能</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def data_generator():</span><br><span class="line">    for i in range(100):</span><br><span class="line">        yield (np.random.randn(32, 32, 3), np.random.randint(0, 10)</span><br><span class="line"></span><br><span class="line">dataset = ds.GeneratorDataset(source=data_generator, column_names=[&quot;image&quot;, &quot;label&quot;])</span><br></pre></td></tr></table></figure><p>除此之外mindspore和mindNLP只支持一些基本操作比如map，padding之类的</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;NLP任务微调笔记&lt;/h1&gt;
&lt;p&gt;NLP数据集没有像CV一样大量标号的数据集，所以NLP一般是自监督的，有两种自监督的模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LM：语言模型，预测下一个词&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MLM：带掩码的语言模型，完形填空&lt;/p&gt;
</summary>
      
    
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="huggingface" scheme="http://outbreak-sen.github.io/tags/huggingface/"/>
    
    <category term="mindspore实习" scheme="http://outbreak-sen.github.io/tags/mindspore%E5%AE%9E%E4%B9%A0/"/>
    
    <category term="mindNLP" scheme="http://outbreak-sen.github.io/tags/mindNLP/"/>
    
  </entry>
  
  <entry>
    <title>mindNLP使用方法以及NLP模型的使用</title>
    <link href="http://outbreak-sen.github.io/2025/02/26/mindNLP%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>http://outbreak-sen.github.io/2025/02/26/mindNLP%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2025-02-26T02:53:47.000Z</published>
    <updated>2025-03-19T09:14:35.074Z</updated>
    
    <content type="html"><![CDATA[<h1>mindNLP</h1><p><a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/abc.html">API reference</a></p><p><a href="https://mindnlp-ai.readthedocs.io/en/latest/zh/api/accelerate/">另一个API reference，这个全</a></p><h2 id="介绍这是什么">介绍这是什么</h2><ul><li><p>MindNLP是基于MindSpore的开源NLP库。这个是个package，类似于huggingface的transformer库，有 250+ 预训练模型支持类似 huggingface transformers 的 API。您可以通过以下代码片段轻松使用，这样可以直接使用已经定义好的模型并且还有模型的权重：<a href="https://mindnlp.cqu.ai/supported_models/">支持的模型</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import mindnlp.transformers import AutoModel</span><br><span class="line"></span><br><span class="line">model = AutoModel.from_pretrained（&#x27;bert-base-cased&#x27;）</span><br></pre></td></tr></table></figure></li><li><p>全面的数据处理：将多个经典的 NLP 数据集打包成友好的模块，以便于使用，例如 Multi30k、SQuAD、CoNLL 等。</p></li><li><p>友好的 NLP 模型工具集：MindNLP 提供了各种可配置的组件。使用 MindNLP 自定义模型很友好。</p></li><li><p>易于使用的引擎：MindNLP 简化了 MindSpore 中复杂的训练过程。它支持 Trainer 和 Evaluator 接口，可轻松训练和评估模型。</p></li><li><p>全平台支持：全面支持昇腾 910 系列、昇腾 310B （Orange Pi）、GPU 和 CPU。（注意：目前 Orange Pi 上唯一可用的 AI 开发套件。</p></li><li><p>分布式并行推理：对超过 10B 参数的模型提供多设备、多进程并行推理支持。</p></li><li><p>量化算法支持：SmoothQuant 可用于 Orange Pi;GPU 支持类似 bitsandbytes 的 int8 量化。</p></li><li><p>Sentence Transformer 支持：实现高效的 RAG（检索增强生成）开发。</p></li><li><p>动态图性能优化：在 Ascend 硬件上实现动态图的 PyTorch+GPU 级推理速度（在 85 毫秒/令牌下测试 Llama 性能）。</p></li><li><p>真正的静态和动态图统一：使用 mindspore.jit 单行切换到图形模式，完全兼容 Hugging Face  代码风格，既易于使用，又能快速提升性能。在Ascend硬件上测试的Llama性能达到了2倍的动态图速度（45ms/token），与其他MindSpore基于静态图的套件一致。</p></li><li><p>广泛的 LLM 应用程序更新：包括文本信息提取、聊天机器人、语音识别、ChatPDF、音乐生成、代码生成、语音克隆等。随着模型支持的增加，更多令人兴奋的应用程序等待开发！</p></li></ul><h2 id="安装">安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># whl的下载位置： https://repo.mindspore.cn/mindspore-lab/mindnlp/newest/any/</span><br><span class="line"># 直接pip就可以安装</span><br><span class="line">pip install mindnlp</span><br><span class="line"># source安装</span><br><span class="line">pip install git+https://github.com/mindspore-lab/mindnlp.git</span><br><span class="line"># or</span><br><span class="line">git clone https://github.com/mindspore-lab/mindnlp.git</span><br><span class="line">cd mindnlp</span><br><span class="line">bash scripts/build_and_reinstall.sh</span><br><span class="line"></span><br><span class="line"># 版本要求：python &gt;=3.9, &lt;=3.11  mingspore &gt;=2.2.x</span><br></pre></td></tr></table></figure><h2 id="补充知识">补充知识</h2><h3 id="分词器-词表-预训练的词向量模型">分词器，词表，预训练的词向量模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 使用分词器分词</span><br><span class="line">tokens = tokenizer.tokenize(&quot;Hello, how are you?&quot;)</span><br><span class="line">print(tokens)  # 输出: [&#x27;hello&#x27;, &#x27;,&#x27;, &#x27;how&#x27;, &#x27;are&#x27;, &#x27;you&#x27;, &#x27;?&#x27;]</span><br><span class="line"></span><br><span class="line"># 使用词表映射到索引</span><br><span class="line">indices = vocab(tokens)</span><br><span class="line">print(indices)  # 输出: [2, 3, 4, 5, 6, 7]</span><br></pre></td></tr></table></figure><h4 id="分词器tokenizer">分词器tokenizer</h4><p>分词器的主要任务是将文本分割成基本单元（如单词、子词或字符），并将这些单元转换为模型可以理解的数值形式（如索引）。常见的分词器包括：</p><ul><li><strong>空格分词器</strong>：按空格分割文本。</li><li><strong>BPE（Byte Pair Encoding）分词器</strong>：将文本分割成子词单元。</li><li><strong>WordPiece 分词器</strong>：BERT 等模型使用的分词器。</li><li><strong>SentencePiece 分词器</strong>：支持无空格语言的分词器。</li></ul><p>分词器的处理流程：</p><ol><li><strong>分词</strong>：将文本分割成基本单元（如单词或子词）。</li><li><strong>转换为索引</strong>：将分词结果映射到词表中的索引。</li><li><strong>添加特殊标记</strong>：如 <code>[CLS]</code>、<code>[SEP]</code>、<code>[PAD]</code> 等。</li><li><strong>填充或截断</strong>：将序列长度统一为固定长度。</li></ol><h4 id="词表-vocab-的作用"><strong>词表（Vocab）的作用</strong></h4><p>词表是词汇到索引的映射表。它的作用是将分词后的文本转换为数值形式，以便模型能够处理。词表通常包括：</p><ul><li><strong>词汇表</strong>：所有可能的词汇或子词。</li><li><strong>特殊标记</strong>：如 <code>&lt;unk&gt;</code>（未知词）、<code>&lt;pad&gt;</code>（填充标记）等。</li><li><strong>索引映射</strong>：将每个词汇映射到一个唯一的索引。</li></ul><h3 id="glove预训练词向量">glove预训练词向量</h3><p><strong>GloVe（Global Vectors for Word Representation）</strong> 是一种预训练的词向量模型，它通过全局词共现统计来学习词汇的分布式表示。主要作用是为词汇提供语义丰富的向量表示，从而增强模型对文本的理解能力。是一种嵌入层embedding。</p><p>（1）<strong>语义表示</strong>GloVe 词向量捕捉了词汇之间的语义关系。例如，<code>king - man + woman ≈ queen</code>，这种关系在向量空间中可以通过向量加减来表示。</p><p>（2）<strong>降维</strong>将高维的离散词汇表示（如 one-hot 编码）转换为低维的连续向量表示。例如，一个词汇可以用一个 100 维的向量表示，而不是一个数万维的 one-hot 向量。</p><p>（3）<strong>初始化嵌入层</strong>在训练 NLP 模型时，GloVe 词向量可以作为嵌入层（Embedding Layer）的初始化参数，从而加速模型收敛并提升性能。</p><p>（4）<strong>解决稀疏性问题</strong>传统的 one-hot 编码会导致数据稀疏性问题，而 GloVe 词向量是稠密的，能够更好地表示词汇。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from torchtext.vocab import GloVe</span><br><span class="line"></span><br><span class="line"># 加载预训练的 GloVe 词向量（6B 表示训练语料为 60 亿词，100 表示向量维度）</span><br><span class="line">glove = GloVe(name=&#x27;6B&#x27;, dim=100)</span><br><span class="line"></span><br><span class="line"># 查看词汇表大小</span><br><span class="line">print(len(glove.itos))  # 输出: 400000（GloVe 6B 包含 40 万个词汇）</span><br><span class="line"></span><br><span class="line"># 获取单词 &quot;king&quot; 的词向量</span><br><span class="line">king_vector = glove[&#x27;king&#x27;]</span><br><span class="line">print(king_vector.shape)  # 输出: torch.Size([100])</span><br></pre></td></tr></table></figure><h3 id="词表和glove预训练词向量不是一个东西">词表和glove预训练词向量不是一个东西</h3><p>虽然 <strong>GloVe 预训练词向量</strong> 和 <strong>词表（Vocab）</strong> 都涉及将词汇转换为向量或索引。</p><p>大多数深度学习模型（如 LSTM、Transformer）的输入是索引序列，而不是直接输入向量序列。词表将文本转换为索引序列，而 GloVe 词向量用于将索引映射为向量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 将文本转换为索引</span><br><span class="line">text = &quot;hello NLP&quot;</span><br><span class="line">indices = vocab(text.split())</span><br><span class="line">print(indices)  # 输出: [2, 4]</span><br><span class="line"># 加载 GloVe 词向量</span><br><span class="line">glove = GloVe(name=&#x27;6B&#x27;, dim=100)</span><br><span class="line"></span><br><span class="line"># 创建嵌入层，并使用 GloVe 词向量初始化</span><br><span class="line">embedding_layer = nn.Embedding.from_pretrained(glove.vectors, freeze=False)</span><br><span class="line"></span><br><span class="line"># 将索引转换为 GloVe 向量</span><br><span class="line">input_indices = torch.LongTensor(indices)</span><br><span class="line">embedded_vectors = embedding_layer(input_indices)</span><br><span class="line">print(embedded_vectors.shape)  # 输出: torch.Size([2, 100])</span><br></pre></td></tr></table></figure><h2 id="学习使用">学习使用</h2><p><a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/overview/about.html">官方参考文件</a></p><p><a href="https://mindnlp-ai.readthedocs.io/en/latest/zh/tutorials/quick_start/">另一个官方参考文件</a></p><h3 id="使用模型">使用模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line">from mindspore import nn</span><br><span class="line">from mindspore import ops</span><br><span class="line">from mindspore.common.initializer import Uniform, HeUniform</span><br><span class="line">from mindnlp.modules import Glove</span><br><span class="line">from mindnlp.modules import RNNEncoder</span><br><span class="line"># 使用 Seq2vecModel 进行模型构建。模块 Seq2vecModel 的功能是提取输入序列数据的语义特征并计算得到结果向量。这一模块由 encoder 和 head 两部分组成，其中 encoder 将输入句子映射为语义向量，而 head 对 encoder 的输出进行进一步计算得到最终的结果。</span><br><span class="line"># 使用MindNLP提供的 RNNEncoder 作为模型的 encoder ，并使用自定义的模块作为模型的 head 。</span><br><span class="line"></span><br><span class="line"># 定义一个head</span><br><span class="line">class Head(nn.Cell):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Head for Sentiment Classification model</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, hidden_dim, output_dim, dropout):</span><br><span class="line">        super().__init__()</span><br><span class="line">        weight_init = HeUniform(math.sqrt(5))</span><br><span class="line">        bias_init = Uniform(1 / math.sqrt(hidden_dim * 2))</span><br><span class="line">        self.fc = nn.Dense(hidden_dim * 2, output_dim, weight_init=weight_init, bias_init=bias_init)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">        self.dropout = nn.Dropout(1 - dropout)</span><br><span class="line">    def construct(self, context):</span><br><span class="line">        context = ops.concat((context[-2, :, :], context[-1, :, :]), axis=1)</span><br><span class="line">        context = self.dropout(context)</span><br><span class="line">        return self.sigmoid(self.fc(context))</span><br><span class="line"># 使用encoder</span><br><span class="line">hidden_size = 256</span><br><span class="line">output_size = 1</span><br><span class="line">num_layers = 2</span><br><span class="line">bidirectional = True</span><br><span class="line">drop = 0.5</span><br><span class="line">lr = 0.001</span><br><span class="line">embedding, vocab = Glove.from_pretrained(&#x27;6B&#x27;, 100, special_tokens=[&quot;&lt;unk&gt;&quot;, &quot;&lt;pad&gt;&quot;], dropout=drop)</span><br><span class="line">lstm_layer = nn.LSTM(100, hidden_size, num_layers=num_layers, batch_first=True,</span><br><span class="line">                    dropout=drop, bidirectional=bidirectional)</span><br><span class="line">sentiment_encoder = RNNEncoder(embedding, lstm_layer)</span><br><span class="line"></span><br><span class="line">sentiment_head = Head(hidden_size, output_size, drop)</span><br><span class="line"># 把这两个传进去生成model</span><br><span class="line">net = SentimentClassification(sentiment_encoder, sentiment_head)</span><br></pre></td></tr></table></figure><h3 id="使用数据集">使用数据集</h3><h4 id="通过对应接口加载">通过对应接口加载</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.dataset import Multi30k</span><br><span class="line">multi30k_train, multi30k_valid, multi30k_test = Multi30k(&quot;./dataset&quot;)</span><br><span class="line">multi30k_train = Multi30k(root=&quot;./dataset&quot;, split=&#x27;train&#x27;)</span><br><span class="line"></span><br><span class="line">通过注释或者网站对应的接口 文档 查看参数列表以及返回值等信息：</span><br><span class="line"># 参数：</span><br><span class="line"># root (str) - 存放数据集的目录。默认：”~/.mindnlp”。</span><br><span class="line"># split (str|Tuple[str]) - 要返回的数据集分块。默认：(‘train’, ‘valid’, ‘test’).</span><br><span class="line"># language_pair (Tuple[str]) - 包含源语言和目标语言的元组。默认：(‘de’, ‘en’).</span><br><span class="line"># proxies (dict) - 定义代理的字典，例如：&#123;“https”: “https://127.0.0.1:7890”&#125;.</span><br><span class="line"># 返回：</span><br><span class="line"># datasets_list (list) - 加载完成的数据集分块列表。如果只加载了一个数据集分块， 如：’trian’，那么就只返回这个数据集分块，而不是一个列表。</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="通过对应接口load预处理">通过对应接口load预处理</h4><p>可以在 <code>mindnlp.dataset</code> 下找到对应数据集接口，名称为数据集名称加下划线以及 <code>Process</code> ，其中的 <code>vocab</code> 为如上生成的词表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.dataset import Multi30k_Process</span><br><span class="line">train_dataset = Multi30k_Process(train_dataset, vocab=vocab)</span><br><span class="line"># 通过注释或者网站对应的接口 [文档](https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/machine_translation.html#module-mindnlp.dataset.machine_translation.multi30k) 查看参数列表以及返回值等信息：</span><br><span class="line"># 参数：</span><br><span class="line"># - **dataset** (*GeneratorDataset*) - Multi30k数据集。</span><br><span class="line"># - **vocab** (*Vocab*) - 词表对象，用于存储分词和索引的映射。默认为空。如果为空，一个新的词表对象将会被创建。</span><br><span class="line"># - **batch_size** (*int*) - 指定每个批处理数据包含的数据条目。默认值：64。</span><br><span class="line"># - **max_len** (*int*) - 句子的最大长度。默认值：500。</span><br><span class="line"># - **drop_remainder** (*bool*) - 当最后一批数据包含的数据条目小于batch_size时，是否丢弃该批次，而不将其传递到下一个操作。默认值：False，不丢弃</span><br><span class="line"># 返回：</span><br><span class="line"># - **dataset** (MapDataset) - 预处理操作后返回的数据集。</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 处理和划分数据，针对语音数据集还需要分词器和词汇表</span><br><span class="line"># 调用来自 Glove 的函数 from_pretrained() ，获取嵌入和词汇表</span><br><span class="line">from mindnlp.modules import Glove</span><br><span class="line">embedding, vocab = Glove.from_pretrained(&#x27;6B&#x27;, 100, special_tokens=[&quot;&lt;unk&gt;&quot;, &quot;&lt;pad&gt;&quot;], dropout=drop)</span><br><span class="line"># 实例化类 BasicTokenizer 来初始化分词器：</span><br><span class="line">from mindnlp.dataset.transforms import BasicTokenizer</span><br><span class="line">tokenizer = BasicTokenizer(True)</span><br><span class="line">将获取到的训练集、分词器和词汇表等传入方法 process() ，应用该方法获取处理过的训练集：</span><br><span class="line">from mindnlp.dataset import process</span><br><span class="line">imdb_train = process(&#x27;imdb&#x27;, imdb_train, tokenizer=tokenizer, vocab=vocab, bucket_boundaries=[400, 500], max_len=600, drop_remainder=True)</span><br><span class="line"># 使用方法 split() 来划分处理后的训练集，从而获取新的训练集和验证集</span><br><span class="line">imdb_train, imdb_valid = imdb_train.split([0.7, 0.3])             </span><br></pre></td></tr></table></figure><h4 id="通过统一接口加载">通过统一接口加载</h4><p>通过一个统一的 <code>load</code> 接口进行加载，第一个参数为数据集的名称字符串，用以指定数据集：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.dataset import load</span><br><span class="line">multi30k_train, multi30k_valid, multi30k_test = load(&#x27;multi30k&#x27;)</span><br><span class="line">multi30k_train, multi30k_valid, multi30k_test = load(&#x27;multi30k&#x27;, root=&quot;./dataset&quot;) # 其他参数可以通过查询接口继续添加</span><br></pre></td></tr></table></figure><h4 id="通过统一接口process预处理">通过统一接口process预处理</h4><p>对于不同领域中的不同数据集，有不同的处理流程，mindnlp提供了数据集的特定处理函数帮助我们快速处理数据。和前面的加载方法一样，这里同样有两种方法调用该处理函数。以 <code>Multi30k</code> 数据集为例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.dataset import process</span><br><span class="line">multi30k_train, multi30k_valid, multi30k_test = load(&#x27;multi30k&#x27;)</span><br><span class="line">dataset_train = process(&#x27;Multi30k&#x27;, multi30k_train, vocab = vocab)</span><br></pre></td></tr></table></figure><h3 id="数据集变换处理">数据集变换处理</h3><p>数据集变换处理中最重要的操作是 <code>map</code> 操作，可以针对数据集指定列（column）添加数据变换（Transforms），将数据变换应用于该列数据的每个元素，并返回包含变换后元素的新数据集。这里使用 <code>BasicTokenizer</code> 对数据集的两列进行分词，并使用 <code>from_dataset</code> 生成词表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.dataset.transforms import BasicTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = BasicTokenizer(True)</span><br><span class="line">dataset_train= dataset_train.map([tokenizer], &#x27;en&#x27;)</span><br><span class="line">dataset_train= dataset_train.map([tokenizer], &#x27;de&#x27;)</span><br><span class="line"></span><br><span class="line">en_vocab = text.Vocab.from_dataset(dataset_train, &#x27;en&#x27;, special_tokens=[&#x27;&lt;pad&gt;&#x27;, &#x27;&lt;unk&gt;&#x27;], special_first= True)</span><br><span class="line">de_vocab = text.Vocab.from_dataset(dataset_train, &#x27;de&#x27;, special_tokens=[&#x27;&lt;pad&gt;&#x27;, &#x27;&lt;unk&gt;&#x27;], special_first= True)</span><br><span class="line">vocab = &#123;&#x27;en&#x27;:en_vocab, &#x27;de&#x27;:de_vocab&#125;</span><br></pre></td></tr></table></figure><h3 id="用trainer进行训练">用Trainer进行训练</h3><h4 id="定义loss和优化器">定义loss和优化器</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 使用MindSpore提供的 `mindspore.nn.BCELoss` 来定义一个损失函数：</span><br><span class="line">loss = nn.BCELoss(reduction=&#x27;mean&#x27;)</span><br><span class="line"># 然后，调用 `mindspore.nn.Adam` ，并传入模型的可训练参数，从而定义运行模型所需要的优化器：</span><br><span class="line">optimizer = nn.Adam(net.trainable_params(), learning_rate=lr)</span><br></pre></td></tr></table></figure><h4 id="定义回调函数">定义回调函数</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.engine.callbacks.timer_callback import TimerCallback</span><br><span class="line">from mindnlp.engine.callbacks.earlystop_callback import EarlyStopCallback</span><br><span class="line">from mindnlp.engine.callbacks.best_model_callback import BestModelCallback</span><br><span class="line"># 首先需要初始化回调函数对应的类</span><br><span class="line">timer_callback_epochs = TimerCallback(print_steps=2) # 用于计时的回调函数</span><br><span class="line">earlystop_callback = EarlyStopCallback(patience=2) # 用于早停的回调函数</span><br><span class="line">bestmodel_callback = BestModelCallback(save_path=&#x27;save/callback/best_model&#x27;, auto_load=True) #  BestModelCallback 用于保存和加载最好的模型使用 CheckpointCallback 来保存checkpoint</span><br><span class="line"># 声明一个由我们事先初始化的回调函数组成的列表</span><br><span class="line">callbacks = [timer_callback_epochs, earlystop_callback, bestmodel_callback]</span><br></pre></td></tr></table></figure><p>也可自定义Callback，继承自mindnlp.abc.callback。Callback中所有的类方法都会在Trainer的训练中在特定的阶段调用。如train_begin()会在训练开始时被调用，epoch_end()会在每个epoch结束时调用。具体有哪些类方法，参见Callback文档。这里，MyCallback在每个epoch结束时调用epoch_end()，输出当前epoch结束时的loss均值。</p><h4 id="定义评价指标">定义评价指标<a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/quick_start/train_and_eval.html#define-metrics"></a></h4><p>MindNLP中有很多 <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/abc.html#mindnlp.abc.Metric"><code>Metric</code></a> 可以用于模型评估： <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.accuracy.Accuracy"><code>Accuracy</code></a> ， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.bleu.BleuScore"><code>BleuScore</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.confusion_matrix.ConfusionMatrix"><code>ConfusionMatrix</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.distinct.Distinct"><code>Distinct</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.em_score.EmScore"><code>EmScore</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.f1.F1Score"><code>F1Score</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.matthews.MatthewsCorrelation"><code>MatthewsCorrelation</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.pearson.PearsonCorrelation"><code>PearsonCorrelation</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.perplexity.Perplexity"><code>Perplexity</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.precision.Precision"><code>Precision</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.recall.Recall"><code>Recall</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.rouge.RougeL"><code>RougeL</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.rouge.RougeN"><code>RougeN</code></a>， <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.spearman.SpearmanCorrelation"><code>SpearmanCorrelation</code></a>。使用一个或多个评价指标来评估模型是有必要的。我们选择 <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/engine/metrics.html#mindnlp.engine.metrics.accuracy.Accuracy"><code>Accuracy</code></a> 作为模型的评价指标：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.engine.metrics import Accuracy</span><br><span class="line">metric = Accuracy()</span><br></pre></td></tr></table></figure><p><strong>也可以通过继承基类Metric自己定义</strong></p><h4 id="特别快的使用trainer-不需要多余写东西">特别快的使用trainer，不需要多余写东西</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from mindnlp.engine.trainer import Trainer</span><br><span class="line"></span><br><span class="line">trainer = Trainer(network=net, train_dataset=imdb_train, eval_dataset=imdb_valid, metrics=metric,epochs=5, loss_fn=loss, optimizer=optimizer, callbacks=callbacks)</span><br><span class="line">    # network：训练的网络。</span><br><span class="line">    # train_dataset：用于训练模型的数据集。</span><br><span class="line">    # eval_dataset：用于评估模型的数据集。</span><br><span class="line">    # metrics：用于评估模型的评价指标。</span><br><span class="line">    # epochs：训练数据的总迭代次数。</span><br><span class="line">    # loss_fn：损失函数。</span><br><span class="line">    # optimizer：用于更新训练参数的优化器。</span><br><span class="line">    # callbacks：训练时执行的额外操作。</span><br><span class="line"></span><br><span class="line">trainer.run(tgt_columns=&quot;label&quot;, jit=False)</span><br></pre></td></tr></table></figure><h3 id="组件">组件</h3><p><code>modules</code> 用于构建神经网络模型，可以和 MindSpore 一起使用。 <code>modules</code> 具有三大功能模块：Embedding, Encoder-Decoder 和 Attention</p><h3 id="embedding">Embedding</h3><p>embedding直译是<strong>嵌入式、嵌入层</strong>。本质上是一种词嵌入技术,能够将一个单词或短语表示为低维向量.mindnlp提供了一个快速通过预训练glove,fasttext,word2vec词向量简单构造embedding的方法</p><p><a href="https://zhuanlan.zhihu.com/p/150556238">embedding的发展和常用embedding</a><br><a href="https://zhuanlan.zhihu.com/p/164502624">embedding基本概念</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from mindspore import Tensor</span><br><span class="line">from mindspore.dataset.text.utils import Vocab</span><br><span class="line">from mindnlp.modules.embeddings.glove_embedding import Glove</span><br><span class="line"></span><br><span class="line"># 这个是自己定义的，需要字典和对应的向量，然后可以传入这两个参数创建一个自定义的glove</span><br><span class="line"># Define your own vocab</span><br><span class="line">vocab = Vocab.from_list([&#x27;default&#x27;, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;])</span><br><span class="line"># Define your own embedding table</span><br><span class="line">init_embed = Tensor(np.zeros((4, 4)).astype(np.float32))</span><br><span class="line"># Create your own embedding object</span><br><span class="line">glove_embed = Glove(vocab, init_embed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 直接用他定义好的，pretrained的</span><br><span class="line"># You can also use pre-trained word vectors</span><br><span class="line">glove_embed_pretrained, _ = Glove.from_pretrained()</span><br><span class="line"></span><br><span class="line"># 这个Embedding怎么反向通过向量输出文字</span><br><span class="line"># The index to query for</span><br><span class="line">ids = Tensor([1, 2, 3])</span><br><span class="line"></span><br><span class="line"># Computed by the built embedding</span><br><span class="line">output = glove_embed(ids)</span><br></pre></td></tr></table></figure><h3 id="encoder-decoder">Encoder-Decoder</h3><p>Encoder-Decoder是一个模型架构，是一类算法统称。在这个框架下可以使用不同的算法来解决不同的人物。Encoder将输入序列转化为语义向量，Decoder根据Encoder的输出生成目标译文。<a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/modules/encoder.html">MindNLP.modules.encoder</a> 和 <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/modules/decoder.html">MindNLP.modules.decoder</a> ，MindNLP中包含的Encoder-Decoder模块如下表所示</p><table><thead><tr><th>名称</th><th>介绍</th></tr></thead><tbody><tr><td><a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/modules/encoder.html#mindnlp.modules.encoder.cnn_encoder.CNNEncoder"><code>CNNEncoder</code></a></td><td>由传入参数convolutions组成的卷积编码器</td></tr><tr><td><a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/modules/encoder.html#mindnlp.modules.encoder.rnn_encoder.RNNEncoder"><code>RNNEncoder</code></a></td><td>循环神经网络（RNN）编码器</td></tr><tr><td><a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/modules/decoder.html#mindnlp.modules.decoder.rnn_decoder.RNNDecoder"><code>RNNDecoder</code></a></td><td>循环神经网络（RNN）解码器</td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">from mindspore import nn</span><br><span class="line">from mindnlp.abc import Seq2seqModel</span><br><span class="line">from mindnlp.modules import RNNEncoder, RNNDecoder</span><br><span class="line"></span><br><span class="line">class MachineTranslation(Seq2seqModel):</span><br><span class="line">    def __init__(self, encoder, decoder):</span><br><span class="line">        super().__init__(encoder, decoder)</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line"></span><br><span class="line">    def construct(self, en, de):</span><br><span class="line">        encoder_out = self.encoder(en)</span><br><span class="line">        decoder_out = self.decoder(de, encoder_out=encoder_out)</span><br><span class="line">        output = decoder_out[0]</span><br><span class="line">        return output.swapaxes(1,2)</span><br><span class="line"></span><br><span class="line">enc_emb_dim = 256</span><br><span class="line">dec_emb_dim = 256</span><br><span class="line">enc_hid_dim = 512</span><br><span class="line">dec_hid_dim = 512</span><br><span class="line">enc_dropout = 0.5</span><br><span class="line">dec_dropout = 0.5</span><br><span class="line"></span><br><span class="line"># encoder</span><br><span class="line">en_embedding = nn.Embedding(input_dim, enc_emb_dim)</span><br><span class="line">en_rnn = nn.RNN(enc_emb_dim, hidden_size=enc_hid_dim, num_layers=2, has_bias=True,batch_first=True, dropout=enc_dropout, bidirectional=False)</span><br><span class="line">rnn_encoder = RNNEncoder(en_embedding, en_rnn)</span><br><span class="line"></span><br><span class="line"># decoder</span><br><span class="line">de_embedding = nn.Embedding(output_dim, dec_emb_dim)</span><br><span class="line">input_feed_size = 0 if enc_hid_dim == 0 else dec_hid_dim</span><br><span class="line">rnns = [</span><br><span class="line">    nn.RNNCell(</span><br><span class="line">        input_size=dec_emb_dim + input_feed_size</span><br><span class="line">        if layer == 0</span><br><span class="line">            else dec_hid_dim,</span><br><span class="line">        hidden_size=dec_hid_dim</span><br><span class="line">        )</span><br><span class="line">        for layer in range(2)</span><br><span class="line">]</span><br><span class="line">rnn_decoder = RNNDecoder(de_embedding, rnns, dropout_in=enc_dropout, dropout_out = dec_dropout,attention=True, encoder_output_units=enc_hid_dim)</span><br></pre></td></tr></table></figure><h3 id="attention">Attention</h3><p>目前，MindNlp已经实现了8种注意力机制。 <a href="https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/modules/attentions.html">MindNLP.modules.attentions</a> .</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import mindspore</span><br><span class="line">from mindspore import Tensor</span><br><span class="line">from mindspore.text.modules.attentions import ScaledDotAttention</span><br><span class="line">model = ScaledDotAttention(dropout=0.9)</span><br><span class="line"># You can customize the query, key, vlaue vector</span><br><span class="line">q = Tensor(np.ones((2, 32, 512)), mindspore.float32)</span><br><span class="line">k = Tensor(np.ones((2, 20, 512)), mindspore.float32)</span><br><span class="line">v = Tensor(np.ones((2, 20, 400)), mindspore.float32)</span><br><span class="line">output, att = model(q, k, v)</span><br><span class="line"># output shape is (2, 1024, 512)</span><br><span class="line"># att shape is (2, 1024, 32)</span><br></pre></td></tr></table></figure><h2 id="示例四个">示例四个</h2><h3 id="文本分类">文本分类</h3><h3 id="序列翻译">序列翻译</h3><h3 id="机器学习">机器学习</h3><h3 id="回答问题">回答问题</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;mindNLP&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://mindnlpdocs.readthedocs.io/zh-cn/latest/api/abc.html&quot;&gt;API reference&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mindnlp</summary>
      
    
    
    
    
    <category term="mindspore实习" scheme="http://outbreak-sen.github.io/tags/mindspore%E5%AE%9E%E4%B9%A0/"/>
    
    <category term="mindNLP" scheme="http://outbreak-sen.github.io/tags/mindNLP/"/>
    
  </entry>
  
  <entry>
    <title>大恒相机的多相机硬触发方案</title>
    <link href="http://outbreak-sen.github.io/2025/02/17/%E5%A4%A7%E6%81%92%E7%9B%B8%E6%9C%BA%E7%9A%84%E5%A4%9A%E7%9B%B8%E6%9C%BA%E7%A1%AC%E8%A7%A6%E5%8F%91%E6%96%B9%E6%A1%88/"/>
    <id>http://outbreak-sen.github.io/2025/02/17/%E5%A4%A7%E6%81%92%E7%9B%B8%E6%9C%BA%E7%9A%84%E5%A4%9A%E7%9B%B8%E6%9C%BA%E7%A1%AC%E8%A7%A6%E5%8F%91%E6%96%B9%E6%A1%88/</id>
    <published>2025-02-17T06:49:03.000Z</published>
    <updated>2025-02-28T06:37:09.853Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>zed相机使用</title>
    <link href="http://outbreak-sen.github.io/2025/02/16/zed%E7%9B%B8%E6%9C%BA%E4%BD%BF%E7%94%A8/"/>
    <id>http://outbreak-sen.github.io/2025/02/16/zed%E7%9B%B8%E6%9C%BA%E4%BD%BF%E7%94%A8/</id>
    <published>2025-02-16T04:28:48.000Z</published>
    <updated>2025-03-19T09:15:42.926Z</updated>
    
    <content type="html"><![CDATA[<h1>Zed相机的驱动安装和图像视频获取</h1><p>和众多的深度相机一样，下载SDK，然后SDK里有个上位机可以用来快速的获取视频和可视化，然后还有一套ROS，C++，python的API可以编写一些定制程序。</p><p>型号</p><p><img src="/home/outbreak/BlogOutbreak/source/_posts/zed%E7%9B%B8%E6%9C%BA%E4%BD%BF%E7%94%A8/image-20250216161117215.png" alt="image-20250216161117215"></p><table><thead><tr><th>型号</th><th>ZED mini垃圾</th><th>ZED 2 黑色的</th><th>ZED白色的 最垃圾</th><th>ZED 2I 想要的</th></tr></thead><tbody><tr><td>特点</td><td>不写了自己看</td><td></td><td></td><td></td></tr><tr><td>帧率</td><td></td><td></td><td></td><td></td></tr><tr><td>陀螺仪</td><td></td><td></td><td></td><td></td></tr></tbody></table><h2 id="驱动安装">驱动安装</h2><h3 id="zed-sdk-python-的环境后面装">ZED SDK-Python 的环境后面装</h3><p>我的cuda环境：cuda12.4</p><p>参考官网的下载方式是SDK，针对不同硬件平台和cuda版本下载不同的SDK版本，这里下载的SDK版本号是4.2。</p><img src="./zed相机使用/image-20250216130038994.png" alt="image-20250216130038994" style="zoom:50%;" /><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ sh ./ZED_SDK_Ubuntu22_cuda12.1_v4.2.5.zstd.run</span><br><span class="line"></span><br><span class="line">Verifying archive integrity...  100%   MD5 checksums are OK. All good.</span><br><span class="line">Uncompressing &#x27;ZED camera SDK by Stereolabs (Use &#x27;sudo apt install zstd&#x27; if zstd is not found)&#x27;  100%  </span><br><span class="line">Ubuntu version 22.04 detected. OK</span><br><span class="line">To continue you have to accept the EULA. Accept  [Y/n] ?y</span><br><span class="line">Installing...Python 的环境后面装</span><br><span class="line">Installation path: /usr/local/zed #安装路径，tools samples都在这</span><br><span class="line">Checking CUDA version...</span><br><span class="line">OK: Found CUDA 12.4 # 查cuda版本，找不到输出一下路径</span><br><span class="line">Do you want to also install the static version of the ZED SDK (AI module will still require libsl_ai.so) [Y/n] ?y # 必须的</span><br><span class="line">Do you want to install the AI module (required for Object detection and Neural Depth, recommended), cuDNN 8.9 and TensorRT 8.6 will be installed [Y/n] ?y # 这个就是是否需要下载他写好的深度学习的一些方法，可以识别物体这类的，没必要</span><br><span class="line">Install samples (recommended) [Y/n] ?y # sample还是很有必要的，得看看api怎么用的</span><br><span class="line">Installation path: /usr/local/zed/samples/ # sample的路径</span><br><span class="line">Do you want to auto-install dependencies (recommended) ? following packet will be installed via the package manager : libjpeg-turbo8 libturbojpeg libusb-1.0-0 libusb-1.0-0-dev libopenblas-dev libarchive-dev libv4l-0 curl unzip zlib1g mesa-utils libpng-dev python3-dev python3-pip python3-setuptools libglew-dev freeglut3-dev qtbase5-dev qtchooser qt5-qmake qtbase5-dev-tools libqt5opengl5 libqt5svg5 [Y/n] ?y # 装啊，还能不装？</span><br><span class="line">Do you want to install the Python API (recommended) [Y/n] ?N # 这里装的不好，需要指定python的路径，建议看下面python的是怎么安装的</span><br><span class="line">Please specify your python executable: python3 # 这里直接摁了回车 ，我感觉得提前构建一个环境给zed</span><br><span class="line">Requirement already satisfied: numpy in /home/outbreak/anaconda3/lib/python3.11/site-packages (1.24.3)</span><br><span class="line">Requirement already satisfied: requests in /home/outbreak/anaconda3/lib/python3.11/site-packages (2.31.0)</span><br><span class="line">Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/outbreak/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)</span><br><span class="line">Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/outbreak/anaconda3/lib/python3.11/site-packages (from requests) (3.4)</span><br><span class="line">Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/outbreak/anaconda3/lib/python3.11/site-packages (from requests) (1.26.16)</span><br><span class="line">Requirement already satisfied: certifi&gt;=2017.4.17 in /home/outbreak/anaconda3/lib/python3.11/site-packages (from requests) (2023.7.22)</span><br><span class="line"></span><br><span class="line">ERROR: pip&#x27;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span><br><span class="line">tables 3.8.0 requires blosc2~=2.0.0, which is not installed.</span><br><span class="line">gensim 4.3.0 requires FuzzyTM&gt;=0.4.0, which is not installed.</span><br><span class="line">numba 0.57.1 requires numpy&lt;1.25,&gt;=1.21, but you have numpy 1.26.4 which is incompatible.</span><br><span class="line">Successfully installed cython-3.0.12 numpy-1.24.3 pyzed-4.2</span><br><span class="line">Done</span><br><span class="line">  To install it later or on a different environment run : </span><br><span class="line"> python -m pip install --ignore-installed /tmp/selfgz29281/pyzed-4.2-cp311-cp311-linux_x86_64.whl</span><br><span class="line">The ZED Python API was installed for &#x27;python3&#x27; #这里是报错了，自动安装到anaconda里了，然后有几个下载的package，有的没装，之后自己装吧，但是没关系，因为ZED SDK 安装文件夹中有一个 Python 脚本（get_python_api.py），可以自动检测操作系统、CUDA 和 Python 版本并下载相应的预编译 Python API 包（pyzed）。大家都是安装zedsdk时候不安装这个pythonAPI，然后后面自己安装</span><br><span class="line"></span><br><span class="line">Do you want to run the ZED Diagnostic to download all AI models [Y/n] ?y # 深度学习的model，可以不用</span><br><span class="line">Downloading all AI models</span><br><span class="line">Downloading: MULTI CLASS DETECTION...</span><br><span class="line">/usr/local/zed/resources/objects_ 100%[=============================================================&gt;]  35.84M  10.4MB/s    用时 3.7s  </span><br><span class="line">Downloading: MULTI CLASS MEDIUM DETECTION...</span><br><span class="line"></span><br><span class="line">Do you want to run the ZED Diagnostic to optimize all AI models, it may take a very long time, up to multiple hours but will be done only once. Otherwise it will be optimized just in time when running the ZED SDK [Y/n] ?n # 对不起我赶时间，这个优化我不装了</span><br></pre></td></tr></table></figure><h3 id="安装zed-python-api-pyzed-针对conda">安装ZED-Python-API（pyzed）-针对conda</h3><p>ZED SDK 安装文件夹/usr/local/zed中有一个 Python 脚本（get_python_api.py），可以自动检测操作系统、CUDA 和 Python 版本并下载相应的预编译 Python API 的whl包（pyzed）。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /usr/local/zed</span><br><span class="line">$ conda activate ZED <span class="comment">#先激活conda还环境，因为这个脚本需要查看python版本和python路径</span></span><br><span class="line">$ python get_python_api.py</span><br><span class="line"></span><br><span class="line">Detected platform: </span><br><span class="line"> linux_x86_64</span><br><span class="line"> Python 3.10</span><br><span class="line"> ZED SDK 4.2</span><br><span class="line">-&gt; Checking <span class="keyword">if</span> https://download.stereolabs.com/zedsdk/4.2/whl/linux_x86_64/pyzed-4.2-cp310-cp310-linux_x86_64.whl exists and is available</span><br><span class="line">-&gt; Found ! Downloading python package into /usr/local/zed/pyzed-4.2-cp310-cp310-linux_x86_64.whl</span><br><span class="line">-&gt; Installing necessary dependencies</span><br><span class="line">Requirement already satisfied: numpy <span class="keyword">in</span> /home/outbreak/anaconda3/envs/pytorch2/lib/python3.10/site-packages (1.26.4)</span><br><span class="line">Processing ./pyzed-4.2-cp310-cp310-linux_x86_64.whl</span><br><span class="line">Collecting numpy&lt;2.0,&gt;=1.13 (from pyzed==4.2)</span><br><span class="line">  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)</span><br><span class="line">Collecting cython&gt;=3.0.0 (from pyzed==4.2)</span><br><span class="line">  Downloading Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)</span><br><span class="line">Downloading Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)</span><br><span class="line">   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 4.6 MB/s eta 0:00:00</span><br><span class="line">Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)</span><br><span class="line">   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 5.0 MB/s eta 0:00:00</span><br><span class="line">Installing collected packages: numpy, cython, pyzed</span><br><span class="line">Successfully installed cython-3.0.12 numpy-1.26.4 pyzed-4.2</span><br><span class="line">Done</span><br><span class="line">  To install it later or on a different environment run : </span><br><span class="line"> python -m pip install --ignore-installed /usr/local/zed/pyzed-4.2-cp310-cp310-linux_x86_64.whl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ python -m pip install --ignore-installed /usr/local/zed/pyzed-4.2-cp310-cp310-linux_x86_64.whl</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">这个脚本可以测试又没有安装好，这里方便复制，其实就是下面的sample的第一个</span><br><span class="line">import pyzed.sl as sl</span><br><span class="line">def main():</span><br><span class="line">    # Create a Camera object</span><br><span class="line">    zed = sl.Camera()</span><br><span class="line"></span><br><span class="line">    # Create a InitParameters object and set configuration parameters</span><br><span class="line">    init_params = sl.InitParameters()</span><br><span class="line">    init_params.sdk_verbose = False</span><br><span class="line"></span><br><span class="line">    # Open the camera</span><br><span class="line">    err = zed.open(init_params)</span><br><span class="line">    if err != sl.ERROR_CODE.SUCCESS:</span><br><span class="line">        exit(1)</span><br><span class="line"></span><br><span class="line">    # Get camera information (ZED serial number)</span><br><span class="line">    zed_serial = zed.get_camera_information().serial_number</span><br><span class="line">    print(&quot;Hello! This is my serial number: &#123;0&#125;&quot;.format(zed_serial))</span><br><span class="line"></span><br><span class="line">    # Close the camera</span><br><span class="line">    zed.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 发现报错，这个报错很常见，自己搜一下</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/home/outbreak/ZED/samples/tutorials/tutorial 1 - hello ZED/python/hello_zed.py&quot;, line 21, in &lt;module&gt;</span><br><span class="line">    import pyzed.sl as sl</span><br><span class="line">ImportError: /home/outbreak/anaconda3/envs/pytorch2/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.30&#x27; not found (required by /usr/local/zed/lib/libsl_zed.so)</span><br><span class="line">#解决方法：ln -sf /usr/lib/x86_64-linux-gnu/libstdc++.so.6  /home/outbreak/anaconda3/envs/pytorch2/bin/../lib/libstdc++.so.6</span><br></pre></td></tr></table></figure><h2 id="上位机的使用">上位机的使用</h2><p>这玩意有多个上位机，可以直接命令行输入命令运行，这些软件的位置都在tools里</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/zed/tools/ZED Depth Viewer</span><br><span class="line">ZED360             ZED_Depth_Viewer   ZED_Explorer       ZED_Sensor_Viewer</span><br><span class="line">ZED_Calibration    ZED_Diagnostic     ZEDfu              ZED_SVO_Editor</span><br></pre></td></tr></table></figure><h3 id="zed-explorer">ZED Explorer</h3><p>ZED Explorer是ZED实时预览和录制的应用程序。它允许您更改视频分辨率、纵横比和相机参数，并捕获高分辨率快照和3D视频。<br>如果ZED被您的计算机识别，您将看到来自相机的3D视频。</p><p><img src="./zed%E7%9B%B8%E6%9C%BA%E4%BD%BF%E7%94%A8/image-20250216134044179.png" alt="image-20250216134044179"></p><h3 id="zed-depth-viewer">ZED Depth Viewer</h3><p>ZED Depth Viewer使用ZED SDK捕获和显示深度图和3D点云。运行ZED Depth Viewer，检查深度图是否正确显示。尝试不同的深度模式，以选择最适合您的深度质量/性能比。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">工业垃圾，写的一托，相机打不开</span><br><span class="line">ZED_Depth_Viewer</span><br><span class="line">[2025-02-16 05:49:06 UTC][ZED][INFO] Logging level INFO</span><br><span class="line">[2025-02-16 05:49:06 UTC][ZED][INFO] Logging level INFO</span><br><span class="line">[2025-02-16 05:49:06 UTC][ZED][INFO] [Init]  Depth mode: ULTRA</span><br><span class="line">[2025-02-16 05:49:07 UTC][ZED][INFO] [Init]  Camera successfully opened.</span><br><span class="line">[2025-02-16 05:49:07 UTC][ZED][INFO] [Init]  Camera FW version: 1523</span><br><span class="line">[2025-02-16 05:49:07 UTC][ZED][INFO] [Init]  Video mode: HD1080@30</span><br><span class="line">[2025-02-16 05:49:07 UTC][ZED][INFO] [Init]  Serial Number: S/N 25939373</span><br><span class="line">in bool ImageHandler::initialize(sl::Mat&amp;) : Err [999]: unknown error.</span><br><span class="line">Stack trace (most recent call last):</span><br><span class="line">#26   Object &quot;[0xffffffffffffffff]&quot;, at 0xffffffffffffffff, in </span><br><span class="line">#25   Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315f97e44, in </span><br><span class="line">#24   Object &quot;/lib/x86_64-linux-gnu/libc.so.6&quot;, at 0x77912ce29e3f, in __libc_start_main</span><br><span class="line">#23   Object &quot;/lib/x86_64-linux-gnu/libc.so.6&quot;, at 0x77912ce29d8f, in </span><br><span class="line">#22   Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315f97061, in </span><br><span class="line">#21   Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fc841d, in </span><br><span class="line">#20   Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fc341e, in </span><br><span class="line">#19   Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fdc499, in </span><br><span class="line">#18   Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d8b875a, in QEventLoop::exec(QFlags&lt;QEventLoop::ProcessEventsFlag&gt;)</span><br><span class="line">#17   Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d9130b7, in QEventDispatcherGlib::processEvents(QFlags&lt;QEventLoop::ProcessEventsFlag&gt;)</span><br><span class="line">#16   Object &quot;/lib/x86_64-linux-gnu/libglib-2.0.so.0&quot;, at 0x77912d1193e2, in g_main_context_iteration</span><br><span class="line">#15   Object &quot;/lib/x86_64-linux-gnu/libglib-2.0.so.0&quot;, at 0x77912d1712b7, in </span><br><span class="line">#14   Object &quot;/lib/x86_64-linux-gnu/libglib-2.0.so.0&quot;, at 0x77912d11bd3a, in g_main_context_dispatch</span><br><span class="line">#13   Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d912d33, in </span><br><span class="line">#12   Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d9123ea, in QTimerInfoList::activateTimers()</span><br><span class="line">#11   Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d8b9e39, in QCoreApplication::notifyInternal2(QObject*, QEvent*)</span><br><span class="line">#10   Object &quot;/lib/x86_64-linux-gnu/libQt5Widgets.so.5&quot;, at 0x77912e56c712, in QApplicationPrivate::notify_helper(QObject*, QEvent*)</span><br><span class="line">#9    Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d8e733e, in QObject::event(QEvent*)</span><br><span class="line">#8    Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d8f57fd, in QTimer::timeout(QTimer::QPrivateSignal)</span><br><span class="line">#7    Object &quot;/lib/x86_64-linux-gnu/libQt5Core.so.5&quot;, at 0x77912d8f17c7, in </span><br><span class="line">#6    Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fc8eec, in </span><br><span class="line">#5    Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fc4434, in </span><br><span class="line">#4    Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fd48d3, in </span><br><span class="line">#3    Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315fd3368, in </span><br><span class="line">#2    Object &quot;ZED_Depth_Viewer&quot;, at 0x64b31603654d, in </span><br><span class="line">#1    Object &quot;ZED_Depth_Viewer&quot;, at 0x64b315ff272d, in </span><br><span class="line">#0    Object &quot;/lib/x86_64-linux-gnu/libcuda.so.1&quot;, at 0x779139af30e9, in </span><br><span class="line">Segmentation fault (Address not mapped to object [0x1500000015])</span><br><span class="line">[1]    4712 segmentation fault (core dumped)  ZED_Depth_Viewer</span><br></pre></td></tr></table></figure><h4 id="工业垃圾的上位机bug一堆">工业垃圾的上位机bug一堆</h4><p>用上位机看zed mini深度图，看不到，还把我系统的所有小图表都崩没了，然后还卡住了，垃圾至极。比realsense不知道拉到哪里去了。</p><h3 id="zed-sensor-viewer">ZED Sensor Viewer</h3><p>能看到当前的陀螺仪，加速度，磁力计数据。</p><p><img src="./zed%E7%9B%B8%E6%9C%BA%E4%BD%BF%E7%94%A8/image-20250216133853582.png" alt="image-20250216133853582"></p><h3 id="sed-svo-editor">SED_SVO_Editor</h3><h2 id="zed-tutorials">ZED tutorials</h2><p>ZED SDK包括几个教程和示例，用于学习如何使用视频、深度、位置跟踪、地图和其他信息，以及许多第三方集成。自己看吧。代码路径在/usr/local/zed/samples/tutorials里面</p><table><thead><tr><th>Tutorial</th><th>Description</th><th>Link</th></tr></thead><tbody><tr><td><a href="https://www.stereolabs.com/docs/tutorials/hello-zed/">Hello ZED</a></td><td>This is the simplest tutorial. It shows how to open a stereo camera and print its serial number in the terminal.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 1 - hello ZED/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 1 - hello ZED/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/image-capture/">Image Capture</a></td><td>Shows how to open a stereo camera, capture an image and print its timestamp and image size in the terminal.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 2 - image capture/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 2 - image capture/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/depth-sensing/">Depth Perception</a></td><td>Shows how to retrieve the depth and point cloud of a scene, and print the distance of a given point in the terminal.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 3 - depth sensing/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 3 - depth sensing/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/positional-tracking/">Camera Tracking</a></td><td>Shows how to enable positional tracking and get the position and orientation of the camera in real time.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 4 - positional tracking/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 4 - positional tracking/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/spatial-mapping/">Spatial Mapping</a></td><td>Shows how to enable spatial mapping and capture a mesh or fused point cloud of the environment.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 5 - spatial mapping/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 5 - spatial mapping/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/3d-object-detection/">3D Object Detection</a></td><td>Shows how to detect objects in a scene and localize them in 3D.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 6 - object detection/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 6 - object detection/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/using-sensors/">Using Sensors</a></td><td>Shows how to acquire IMU, barometer and magnetometer data.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 7 - sensor data/cpp/) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 7 - sensor data/python/)</td></tr><tr><td><a href="https://www.stereolabs.com/docs/tutorials/body-tracking/">3D Body Tracking</a></td><td>Shows how to detect human body skeletons in a 3D scene.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 7 - sensor data/cpp/) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-sdk/tree/master/tutorials/tutorial</a> 8 - body tracking/python)</td></tr><tr><td>Geo-tracking</td><td>Shows how to use the Geo-tracking Fusion API to display fused GNSS and positional tracking data on a map.</td><td>[C++](<a href="https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-examples/tree/master/tutorials/tutorial</a> 7 - sensor data/cpp/) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/tutorials/tutorial">https://github.com/stereolabs/zed-sdk/tree/master/tutorials/tutorial</a> 8 - body tracking/python)</td></tr></tbody></table><h3 id="只讲解深度图-视差图-彩色图获取">只讲解深度图/视差图/彩色图获取</h3><p>要获得数据，首先要使用grab函数获得数据</p><p>然后通过retrieve_image函数获得每个视角的彩色图等</p><p>然后通过retrieve_measure函数获得每个视角的深度图视差图等</p><p>默认名称获得的是左视角的深度图和视差图，比如说DEPTH是指左目的深度图，如果想获得右目的，那就得参数为DEPTH_RIGHT</p><table><thead><tr><th>Enumerator</th><th></th></tr></thead><tbody><tr><td>DISPARITY</td><td>Disparity map. Each pixel contains 1 float.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C1</a></td></tr><tr><td>DEPTH</td><td>Depth map in <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1UNIT.html">sl.UNIT</a> defined in <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1InitParameters.html#a59b4de42de6f091613c01daa1c82e37b">sl.InitParameters.coordinate_units</a>. Each pixel contains 1 float.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C1</a></td></tr><tr><td>CONFIDENCE</td><td>Certainty/confidence of the depth map. Each pixel contains 1 float.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C1</a></td></tr><tr><td>XYZ</td><td>Point cloud. Each pixel contains 4 float (X, Y, Z, not used).  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZRGBA</td><td>Colored point cloud. Each pixel contains 4 float (X, Y, Z, color).  The color should to be read as an unsigned char[4] representing the RGBA color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZBGRA</td><td>Colored point cloud. Each pixel contains 4 float (X, Y, Z, color).  The color should to be read as an unsigned char[4] representing the BGRA color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZARGB</td><td>Colored point cloud. Each pixel contains 4 float (X, Y, Z, color).  The color should to be read as an unsigned char[4] representing the ARGB color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZABGR</td><td>Colored point cloud. Each pixel contains 4 float (X, Y, Z, color).  The color should to be read as an unsigned char[4] representing the ABGR color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>NORMALS</td><td>Normal vectors map. Each pixel contains 4 float (X, Y, Z, 0).  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>DISPARITY_RIGHT</td><td>Disparity map for right sensor. Each pixel contains 1 float.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C1</a></td></tr><tr><td>DEPTH_RIGHT</td><td>Depth map for right sensor. Each pixel contains 1 float.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C1</a></td></tr><tr><td>XYZ_RIGHT</td><td>Point cloud for right sensor. Each pixel contains 4 float (X, Y, Z, not used).  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZRGBA_RIGHT</td><td>Colored point cloud for right sensor. Each pixel contains 4 float (X, Y, Z, color).  The color needs to be read as an unsigned char[4] representing the RGBA color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZBGRA_RIGHT</td><td>Colored point cloud for right sensor. Each pixel contains 4 float (X, Y, Z, color).  The color needs to be read as an unsigned char[4] representing the BGRA color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZARGB_RIGHT</td><td>Colored point cloud for right sensor. Each pixel contains 4 float (X, Y, Z, color).  The color needs to be read as an unsigned char[4] representing the ARGB color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>XYZABGR_RIGHT</td><td>Colored point cloud for right sensor. Each pixel contains 4 float (X, Y, Z, color).  The color needs to be read as an unsigned char[4] representing the ABGR color.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>NORMALS_RIGHT</td><td>Normal vectors map for right view. Each pixel contains 4 float (X, Y, Z, 0).  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.F32_C4</a></td></tr><tr><td>DEPTH_U16_MM</td><td>Depth map in millimeter whatever the <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1UNIT.html">sl.UNIT</a> defined in <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1InitParameters.html#a59b4de42de6f091613c01daa1c82e37b">sl.InitParameters.coordinate_units</a>.  Invalid values are set to 0 and depth values are clamped at 65000.  Each pixel contains 1 unsigned short.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.U16_C1</a></td></tr><tr><td>DEPTH_U16_MM_RIGHT</td><td>Depth map in millimeter for right sensor. Each pixel contains 1 unsigned short.  Type: <a href="https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1MAT__TYPE.html">sl.MAT_TYPE.U16_C1</a></td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########################################################################</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Copyright (c) 2022, STEREOLABS.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># All rights reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS</span></span><br><span class="line"><span class="comment"># &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT</span></span><br><span class="line"><span class="comment"># LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR</span></span><br><span class="line"><span class="comment"># A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT</span></span><br><span class="line"><span class="comment"># OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,</span></span><br><span class="line"><span class="comment"># SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT</span></span><br><span class="line"><span class="comment"># LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,</span></span><br><span class="line"><span class="comment"># DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY</span></span><br><span class="line"><span class="comment"># THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT</span></span><br><span class="line"><span class="comment"># (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE</span></span><br><span class="line"><span class="comment"># OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span></span><br><span class="line"><span class="comment"># 我自己根据官方的sample改的</span></span><br><span class="line"><span class="comment">########################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pyzed.sl <span class="keyword">as</span> sl</span><br><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_camera_information</span>(<span class="params">cam_info</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ZED Model                 : &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(cam_info.camera_model))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ZED Serial Number         : &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(cam_info.serial_number))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ZED Camera Firmware       : &#123;0&#125;/&#123;1&#125;&quot;</span>.<span class="built_in">format</span>(cam_info.camera_configuration.firmware_version,</span><br><span class="line">                                                       cam_info.sensors_configuration.firmware_version))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ZED Camera Resolution     : &#123;0&#125;x&#123;1&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>(cam_info.camera_configuration.resolution.width, <span class="number">2</span>),</span><br><span class="line">                                                       cam_info.camera_configuration.resolution.height))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ZED Camera FPS            : &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(cam_info.camera_configuration.fps))</span><br><span class="line">)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 找到相机，创建相机对象</span></span><br><span class="line">    zed = sl.Camera()</span><br><span class="line">    <span class="comment"># 这个param需要设置开启相机的参数</span></span><br><span class="line">    init_params = sl.InitParameters()</span><br><span class="line">    <span class="comment"># 这里要获得左右视差图，深度图，点云数据，所以要开启右侧测量</span></span><br><span class="line">    init_params.enable_right_side_measure=<span class="literal">True</span></span><br><span class="line">    <span class="comment"># 拍摄2k的图像，或者1080,720，参数查询https://www.stereolabs.com/docs/api/python/classpyzed_1_1sl_1_1RESOLUTION.html</span></span><br><span class="line">    init_params.camera_resolution = sl.RESOLUTION.HD720   <span class="comment"># Use HD2K HD720 opr HD1200 video mode, depending on camera type.</span></span><br><span class="line">    <span class="comment"># 存图路径</span></span><br><span class="line">    filefolder_name = <span class="string">&quot;2_720&quot;</span></span><br><span class="line">    <span class="comment"># init_params.camera_fps = 30  # Set fps at 30</span></span><br><span class="line">    <span class="comment"># 这里是所有更改的参数，请配合SetCameraSettings文件使用</span></span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.LED_STATUS, <span class="literal">True</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.BRIGHTNESS, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.CONTRAST, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.HUE, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.SATURATION, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.SHARPNESS, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.GAIN, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.EXPOSURE, -<span class="number">1</span>)</span><br><span class="line">    zed.set_camera_settings(sl.VIDEO_SETTINGS.WHITEBALANCE_TEMPERATURE, -<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[Sample] Reset all settings to default&quot;</span>)</span><br><span class="line">    err = zed.<span class="built_in">open</span>(init_params)</span><br><span class="line">    <span class="keyword">if</span> err != sl.ERROR_CODE.SUCCESS:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Camera Open : &quot;</span>+<span class="built_in">repr</span>(err)+<span class="string">&quot;. Exit program.&quot;</span>)</span><br><span class="line">        exit()</span><br><span class="line">    <span class="comment"># Capture flag</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    image_left = sl.Mat()  <span class="comment"># 图像</span></span><br><span class="line">    disparity_left = sl.Mat()  <span class="comment"># 视差值</span></span><br><span class="line">    dep_left = sl.Mat()  <span class="comment"># 深度图</span></span><br><span class="line">    depth_left = sl.Mat()  <span class="comment"># 深度值</span></span><br><span class="line">    point_cloud_left = sl.Mat()  <span class="comment"># 点云数据</span></span><br><span class="line">    </span><br><span class="line">    image_right = sl.Mat()  <span class="comment"># 图像</span></span><br><span class="line">    disparity_right = sl.Mat()  <span class="comment"># 视差值</span></span><br><span class="line">    dep_right = sl.Mat()  <span class="comment"># 深度图</span></span><br><span class="line">    depth_right = sl.Mat()  <span class="comment"># 深度值</span></span><br><span class="line">    point_cloud_right = sl.Mat()  <span class="comment"># 点云数据</span></span><br><span class="line">    runtime_parameters = sl.RuntimeParameters()</span><br><span class="line">     <span class="comment"># 获取分辨率</span></span><br><span class="line">    cam_info = zed.get_camera_information()</span><br><span class="line">    print_camera_information(cam_info)</span><br><span class="line">    w, h = cam_info.camera_configuration.resolution.width , cam_info.camera_configuration.resolution.height</span><br><span class="line">    x,y = <span class="built_in">int</span>(w/<span class="number">2</span>),<span class="built_in">int</span>(h/<span class="number">2</span>)  <span class="comment"># 中心点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得当前相机的两个相机的标定参数，Intrinsics and extrinsic stereo parameters for rectified/undistorted images. </span></span><br><span class="line">    calibration_params = zed.get_camera_information().camera_configuration.calibration_parameters</span><br><span class="line">    <span class="comment"># Focal length of the left eye in pixels</span></span><br><span class="line">    focal_left_x = calibration_params.left_cam.fx</span><br><span class="line">    focal_left_y = calibration_params.left_cam.fy</span><br><span class="line">    opticalCenter_left_x = calibration_params.left_cam.cx</span><br><span class="line">    opticalCenter_left_y = calibration_params.left_cam.cy</span><br><span class="line">    distolist_lfet  = calibration_params.left_cam.disto</span><br><span class="line">    focal_length_meteric_left = calibration_params.left_cam.focal_length_metric</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Focal length of the right eye in pixels</span></span><br><span class="line">    focal_right_x = calibration_params.right_cam.fx</span><br><span class="line">    focal_right_y = calibration_params.right_cam.fy</span><br><span class="line">    opticalCenter_right_x = calibration_params.right_cam.cx</span><br><span class="line">    opticalCenter_right_y = calibration_params.right_cam.cy</span><br><span class="line">    distolist_right  = calibration_params.right_cam.disto</span><br><span class="line">    focal_length_meteric_right = calibration_params.right_cam.focal_length_metric</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;左目焦距&#x27;</span>,focal_left_x,focal_left_y,<span class="string">&#x27;右目焦距&#x27;</span>,focal_right_x,focal_right_y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;左目光心&#x27;</span>,opticalCenter_left_x,opticalCenter_left_y,<span class="string">&#x27;右目光心&#x27;</span>,opticalCenter_right_x,opticalCenter_right_y) </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;左目畸变参数&#x27;</span>,distolist_lfet,<span class="string">&#x27;右目畸变参数&#x27;</span>,distolist_right)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;左目焦距&#x27;</span>,focal_length_meteric_left,<span class="string">&#x27;右目焦距&#x27;</span>,focal_length_meteric_right)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得双目的联合标定参数，看看需要什么</span></span><br><span class="line">    <span class="comment"># get translation and rotation</span></span><br><span class="line">    rotation = calibration_params.stereo_transform.get_rotation_matrix()<span class="comment">#  3*3 matrix sl.Matrix3f</span></span><br><span class="line">    translation = calibration_params.stereo_transform.get_translation().get() <span class="comment"># [tx, ty, tz] </span></span><br><span class="line">    <span class="comment"># Returns the baseline of the camera in the sl.UNIT defined in sl.InitParameters.coordinate_units. </span></span><br><span class="line">    baseline = calibration_params.get_camera_baseline()</span><br><span class="line">    <span class="comment"># Translation between left and right eye on x-axis</span></span><br><span class="line">    tx = calibration_params.stereo_transform.get_translation().get()[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;平移向量&#x27;</span>,translation)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;旋转矩阵&#x27;</span>,rotation) </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;双目基线&#x27;</span>,baseline,<span class="string">&#x27;左右相机的x轴平移&#x27;</span>,tx)</span><br><span class="line">    <span class="comment"># 导出标定参数到txt文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filefolder_name+<span class="string">&quot;/calibration_parameters.txt&quot;</span>, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(<span class="string">&quot;左目焦距: fx = &#123;0&#125;, fy = &#123;1&#125;\n&quot;</span>.<span class="built_in">format</span>(focal_left_x, focal_left_y))</span><br><span class="line">        file.write(<span class="string">&quot;右目焦距: fx = &#123;0&#125;, fy = &#123;1&#125;\n&quot;</span>.<span class="built_in">format</span>(focal_right_x, focal_right_y))</span><br><span class="line">        file.write(<span class="string">&quot;左目光心: cx = &#123;0&#125;, cy = &#123;1&#125;\n&quot;</span>.<span class="built_in">format</span>(opticalCenter_left_x, opticalCenter_left_y))</span><br><span class="line">        file.write(<span class="string">&quot;右目光心: cx = &#123;0&#125;, cy = &#123;1&#125;\n&quot;</span>.<span class="built_in">format</span>(opticalCenter_right_x, opticalCenter_right_y))</span><br><span class="line">        file.write(<span class="string">&quot;畸变参数格式: [k1, k2, p1, p2, k3, k4, k5, k6, s1, s2, s3, s4]\n&quot;</span>)</span><br><span class="line">        file.write(<span class="string">&quot;左目畸变参数: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(distolist_lfet))</span><br><span class="line">        file.write(<span class="string">&quot;右目畸变参数: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(distolist_right))</span><br><span class="line">        file.write(<span class="string">&quot;左目焦距 (米): &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(focal_length_meteric_left))</span><br><span class="line">        file.write(<span class="string">&quot;右目焦距 (米): &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(focal_length_meteric_right))</span><br><span class="line">        file.write(<span class="string">&quot;双目基线: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(baseline))</span><br><span class="line">        file.write(<span class="string">&quot;左右相机的x轴平移: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(tx))</span><br><span class="line">        file.write(<span class="string">&quot;旋转矩阵: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(rotation))</span><br><span class="line">        file.write(<span class="string">&quot;平移向量: &#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(translation))</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 获取最新的图像，修正它们，并基于提供的RuntimeParameters(深度，点云，跟踪等)计算测量值。</span></span><br><span class="line">        <span class="keyword">if</span> zed.grab(runtime_parameters) == sl.ERROR_CODE.SUCCESS:  <span class="comment"># 相机成功获取图象</span></span><br><span class="line">            timestamp = zed.get_timestamp(sl.TIME_REFERENCE.CURRENT)  <span class="comment"># 获取图像被捕获时的时间点，用于图像命名</span></span><br><span class="line">            <span class="comment"># 获取左目图像</span></span><br><span class="line">            zed.retrieve_image(image_left, sl.VIEW.LEFT)  <span class="comment"># image：容器，sl.VIEW.LEFT：内容</span></span><br><span class="line">            d_image_left = image_left.get_data()  <span class="comment"># 转换成图像数组，便于后续的显示或者储存</span></span><br><span class="line">            <span class="comment"># 获取视差值</span></span><br><span class="line">            zed.retrieve_measure(disparity_left,sl.MEASURE.DISPARITY,sl.MEM.CPU)</span><br><span class="line">            d_disparity_left = disparity_left.get_data()</span><br><span class="line">            zed.retrieve_image(dep_left,sl.VIEW.DEPTH)  <span class="comment"># 深度图</span></span><br><span class="line">            d_dep_left = dep_left.get_data()</span><br><span class="line">            <span class="comment"># 获取深度</span></span><br><span class="line">            zed.retrieve_measure(depth_left,sl.MEASURE.DEPTH,sl.MEM.CPU)  <span class="comment"># 深度值</span></span><br><span class="line">            d_depth_left = depth_left.get_data()</span><br><span class="line">            <span class="comment"># 获取点云</span></span><br><span class="line">            zed.retrieve_measure(point_cloud_left,sl.MEASURE.XYZBGRA,sl.MEM.CPU)</span><br><span class="line">            d_point_map_left = point_cloud_left.get_data()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取左目图像</span></span><br><span class="line">            zed.retrieve_image(image_right, sl.VIEW.RIGHT)  <span class="comment"># image：容器，sl.VIEW.right：内容</span></span><br><span class="line">            d_image_right = image_right.get_data()  <span class="comment"># 转换成图像数组，便于后续的显示或者储存</span></span><br><span class="line">            <span class="comment"># 获取视差值</span></span><br><span class="line">            zed.retrieve_measure(disparity_right,sl.MEASURE.DISPARITY_RIGHT ,sl.MEM.CPU)</span><br><span class="line">            d_disparity_right = disparity_right.get_data()</span><br><span class="line">            <span class="comment"># 获取深度</span></span><br><span class="line">            zed.retrieve_measure(depth_right,sl.MEASURE.DEPTH_RIGHT,sl.MEM.CPU)  <span class="comment"># 深度值</span></span><br><span class="line">            d_depth_right = depth_right.get_data()</span><br><span class="line">            zed.retrieve_image(dep_right,sl.VIEW.DEPTH_RIGHT)  <span class="comment"># 深度图</span></span><br><span class="line">            d_dep_right = dep_right.get_data()</span><br><span class="line">            <span class="comment"># 获取点云</span></span><br><span class="line">            zed.retrieve_measure(point_cloud_right,sl.MEASURE.XYZBGRA_RIGHT,sl.MEM.CPU)</span><br><span class="line">            d_point_cloud_right = point_cloud_right.get_data()</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;时间点&#x27;</span>,timestamp.get_seconds(),<span class="string">&#x27;中心点视差值&#x27;</span>,d_disparity_left[x,y],<span class="string">&#x27;中心点深度值&#x27;</span>,d_depth_left[x,y],<span class="string">&#x27;中心点云数据&#x27;</span>,d_point_map_left[x,y])</span><br><span class="line">            <span class="comment"># 利用cv2.imshow显示视图，并对想要的视图进行保存</span></span><br><span class="line">            view_color = np.concatenate((cv2.resize(d_image_left,(<span class="number">640</span>,<span class="number">360</span>)),cv2.resize(d_image_right,(<span class="number">640</span>,<span class="number">360</span>))),axis=<span class="number">1</span>)</span><br><span class="line">            cv2.imshow(<span class="string">&quot;ColorImage&quot;</span>, view_color)</span><br><span class="line">            view_depth = np.concatenate((cv2.resize(d_dep_left,(<span class="number">640</span>,<span class="number">360</span>)),cv2.resize(d_dep_right,(<span class="number">640</span>,<span class="number">360</span>))),axis=<span class="number">1</span>)</span><br><span class="line">            cv2.imshow(<span class="string">&quot;DepthImage&quot;</span>, view_depth)</span><br><span class="line">            key = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> key &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):  <span class="comment"># q退出</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> key &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;s&#x27;</span>):  <span class="comment"># 图像保存</span></span><br><span class="line">                timestamp_ms = timestamp.get_milliseconds()</span><br><span class="line">                savePath = os.path.join(filefolder_name + <span class="string">&quot;/images&quot;</span>, <span class="string">&quot;left_&#123;:0&gt;3d&#125;.png&quot;</span>.<span class="built_in">format</span>(i))  <span class="comment"># 注意根目录是否存在&quot;./images&quot;文件夹</span></span><br><span class="line">                cv2.imwrite(savePath, d_image_left)</span><br><span class="line">                savePath = os.path.join(filefolder_name+ <span class="string">&quot;/images&quot;</span>, <span class="string">&quot;right_&#123;:0&gt;3d&#125;.png&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">                cv2.imwrite(savePath, d_image_right)</span><br><span class="line">                i = i + <span class="number">1</span></span><br><span class="line">    <span class="comment"># Close the camera</span></span><br><span class="line">    zed.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/home/outbreak/BlogOutbreak/source/_posts/zed%E7%9B%B8%E6%9C%BA%E4%BD%BF%E7%94%A8/image-20250216160621095.png" alt="image-20250216160621095"></p><h2 id="sample-usage">Sample usage</h2><table><thead><tr><th>Sample</th><th>Description</th><th>Link</th></tr></thead><tbody><tr><td>Camera Control</td><td>Shows how camera settings like Exposure, Gain, Contrast, Sharpness, etc. can be modified and display the resulting image.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/camera">https://github.com/stereolabs/zed-sdk/tree/master/camera</a> control/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/camera">https://github.com/stereolabs/zed-sdk/tree/master/camera</a> control/python)</td></tr><tr><td>Camera Streaming</td><td>Shows how to stream the ZED stereo video on an IP network, decode the video and display its live 3D point cloud.</td><td>[GitHub](<a href="https://github.com/stereolabs/zed-sdk/tree/master/camera">https://github.com/stereolabs/zed-sdk/tree/master/camera</a> streaming)</td></tr><tr><td>Depth Sensing</td><td>Shows how to capture a 3D point cloud and display it in an OpenGL window.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/depth">https://github.com/stereolabs/zed-sdk/tree/master/depth</a> sensing/depth sensing/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/depth">https://github.com/stereolabs/zed-sdk/tree/master/depth</a> sensing/depth sensing/python)</td></tr><tr><td>Positional Tracking</td><td>Displays the live position and orientation of the camera in a 3D window.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/positional">https://github.com/stereolabs/zed-sdk/tree/master/positional</a> tracking/positional tracking/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/positional">https://github.com/stereolabs/zed-sdk/tree/master/positional</a> tracking/positional tracking/python)</td></tr><tr><td>Spatial Object Detection</td><td><strong>2D Display</strong> Detect and track objects in the scene, and display their 3D bounding boxes over the live image.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/object">https://github.com/stereolabs/zed-sdk/tree/master/object</a> detection/image viewer/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/object">https://github.com/stereolabs/zed-sdk/tree/master/object</a> detection/image viewer/python)</td></tr><tr><td>Spatial Object Detection</td><td><strong>3D Display</strong> Detect and track objects in the scene, and display their 3D bounding boxes over the live point cloud.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/object">https://github.com/stereolabs/zed-sdk/tree/master/object</a> detection/birds eye viewer/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/object">https://github.com/stereolabs/zed-sdk/tree/master/object</a> detection/birds eye viewer/cpp)</td></tr><tr><td>Body Tracking</td><td>Shows how to detect and track 3D human bodies in space and display skeletons over the live image.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/body">https://github.com/stereolabs/zed-sdk/tree/master/body</a> tracking/body tracking/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/body">https://github.com/stereolabs/zed-sdk/tree/master/body</a> tracking/body tracking/python)</td></tr><tr><td>Spatial Mapping</td><td>Captures a live 3D mesh of the environment and displays it as an overlay on the camera image.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/spatial">https://github.com/stereolabs/zed-sdk/tree/master/spatial</a> mapping/spatial mapping/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/spatial">https://github.com/stereolabs/zed-sdk/tree/master/spatial</a> mapping/spatial mapping/python)</td></tr><tr><td>Plane Detection</td><td>Shows how to detect floor and planar areas in the scene and draw them on the image.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/plane">https://github.com/stereolabs/zed-sdk/tree/master/plane</a> detection/plane detection/cpp) [Python](<a href="https://github.com/stereolabs/zed-examples/tree/master/plane">https://github.com/stereolabs/zed-examples/tree/master/plane</a> detection/plane detection/python)</td></tr><tr><td>Video Recording</td><td>Shows how to record a lossless or compressed video in SVO format.</td><td><a href="https://github.com/stereolabs/zed-sdk/tree/master/recording/recording/mono/cpp">C++</a> <a href="https://github.com/stereolabs/zed-sdk/tree/master/recording/recording/mono/python">Python</a></td></tr><tr><td>Video Playback</td><td>Shows how to playback a recorded SVO video.</td><td><a href="https://github.com/stereolabs/zed-sdk/tree/master/recording/playback/mono/cpp">C++</a> <a href="https://github.com/stereolabs/zed-sdk/tree/master/recording/playback/mono/python">Python</a></td></tr><tr><td>Video Export</td><td>Opens an SVO file and exports video and depth to PNG or AVI files.</td><td><a href="https://github.com/stereolabs/zed-sdk/tree/master/recording/export/svo/cpp">C++</a> <a href="https://github.com/stereolabs/zed-sdk/tree/master/recording/export/svo/python">Python</a></td></tr><tr><td>Multi Camera</td><td>Shows how to open and use multiple ZED cameras at the same time in a single application.</td><td>[C++](<a href="https://github.com/stereolabs/zed-sdk/tree/master/depth">https://github.com/stereolabs/zed-sdk/tree/master/depth</a> sensing/multi camera/cpp) [Python](<a href="https://github.com/stereolabs/zed-sdk/tree/master/depth">https://github.com/stereolabs/zed-sdk/tree/master/depth</a> sensing/multi camera/cpp)</td></tr></tbody></table><p>正在更新</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Zed相机的驱动安装和图像视频获取&lt;/h1&gt;
&lt;p&gt;和众多的深度相机一样，下载SDK，然后SDK里有个上位机可以用来快速的获取视频和可视化，然后还有一套ROS，C++，python的API可以编写一些定制程序。&lt;/p&gt;
&lt;p&gt;型号&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/ho</summary>
      
    
    
    
    
    <category term="深度相机" scheme="http://outbreak-sen.github.io/tags/%E6%B7%B1%E5%BA%A6%E7%9B%B8%E6%9C%BA/"/>
    
    <category term="相机驱动" scheme="http://outbreak-sen.github.io/tags/%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8/"/>
    
  </entry>
  
  <entry>
    <title>FPV ESC学习笔记</title>
    <link href="http://outbreak-sen.github.io/2025/02/13/FPV-ESC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://outbreak-sen.github.io/2025/02/13/FPV-ESC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2025-02-13T02:17:58.000Z</published>
    <updated>2025-03-19T09:12:17.160Z</updated>
    
    <content type="html"><![CDATA[<h1>BLheli电调与Dshot通讯</h1><p>这里首先介绍一下基本概念</p><ul><li><p>电调ESC：全称电子速度控制器，一个电机需要控制转动，需要电调ESC，电调负责把输入的直流电转化为三相电等输入，根据飞行控制器的输入指令（FC）调节电机的速度（和方向）。。</p></li><li><p>电调原理：电调是芯片加一堆mos组成的，芯片负责接收控制信号，然后控制mos的通断，把输入的直流电通过mos通断变化为不同的三相电等</p></li><li><p>电调固件：电调里面的芯片会烧录一个程序，这个程序就是电调固件，这个电调固件有很多开源的方案，比如BLHeli，BLHeli_S，这些是写好的，并且有很多功能比如温度控制等。</p></li><li><p>电调通讯协议：电调里的芯片接收控制信号也有很多，称为电调通讯协议，比如Dshot，PWM，Oneshot，其中dshot是目前最好的。有人提出这些通讯协议之后，这些BLHeli之类的固件就会兼容这些协议，比如BLHeli一般是兼容PWM，Oneshot，Dshot的。<strong>其中PWM的是需要校准最小值和最大值之后才能控制。</strong></p></li><li><p>电调固件如何兼容不同协议：电调固件兼容各种电调通讯协议，具体而言，在固件里有一个分类器，输入不同协议的命令，他会先判别是什么协议然后再执行。<br><a href="https://www.cnblogs.com/Sky-seeker/p/14358676.html">一个参考-无刷电调基础知识以及BLHeli固件烧录和参数调整 - 梦幻之心星 - 博客园 (cnblogs.com)</a></p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/122a27a4aa9bf878d4eef13b5458fdd5.jpeg" alt="电调工作原理"></p></li></ul><h2 id="电调固件">电调固件</h2><p>电调固件是在每个电调上运行的软件，它确定电调的性能，支持的协议以及可以使用的配置接口。电调可以使用的固件取决于硬件。</p><ul><li><strong>SimonK</strong>：最古老的两种开源电调固件之一，已经过时不再更新。内嵌了一个开环foc驱动</li><li><strong>BLHeli</strong>：最古老的两种开源电调固件之一，由于其广泛的功能和友好的用户界面而变得流行。</li><li><strong>BLHeli_S</strong>：BLHeli固件的第二代。专门为具有<em>Busybee</em>处理器的电调开发。</li><li><strong>BLHeli_32</strong>：第三代和最新一代BLHeli固件。专门为32位电调编写，不再开源。</li></ul><h2 id="blheli固件">BLheli固件</h2><h4 id="固件命名：">固件命名：</h4><p>BLHeli_S代码除了修订版外，还用一个字母、另一个字母和两个数字命名。例如&quot;A_L_10_REV16_0.HEX&quot;。</p><p>第一个字母表示MCU的引脚；</p><p>第二个字母是L或H（L代表24MHz MCU，H代表48MHz MCU）；</p><p>这两个数字表示FET的开关死区时间。单位为20.4ns。一些场效应晶体管驱动器具有自适应场效应晶体管死区时间控制，对于这些MOS管，则用00表示场效应晶体管开关死区时间。</p><h4 id="可设置参数">可设置参数</h4><ul><li><p>启动功率：启动功率可设置为0.031到1.5之间的相对值。这是启动期间允许的最大功率。实际应用的功率取决于节气门输入，可以更低，但最低电平是最高电平的四分之一。启动功率也会影响双向操作，因为该参数用于限制方向反转期间应用的功率。于低转速，电机的最大功率是有限的，以便于检测低反电势电压。允许的最大功率可通过启动功率参数设置。较低的启动功率参数将为较低转速提供较低的最大功率（这从rev16.1开始实施）。</p></li><li><p>**换向时间：**换向定时可设置为低/中低/中/中高/高，对应于00/7.50/150/22.50/300定时提前。一般来说，一个中等设置将工作良好，但如果电机口吃它可以是有益的改变时间。一些高电感的电机可以有很长的换相退磁时间。这可能会导致电机停止或口吃时，快速油门增加，特别是在运行在低转速。将定时设置为高将允许更多的时间去消磁，通常是有帮助的。</p></li><li><p>**消磁补偿：**消磁补偿是一种保护电机不因换相后较长的绕组退磁时间而失速的功能。典型的症状是发动机停止或快速增加油门时卡顿，特别是在低转速运行时。如上所述，设置高换向时间通常有帮助，但以效率为代价。</p></li><li><p>**方向：**旋转方向可设置为前进/后退/双向前进/双向后退。在双向模式下，中央油门为零，上面为前进方向旋转，下面为反向旋转。当选择双向操作时，TX编程被禁用。</p></li><li><p>**嘟嘟声强度：**设置正常运行时的蜂鸣音强度。</p></li><li><p>**信标强度：**设置蜂鸣信标蜂鸣时蜂鸣的强度。如果油门信号在给定时间内为零，电子悬架控制系统将开始发出蜂鸣声。请注意，设置高信标强度可能会导致电机或ESC过热！</p></li><li><p>**信标延迟：**信标延迟设置信标哔哔声开始前的延迟。</p></li><li><p>**最小油门、最大油门和中值油门：**这些设置设置ESC的油门范围。中央油门仅用于双向操作。为这些设置提供的值适用于正常的1000us到2000us输入信号，对于其他输入信号，这些值必须按比例缩放。</p></li><li><p>**热保护：**可以启用或禁用热保护。温度阈值可以在800C和1400C之间编程（可编程阈值从rev16.3开始执行）。可编程阈值主要是为了支持硬件制造商使用，因为不同的硬件可以对所使用的各种组件的最高温度有不同的公差。</p></li><li><p>**低转速功率保护：**可以启用或禁用低转速的功率限制。禁用它可能是必要的，以实现在低电源电压下运行的一些低kV电机的全功率。但是，禁用它会增加同步丢失的风险，并可能导致电机或电子稳定控制系统过热。</p></li><li><p>**停止时制动：**可以启用或禁用制动停止。启用时，油门为零时将应用制动器。对于非零油门，此设置无效。</p></li><li><p>**LED控制：**LED可以在支持它的ESC上控制。最多可以打开或关闭4个LED。</p></li></ul><h3 id="blheli蜂鸣器含义">BLHeli蜂鸣器含义</h3><p>对于BLHeli电调，上电的时候会发出一些声音，实际上每个声音都有自己的意思，如下：</p><ul><li>100%上电时，电子稳定控制系统鸣叫3次。</li><li>当检测到油门信号时，它会发出一声低沉的哔哔声。这表示开始警戒序列。</li><li>然后，当或如果油门为零，它会发出一声高音哔哔声。这标志着警戒序列的结束。</li><li>此外，如果在启用顺序期间检测到100%油门，电子悬架控制系统将开始油门校准。</li><li>如果电子稳定控制系统处于待命状态，并在给定时间内看到零油门，它会发出信标哔哔声，大约每三秒发出一声哔哔声。</li></ul><h3 id="blheli的热保护：">BLHeli的热保护：</h3><p>ESC测量MCU内的温度，如果温度过高，则限制电机功率。电机功率分四步限制：</p><p>-  如果温度高于临界值，电机功率限制在75%。</p><p>-  如果温度高于阈值加上50摄氏度，电机功率限制在50%。</p><p>-  如果温度高于阈值加上100摄氏度，电机功率限制在25%。</p><p>-  如果温度高于阈值+150℃，则电机功率限制为0%。</p><h3 id="blheli上位机-blheli-suite">BLheli上位机——BLheli suite</h3><p>传统改变固件参数的方法是编译一个固件之后通过arduino nano烧录到电调里面来设置如上一堆值。</p><p>但是现在有了BLheli，可以通过上位机对电调进行参数修改，具体方法是用一个betaflight的飞控板连接上电调，用电调来改。</p><h3 id="blheli固件烧录">BLheli固件烧录</h3><p>比较简单，但是需要arduino uno，CH340，BLheli Suite，可以搜一下教程，需要把几个焊点和arduino连接，或者直接用Betaflight的飞控板貌似也能烧录。</p><p><a href="https://www.elvinplay.com/how-to-flash-esc-with-blheli-without-soldering/">懒人免焊接傻瓜包会从零开始给电调刷BLHELI固件 – Elvin Play</a></p><h2 id="电调协议">电调协议</h2><p>电调协议是飞行控制器和电调用于通信的<em>语言</em>，决定了信号从飞控到电调的发送速度。四轴飞行器使用的电调协议及信号宽度如下，从上而下依次高级</p><ul><li>最传统PWM ：1000us – 2000us</li><li><a href="https://oscarliang.com/oneshot125-esc-quadcopter-fpv/">Oneshot125模拟协议</a>：125us – 250us</li><li><a href="http://intofpv.com/t-oneshot42-explained-kiss-esc-fc-protocol">Oneshot 42模拟协议</a>：2us – 84us</li><li><a href="https://oscarliang.com/raceflight-multishot/">Multishot模拟协议</a>：5us – 25us</li><li>Dshot数字协议<ul><li>Dshot150 ：106.8us</li><li>Dshot300 ：53.4us</li><li>Dshot600 ：26.7us</li><li><a href="https://oscarliang.com/dshot1200-esc-protocol/">DShot1200</a>：13.4us</li></ul></li><li>ProShot</li></ul><h3 id="模拟电调和数字电调区别">模拟电调和数字电调区别</h3><p>模拟电调协议每隔几微秒就将电脉冲从飞控发送到电调。脉冲持续时间的长短（油门大小）决定了电机的功率。这种控制方案受到电噪声和电脉冲定时精度的限制。</p><p>使用 DShot 数字电调意味着飞控将以数字编号的形式向电调发送精确的油门值。这个数字将有一个校验值，以便从飞控发送到电调的油门值永远不会被识别错误。</p><p>与Oneshot和Multishot相比，DShot有什么优势：</p><ul><li>无需进行电调行程校准</li><li>更精确的传输信号，更强大的抗干扰能力</li><li>分辨率为2048，而其他协议分辨率为1000</li><li>比Oneshot协议更快</li><li>更安全，每个信号 电调都可以检测yifan损坏的数据</li><li>DSHOT并不是效率最高的协议</li></ul><h2 id="pwm">PWM</h2><p>PWM ESC 通常用于固定翼车辆和地面航模，对于FPV通常使用 oneshot 或 dshot ESC，但这是最传统的电调通讯协议。PWM ESC 使用周期性脉冲进行通信，其中脉冲的宽度表示所需的功率水平。脉冲带宽通常介于 1000uS （零功率） 和 2000uS （全功率） 之间。信号的周期性帧速率取决于 ESC 的能力，通常在 50Hz 和 490 Hz 之间理论最大值为 500Hz，速率越高，ESC 越好，尤其是在需要快速响应设定值变化的情况下。对于 PWM 伺服系统，50Hz 通常就足够了，许多不支持更高的速率。</p><h2 id="oneshot">Oneshot</h2><p>OneShot 125 电调通常比 PWM 电调快得多，因此响应更快，更容易调整。对于多旋翼飞行器，它们比 PWM 更受欢迎，但不如 DShot ESC，因为Dshot不需要校准，并且可以提供遥测反馈。OneShot 协议有许多变体，它们支持不同的速率，比如oneshot42,oneshot125。</p><p>OneShot 125 与 PWM 相同，但使用的脉冲宽度短 8 倍（从 125us 到 250us，从零功率到全功率）。这使得 OneShot 125  ESC 具有更短的占空比/更高的速率。对于 PWM，理论最大值接近 500 Hz，而对于 OneShot，则接近 4  kHz。实际支持的速率取决于所使用的 ESC。</p><h2 id="dshot">Dshot</h2><p>DShot（Digital Shot，是数字协议）（相对于oneshot，oneshot125，oneshot42，multishot等模拟协议）。它最初是由Felix在KISS提出的，后来被Betaflight和BLHeli_S开发团队采用。<strong>是用来和刷有BLheli固件的电调通讯的协议。</strong></p><ul><li>BLHeli固件开源地址：<a href="https://github.com/bitdump/BLHeli.git">https://github.com/bitdump/BLHeli.git</a></li><li>BLHeli上位机：<a href="https://github.com/blheli-configurator/blheli-configurator.git">https://github.com/blheli-configurator/blheli-configurator.git</a></li></ul><h3 id="dshot的速度">DShot的速度</h3><p>目前常用的DShot协议有：DShot600，DShot300，DShot150 （DShot1200已经在最新的betaflight4.11固件取消了），其传输速率：</p><ul><li><p>DShot600 – 600,000 bits/Sec</p></li><li><p>DShot300 – 300,000 bits/Sec</p></li><li><p>DShot150 – 150,000 bits/Sec</p></li></ul><p>引入 DSHOT300 和 DSHOT150 是为了确保支持功能较弱的旧ESC电调，DSHOT1200是较新的协仪，有些电调可能还不支持。</p><p>例如，DShot600的频率为600,000 / 1637500hz= 37.5 KHz，这意味着将一个油门值从飞控发送到电调需要大约26.7 uS。各种电调传输协议速度对比与 Oneshot125、 Oneshot42和 Multishot 的速度相比(假设信号是100% 油门)</p><ul><li><p>Oneshot125 – 250 uS</p></li><li><p>DShot150 – 106.7 uS</p></li><li><p>Oneshot42 – 84 uS</p></li><li><p>DShot300 – 53.3 uS</p></li><li><p>DShot600 – 26.7 uS</p></li><li><p>Multishot – 25 uS</p></li></ul><p>快速传输速度的 DShot 理论上将允许高达33KHz的飞控运行频率。但是不要高达37.5 KHz，因为需要留有一些空间。虽然 DShot600没有 Multishot 那么快，但是只要它比飞控运行频率快就足够了。</p><h3 id="dshot600数据帧">Dshot600数据帧</h3><p>一个 DShot 数据包由16位组成</p><ul><li>11位表示油门值(2^10= 2048分辨率)</li><li>1位表示遥测请求是telemetry请求标志，tlm需要电调硬件支持</li><li>4位表示 CRC 校验(循环冗余校验)</li><li>速度600kbits/s，一帧信号的长度为26.7us。</li><li>对于DSHOT600，整个比特位的长度为1.67us（T0H+T0L或T1H+T1L），0的高电平时间为625ns，1的高电平时间是1250ns。</li><li>帧与帧之间需要一点间隔（2-3us），以区别不同的帧信号 <img src="https://i-blog.csdnimg.cn/blog_migrate/0d6a8f70ce815666c70810aeb6ee1ada.png" alt="最详细的DSHOT协议介绍"></li><li>11位油门值可以达到2048的分辨率，实际使用48-2047表示油门值，所以油门信号是2000的分辨率，0是上电后的默认值（锁定值），1-47表示一些命令和设置，一些值的意义如下：<ul><li>1-5：beep（1= low freq. 5 = high freq</li><li>esc信息请求（fw版本和通过tlm线发送的SN）</li><li>7：一个方向旋转</li><li>8：另一个方向旋转</li><li>9：3d模式关闭</li><li>10：3d模式打开</li><li>11：esc设置请求（saved settings over the TLM wire）</li><li>12：保存设置</li></ul></li></ul><h3 id="双向dshot">双向dshot</h3><p>Joe Lucid更进一步引入了双向 DSHOT协议。支持双向dshot的电子调速器ESC能够向飞行控制器发送遥测数据，包括：</p><ul><li>温度</li><li>电压</li><li>当前</li><li>累积电流消耗</li><li>转速值</li></ul><p><strong>这些 DShot ESC 将有一条额外的遥测线。</strong></p><p>要启用此功能（在支持此功能的电调上使用）：将所有电调的遥测线连接在一起，然后将它们连接到未使用的飞行控制器串行端口上的一个 RX 引脚。</p><p>在通讯方式上，双向DSHOT信号使用反转电平（空闲为 1）。 FC 到 ESC 使用 DSHOT 帧，但最低 4 位是其他半字节异或后的反码（正常DSHOT的校验是不反码的）。</p><h2 id="一套dshot通讯参考代码1">一套Dshot通讯参考代码1</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ESC_BIT_0     11</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ESC_BIT_1     22</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ESC_CMD_BUF_LEN 18</span></span><br><span class="line"><span class="type">uint16_t</span> ESC_CMD[ESC_CMD_BUF_LEN]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">uint16_t</span> <span class="title function_">prepareDshotPacket</span><span class="params">(<span class="type">const</span> <span class="type">uint16_t</span> value, <span class="type">int8_t</span> requestTelemetry)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 油门大小为11位  所以这里先左移一位 添加上请求回传标志共12位</span></span><br><span class="line">    <span class="type">uint16_t</span> packet = (value &lt;&lt; <span class="number">1</span>) | (requestTelemetry ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line"><span class="comment">// 将12位数据分为3组 每组4位, 进行异或</span></span><br><span class="line"><span class="comment">// compute checksum</span></span><br><span class="line"><span class="type">int</span> csum = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> csum_data = packet;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">    csum ^=  csum_data;   <span class="comment">// xor data by nibbles</span></span><br><span class="line">    csum_data &gt;&gt;= <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//取最后四位 其他的不要</span></span><br><span class="line">csum &amp;= <span class="number">0xf</span>;</span><br><span class="line"><span class="comment">// append checksum 将CRC添加到后四位</span></span><br><span class="line">packet = (packet &lt;&lt; <span class="number">4</span>) | csum;</span><br><span class="line"><span class="keyword">return</span> packet;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">pwmWriteDigital</span><span class="params">(<span class="type">uint16_t</span> *esc_cmd, <span class="type">uint16_t</span> value)</span></span><br><span class="line">&#123;</span><br><span class="line">value = ( (value &gt; <span class="number">2047</span>) ? <span class="number">2047</span> : value );</span><br><span class="line">value = prepareDshotPacket(value, <span class="number">0</span>);</span><br><span class="line">    esc_cmd[<span class="number">0</span>]  = (value &amp; <span class="number">0x8000</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">1</span>]  = (value &amp; <span class="number">0x4000</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">2</span>]  = (value &amp; <span class="number">0x2000</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">3</span>]  = (value &amp; <span class="number">0x1000</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">4</span>]  = (value &amp; <span class="number">0x0800</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">5</span>]  = (value &amp; <span class="number">0x0400</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">6</span>]  = (value &amp; <span class="number">0x0200</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">7</span>]  = (value &amp; <span class="number">0x0100</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">8</span>]  = (value &amp; <span class="number">0x0080</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">9</span>]  = (value &amp; <span class="number">0x0040</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">10</span>] = (value &amp; <span class="number">0x0020</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">11</span>] = (value &amp; <span class="number">0x0010</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">12</span>] = (value &amp; <span class="number">0x8</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">13</span>] = (value &amp; <span class="number">0x4</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">14</span>] = (value &amp; <span class="number">0x2</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    esc_cmd[<span class="number">15</span>] = (value &amp; <span class="number">0x1</span>) ? ESC_BIT_1 : ESC_BIT_0;</span><br><span class="line">    HAL_TIM_PWM_Start_DMA(&amp;htim1,TIM_CHANNEL_1,(<span class="type">uint32_t</span> *)esc_cmd,ESC_CMD_BUF_LEN);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;BLheli电调与Dshot通讯&lt;/h1&gt;
&lt;p&gt;这里首先介绍一下基本概念&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;电调ESC：全称电子速度控制器，一个电机需要控制转动，需要电调ESC，电调负责把输入的直流电转化为三相电等输入，根据飞行控制器的输入指令（FC）调节电机的速度（和</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://outbreak-sen.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>LLVM tablegen</title>
    <link href="http://outbreak-sen.github.io/2025/02/11/LLVM-tablegen/"/>
    <id>http://outbreak-sen.github.io/2025/02/11/LLVM-tablegen/</id>
    <published>2025-02-11T02:19:57.000Z</published>
    <updated>2025-03-19T09:12:54.058Z</updated>
    
    <content type="html"><![CDATA[<h1>LLVM和LLVM tablegen学习笔记</h1><h2 id="llvm介绍">LLVM介绍</h2><p>LLVM 是一个跨平台（可在 Linux、Windows 和 Mac 上使用）C/C++ 编译器工具集，像 GCC一样。 LLVM 可以编译用  C、C++ 和 Objective-C 编写的代码。  LLVM 通过 libc++ 和 libc++ ABI 项目支持 C++11、C++14 和 C++17。 LLVM 还部分支持最新的 C++20 和 C++2b 标准。LLVM之所以优秀，在于以下几点：</p><ul><li>LLVM的中间表达（IR）是可以阅读的文本形式的，其他很多编译器却只有内存中的数据结构，使得学习调试难度大增。</li><li>LLVM 工具集提供的 Clang 可以比 GCC 更快地编译 C 和 C++ 代码。与  GCC 相比，LLVM 调试器 LLDB 的内存效率更高，加载符号的速度更快。</li><li>始于学术项目一个博士的项目，但LLVM一直受到工业界Apple的支持，clang（是llvm的前端）和LLVM都是apple搞出来的，因为gcc他们不满意，后来apple研发的swift也是基于llvm作为编译器，后来研发llvm的这个人去了Tesla，google，tensorflow。LLVM不仅好用，而且开源可定制。避免了在Java中类似面临选择HotSpot和jikes的困境。</li></ul><p>**你可以基于LLVM提供的功能开发自己的模块，并集成在LLVM系统上，增加它的功能，或者就单纯自己开发软件工具，而利用LLVM来支撑底层实现。**LLVM是一个编译器框架。LLVM作为编译器框架，是需要各种功能模块支撑起来的，你可以将clang和lld都看做是LLVM的组成部分</p><h2 id="llvm如何工作">LLVM如何工作</h2><p><img src="./LLVM-tablegen/image-20250211153154584.png" alt="image-20250211153154584"></p><p>看起来就是三个步骤：</p><ul><li>前端：获取源代码并将其转换为<em>中间表示</em>或 IR。这种翻译简化了编译器其余部分的工作，它不想处理 C++ 源代码的全部复杂性。比如Clang。LLVM IR是LLVM的中间表示，这是LLVM中很重要的一个东西，介绍它的文档就一个，LLVM Language Reference Manual</li><li>将IR 转换为 IR的Pass：在一般情况下，pass 通常会优化代码：生成另一个 IR 程序作为输出。新生成的IR与上一个IR效果相同，只是它更快更优。如果说要把一个语言编译好的**整个编译过程中使用相同的 IR <em>。<em>在其他编译器中，每次传递都可能以独特的形式生成代码。</em></em></li><li>后端：生成实际的机器码。很多时候不需要接触这部分。</li></ul><h3 id="我要做什么？">我要做什么？</h3><p>我需要给mindspore添加一个算子，这个算子是深度学习里面的一个计算方法addlayernorm，我要把这个计算方法变成mindspore里面的一个运算符，就像mindspore的编译器已经有+、-、*，我要基于已有的运算符编写一个新的运算符。这样之后的人用到addlayernorm可以直接用我写的，然后编译器自动编译好，而不是还需要先add再layernorm</p><h2 id="llvm安装">LLVM安装</h2><h3 id="apt安装">apt安装</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是一个mindspore推荐的快速安装方式</span></span><br><span class="line">wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | <span class="built_in">sudo</span> apt-key add -</span><br><span class="line"><span class="built_in">sudo</span> add-apt-repository <span class="string">&quot;deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-12 main&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install llvm-12-dev -y <span class="comment">#但是这样系统找不到llvm，cmake也找不到</span></span><br><span class="line"><span class="comment"># 注意llvm-config --version找不到，因为环境中可能有llvm-config-12和llvm-config-14,但没设置默认的</span></span><br><span class="line">llvm-config-12 --version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下是另一个官方的安装方法</span></span><br><span class="line"><span class="comment"># clang 和 clang++ 程序是 LLVM 工具集的一部分。 clang用于编译C程序，clang++用于编译C++程序。</span></span><br><span class="line"><span class="built_in">sudo</span> apt install clang lldb lld</span><br><span class="line">clang --version <span class="comment">#安装号之后就可以clang hello.c -o hello_c 生成可执行文件hello_c</span></span><br><span class="line">clang++ --version <span class="comment">#安装号之后就可以clang++ hello.cpp -o hello_cpp生成可执行文件hello_cpp</span></span><br><span class="line"><span class="comment"># 安装llvm 默认情况下不会自动安装Clang</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install llvm-12</span><br><span class="line"><span class="comment"># 查看llvm版本</span></span><br><span class="line">llvm-config-12 --version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是llvm和clang都有版本的问题，有时候需要制定版本，比如gcc9也是这样的</span></span><br><span class="line"><span class="comment"># 首先，添加所有可用的 llvm-config 版本到 update-alternatives：一般就12和14两个</span></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/llvm-config llvm-config /usr/bin/llvm-config-12 20</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/llvm-config llvm-config /usr/bin/llvm-config-14 10</span><br><span class="line"><span class="comment"># 选择默认版本</span></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --config llvm-config</span><br><span class="line"><span class="comment"># 这样就可以找到llvm-config --version命令了，而不是非写llvm-config-12</span></span><br><span class="line">llvm-config --version</span><br><span class="line"><span class="comment"># 添加所有可用的 clang 版本到 update-alternatives</span></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/clang clang /usr/bin/clang-12 20</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/clang clang /usr/bin/clang-14 10</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-12 20</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-14 10</span><br><span class="line"><span class="comment"># 选择默认版本</span></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --config clang</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --config clang++</span><br><span class="line"></span><br><span class="line"><span class="comment">#但是这样cmake还是找不到</span></span><br><span class="line"><span class="comment">#llvmCMake Error at CMakeLists.txt:13 (include):</span></span><br><span class="line"><span class="comment">#  include could not find requested file: AddLLVM</span></span><br><span class="line"><span class="comment"># 要找到llvm的安装位置，然后export了</span></span><br><span class="line"><span class="built_in">which</span> llvm-config</span><br><span class="line">/usr/bin/llvm-config <span class="comment">#发现可执行文件在bin里</span></span><br><span class="line"><span class="comment">#头文件/usr/include/llvm-12/</span></span><br><span class="line"><span class="comment">#库文件/usr/lib/llvm-&lt;version&gt;/</span></span><br><span class="line"><span class="comment">#则cmake链接到库文件/usr/lib/llvm-&lt;version&gt;/lib/cmake/llvm/这是 CMake 查找 LLVMConfig.cmake 和 AddLLVM.cmake 的关键路径。</span></span><br><span class="line"><span class="built_in">export</span> LLVM_DIR=/usr/lib/llvm-12/lib/cmake/llvm/</span><br><span class="line"><span class="comment"># 但是我很奇怪12版本的找不到路径，addllvm死活找不到，，所以改成14了</span></span><br><span class="line"><span class="built_in">export</span> LLVM_DIR=/usr/lib/llvm-14/lib/cmake/llvm/</span><br><span class="line"><span class="comment"># set(LLVM_DIR &quot;/usr/lib/llvm-14/lib/cmake/llvm/&quot;) #在cmake里面可以加</span></span><br></pre></td></tr></table></figure><h3 id="cmake编译安装-还没必要">Cmake编译安装（还没必要）</h3><h2 id="llvm语言的一个快速入门">LLVM语言的一个快速入门</h2><p><a href="https://llvm.org/doxygen/">LLVM的doxygen</a></p><p><a href="https://llvm.org/docs/LangRef.html">中间表示IR的语法书</a></p><p><a href="https://llvm.org/docs/ProgrammersManual.html">开发者手册</a></p><p><a href="https://llvm.gnu.ac.cn/docs/TableGen/index.html">开发者手册中文，但是还是要看英文的，比如里面把class直接翻译成类，而class我觉得在这里面不能翻译</a></p><p><a href="https://www.cnblogs.com/Five100Miles/p/11025680.html">这个人的笔记很不错</a></p><ul><li><p>pass：编写一个LLVM的规则，比如把一个函数里面的所有+法变成*法，被称为一个pass。在LLVM中优化以pass形式实现, 每一个pass代表一种优化. pass分为两类,</p><ul><li>一类是分析(analysis)pass,  算相关IR单元的高层信息，但不对其进行修改。这些信息可以被其他Pass使用，或用于调试和程序可视化。换言之，Analysis Pass会从对应的IR单元中挖掘出需要的信息，然后进行存储，并提供查询的接口，让其它Pass去访问其所存储的信息。</li><li>另一类是变换(transform)pass, 可以使用Analysis Pass的分析结果，然后以某种方式改变和优化IR。也就是说，这类Pass是会改变IR的内容的，可能会改变IR中的指令，也可能会改变IR中的控制流。</li></ul><p>还有一种Utility Pass不算进去了，LLVM中实现了几十种优化pass, 其中许多pass运行不止一次. analysis  pass存放在lib/Analysis下, transform pass存放在lib/Transforms下</p></li><li><p>dump：一种语言编译成其他语言的过程，在llvm指的是一种语言变成IR（中间表示）的过程，这个也是llvm的一个函数，可以实现输出IR</p></li></ul><h3 id="读取并打印函数名称">读取并打印函数名称</h3><p>首先LLVM用C++编写，然后用cmake进行编译，变成成一个pass</p><p>这里是仓库 git clone <a href="mailto:git@github.com">git@github.com</a>:sampsyo/llvm-pass-skeleton.git</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># Skeleton.cpp中</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Pass.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Passes/PassBuilder.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Passes/PassPlugin.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;llvm/Support/raw_ostream.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> llvm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SkeletonPass</span> : <span class="keyword">public</span> PassInfoMixin&lt;SkeletonPass&gt; &#123;</span><br><span class="line">    <span class="function">PreservedAnalyses <span class="title">run</span><span class="params">(Module &amp;M, ModuleAnalysisManager &amp;AM)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;F : M) &#123;</span><br><span class="line">            <span class="meta"># errs()是一个LLVM提供的C++输出流，我们可以用它来输出到控制台</span></span><br><span class="line">            # 这个程序的意义是在编译过程中把每个函数的名称打印出来</span><br><span class="line">            <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;I saw a function called &quot;</span> &lt;&lt; F.<span class="built_in">getName</span>() &lt;&lt; <span class="string">&quot;!\n&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> PreservedAnalyses::<span class="built_in">all</span>();</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> LLVM_ATTRIBUTE_WEAK ::<span class="function">llvm::PassPluginLibraryInfo</span></span><br><span class="line"><span class="function"><span class="title">llvmGetPassPluginInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        .APIVersion = LLVM_PLUGIN_API_VERSION,</span><br><span class="line">        .PluginName = <span class="string">&quot;Skeleton pass&quot;</span>,</span><br><span class="line">        .PluginVersion = <span class="string">&quot;v0.1&quot;</span>,</span><br><span class="line">        .RegisterPassBuilderCallbacks = [](PassBuilder &amp;PB) &#123;</span><br><span class="line">            PB.<span class="built_in">registerPipelineStartEPCallback</span>(</span><br><span class="line">                [](ModulePassManager &amp;MPM, OptimizationLevel Level) &#123;</span><br><span class="line">                    MPM.<span class="built_in">addPass</span>(<span class="built_in">SkeletonPass</span>());</span><br><span class="line">                &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cmakelists里面编写生成一个pass，最终会获得build/skeleton/SkeletonPass.so</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load LLVMConfig.cmake. If this fails, consider setting `LLVM_DIR` to point</span></span><br><span class="line"><span class="comment"># to your LLVM installation&#x27;s `lib/cmake/llvm` directory.</span></span><br><span class="line"><span class="comment"># set(LLVM_DIR &quot;/usr/lib/llvm-14/lib/cmake/llvm/&quot;) #找不到可以加</span></span><br><span class="line"><span class="keyword">find_package</span>(LLVM REQUIRED CONFIG)</span><br><span class="line"><span class="comment"># Include the part of LLVM&#x27;s CMake libraries that defines</span></span><br><span class="line"><span class="comment"># `add_llvm_pass_plugin`.</span></span><br><span class="line"><span class="keyword">include</span>(AddLLVM)</span><br><span class="line"><span class="comment"># Use LLVM&#x27;s preprocessor definitions, include directories, and library search</span></span><br><span class="line"><span class="comment"># paths.</span></span><br><span class="line"><span class="keyword">add_definitions</span>(<span class="variable">$&#123;LLVM_DEFINITIONS&#125;</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;LLVM_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"><span class="keyword">link_directories</span>(<span class="variable">$&#123;LLVM_LIBRARY_DIRS&#125;</span>)</span><br><span class="line"><span class="comment"># 要includeaddllvm才能用下面这个命令</span></span><br><span class="line">add_llvm_pass_plugin(SkeletonPass</span><br><span class="line">    <span class="comment"># List your source files here.</span></span><br><span class="line">    Skeleton.cpp</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>获得了这个build/skeleton/SkeletonPass.so，就可以在clang的时候永乐</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">clang -Xclang -load -Xclang build/skeleton/libSkeletonPass.* 某个c程序.c</span> </span><br><span class="line">I saw a function called main!# 这里就会打印函数名称</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-Xclang -load -Xclang path/to/lib.so这是你在Clang中载入并激活你的流程所用的所有代码。</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">所以当你处理较大的项目的时候，你可以直接把这些参数加到Makefile的CFLAGS里或者你构建系统的对应的地方。</span></span><br></pre></td></tr></table></figure><h3 id="如何查看ir">如何查看IR</h3><p>LLVM IR有三种表现形式:</p><ul><li>在编译器内部的IR</li><li>在磁盘中存储的bitcode(用于JIT编译器)</li><li>最常见的易于阅读的LLVM IR汇编. 三种格式的IR是等价的(可互相转化), 因此LLVM IR提供了高效的编译器优化手段的同时又保证了方便调试与定位问题.</li></ul><p>使用IR的优点.</p><ol><li>通用, 任意语言都能转换为IR, 同一IR能转换为任意架构汇编.</li><li>可移植性好, 容易定位问题,  只要保证IR正确性就能确定问题范围(前端还是后端还是某个优化pass).</li><li>支持LTO(link time optimization).LLVM编译的时候会顺序读取程序的每个指令，一套程序可以这样组成</li></ol><p><img src="./LLVM-tablegen/image-20250212112813600.png" alt="image-20250212112813600"></p><ul><li>模块表示了一个源文件</li><li>源文件里面都是函数</li><li>函数主要会做为代码块的容器</li><li>指令就是一条单独的代码命令</li></ul><h4 id="如何生成ir">如何生成IR</h4><p>在编译时添加选项-emit-llvm即可生成IR, 此时的IR为bitcode格式(默认文件名后缀为bc), 若要生成汇编格式还需添加-S选项(默认文件名后缀为ll).</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clang -emit-llvm -S -o - 某个c程序.c <span class="comment">#这个就可以把c程序变成IR进行阅读，-emit-llvm</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> ~/test.c</span><br><span class="line"> 2 int <span class="built_in">test</span>(int a, int b)</span><br><span class="line"> 3 &#123;</span><br><span class="line"> 4   int c = 0;</span><br><span class="line"> 5   <span class="keyword">if</span> (a) &#123;</span><br><span class="line"> 6     c = b;</span><br><span class="line"> 7     a = c;</span><br><span class="line"> 8   &#125;</span><br><span class="line"> 9   <span class="built_in">return</span> c;</span><br><span class="line">10 &#125;</span><br><span class="line">../llvm_build/bin/clang ~/test.c -O0 -emit-llvm -S -o ~/test.ll</span><br><span class="line"><span class="built_in">cat</span> ~/test.ll <span class="comment">#查看ll这个IR语言的 </span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%5 = add i32 %4, 2 #这个指令将两个32位整数相加（可以通过类型i32推断出来）。它将4号寄存器（写作%4）中的数和字面值2（写作2）求和，然后放到5号寄存器中。</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">// dump()。它会打印出人可读的IR对象的表示。</span></span><br><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SkeletonPass</span> : <span class="keyword">public</span> PassInfoMixin&lt;SkeletonPass&gt; &#123;</span><br><span class="line">    <span class="function">PreservedAnalyses <span class="title">run</span><span class="params">(Module &amp;M, ModuleAnalysisManager &amp;AM)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;F : M.<span class="built_in">functions</span>()) &#123;</span><br><span class="line">            <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;In a function called &quot;</span> &lt;&lt; F.<span class="built_in">getName</span>() &lt;&lt; <span class="string">&quot;!\n&quot;</span>;</span><br><span class="line">            <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;Function body:\n&quot;</span>;</span><br><span class="line">            F.<span class="built_in">print</span>(<span class="built_in">errs</span>());</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;B : F) &#123;</span><br><span class="line">              <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;Basic block:\n&quot;</span>;</span><br><span class="line">              B.<span class="built_in">print</span>(<span class="built_in">errs</span>());</span><br><span class="line">              <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;I : B) &#123;</span><br><span class="line">                <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;Instruction: \n&quot;</span>;</span><br><span class="line">                I.<span class="built_in">print</span>(<span class="built_in">errs</span>(), <span class="literal">true</span>);</span><br><span class="line">                <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">errs</span>() &lt;&lt; <span class="string">&quot;I saw a function called &quot;</span> &lt;&lt; F.<span class="built_in">getName</span>() &lt;&lt; <span class="string">&quot;!\n&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> PreservedAnalyses::<span class="built_in">all</span>();</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> LLVM_ATTRIBUTE_WEAK ::<span class="function">llvm::PassPluginLibraryInfo</span></span><br><span class="line"><span class="function"><span class="title">llvmGetPassPluginInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        .APIVersion = LLVM_PLUGIN_API_VERSION,</span><br><span class="line">        .PluginName = <span class="string">&quot;Skeleton pass&quot;</span>,</span><br><span class="line">        .PluginVersion = <span class="string">&quot;v0.1&quot;</span>,</span><br><span class="line">        .RegisterPassBuilderCallbacks = [](PassBuilder &amp;PB) &#123;</span><br><span class="line">            PB.<span class="built_in">registerPipelineStartEPCallback</span>(</span><br><span class="line">                [](ModulePassManager &amp;MPM, OptimizationLevel Level) &#123;</span><br><span class="line">                    MPM.<span class="built_in">addPass</span>(<span class="built_in">SkeletonPass</span>());</span><br><span class="line">                &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="对一个运算符进行重新编写">对一个运算符进行重新编写</h3><p>把函数里第一个二元操作符（比如+，-）改成乘号。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SkeletonPass</span> : <span class="keyword">public</span> PassInfoMixin&lt;SkeletonPass&gt; &#123;</span><br><span class="line">    <span class="function">PreservedAnalyses <span class="title">run</span><span class="params">(Module &amp;M, ModuleAnalysisManager &amp;AM)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;F : M.<span class="built_in">functions</span>()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;B : F) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;I : B) &#123;</span><br><span class="line">                    <span class="comment">// dyn_cast&lt;T&gt;(p)构造函数是LLVM类型检查工具的应用。如果I不是“二元操作符”，这个构造函数返回一个空指针。</span></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">auto</span> *op = <span class="built_in">dyn_cast</span>&lt;BinaryOperator&gt;(&amp;I)) &#123;</span><br><span class="line">                        <span class="comment">// Insert at the point where the instruction `op`</span></span><br><span class="line">                        <span class="comment">// appears.</span></span><br><span class="line">                        <span class="comment">// IRBuilder用于构造代码。</span></span><br><span class="line">                        IRBuilder&lt;&gt; <span class="built_in">builder</span>(op);</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// Make a multiply with the same operands as `op`.</span></span><br><span class="line">                        Value *lhs = op-&gt;<span class="built_in">getOperand</span>(<span class="number">0</span>);</span><br><span class="line">                        Value *rhs = op-&gt;<span class="built_in">getOperand</span>(<span class="number">1</span>);</span><br><span class="line">                        Value *mul = builder.<span class="built_in">CreateMul</span>(lhs, rhs);</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// Everywhere the old instruction was used as an</span></span><br><span class="line">                        <span class="comment">// operand, use our new multiply instruction instead.</span></span><br><span class="line">                        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;U : op-&gt;<span class="built_in">uses</span>()) &#123;</span><br><span class="line">                          <span class="comment">// A User is anything with operands.</span></span><br><span class="line">                          User *user = U.<span class="built_in">getUser</span>();</span><br><span class="line">                          user-&gt;<span class="built_in">setOperand</span>(U.<span class="built_in">getOperandNo</span>(), mul);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// We modified the code.</span></span><br><span class="line">                        <span class="keyword">return</span> PreservedAnalyses::<span class="built_in">none</span>();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> PreservedAnalyses::<span class="built_in">all</span>();</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> LLVM_ATTRIBUTE_WEAK ::<span class="function">llvm::PassPluginLibraryInfo</span></span><br><span class="line"><span class="function"><span class="title">llvmGetPassPluginInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        .APIVersion = LLVM_PLUGIN_API_VERSION,</span><br><span class="line">        .PluginName = <span class="string">&quot;Skeleton pass&quot;</span>,</span><br><span class="line">        .PluginVersion = <span class="string">&quot;v0.1&quot;</span>,</span><br><span class="line">        .RegisterPassBuilderCallbacks = [](PassBuilder &amp;PB) &#123;</span><br><span class="line">            PB.<span class="built_in">registerPipelineStartEPCallback</span>(</span><br><span class="line">                [](ModulePassManager &amp;MPM, OptimizationLevel Level) &#123;</span><br><span class="line">                    MPM.<span class="built_in">addPass</span>(<span class="built_in">SkeletonPass</span>());</span><br><span class="line">                &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">const</span> <span class="type">char</span>** argv)</span> &#123;</span><br><span class="line">  <span class="type">int</span> num;</span><br><span class="line">  <span class="built_in">scanf</span>(<span class="string">&quot;%i&quot;</span>, &amp;num);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%i\n&quot;</span>, num + <span class="number">2</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"> </span><br><span class="line">   $ cc example.c</span><br><span class="line">    $ ./a.out</span><br><span class="line">    <span class="number">10</span></span><br><span class="line">    <span class="number">12</span></span><br><span class="line">    $ clang -Xclang -load -Xclang build/skeleton/libSkeletonPass.so example.c</span><br><span class="line">    $ ./a.out</span><br><span class="line">    <span class="number">10</span></span><br><span class="line">    <span class="number">20</span></span><br></pre></td></tr></table></figure><h2 id="llvm-tablegen-的入门">LLVM tablegen 的入门</h2><p>使用 LLVM 时，你会选择一个“目标”，即你想要为其生成指令的处理器体系结构。TableGen 的等效项是“后端”。这些后端不生成指令，而是输出特定于该后端用例的格式。 tablegen是llvm用于开发和维护编译器中公共特性的条目(e.g. 指令描述, 寄存器描述)的代码, ，其本质是一个parser, **说白了就是把一套公用的指令翻译成不同架构的语言，比如一个加法分别翻译成x86、arm的，**<strong>将输入的td文件转化为特定的数据结构后再输出为易于阅读的cpp代码，实现td文件到cpp代码</strong></p><p><img src="./LLVM-tablegen/0d726f2066052217c46a74cecf86b90f.png" alt="img"></p><h3 id="使用方式">使用方式</h3><p>在llvm下载目录里/bin/可执行文件中有一个llvm-tblgen工具，读入一个td文件, 并将结果输出至一个inc文件中，生成的inc文件实质为cpp代码,</p><p>tablegen代码包含两块:</p><ul><li>对td文件的处理, 在lib/TableGen/目录下, 包含lexer与parser,  负责解析tablegen的语法并转换为内部数据结构;</li><li>输出cpp代码, 在utils/TableGen/目录下, 用于生成我们需要的cpp代码, 这块与llvm代码逻辑强相关, 基本上一个cpp文件对应一类信息.</li></ul><h3 id="td文件的语法">td文件的语法</h3><p>TableGen的语法与C++相似，具有内置类型和规范。此外，TableGen的语法还引入了一些自动化概念，如multiclass、foreach、let等在td中使用两个关键字定义数据结构：</p><p>class与def，这两个在llvm中被称为records，下面分别介绍</p><ul><li>classes类似于模板, 用于描述一类抽象的records，<strong>说白了就是那个公用的指令是什么</strong></li><li>definitions用于表达一个具体的records(可以理解为一个特定的类)，<strong>说白了就是这个公用的指令在特定平台是怎么写的</strong><ul><li>每个records包含若干数据成员, 这些成员的类型有bit(布尔量), int(整型), string(字符串), code(代码段,  包含一行或多行的字符串), bit(位段)等类型.</li><li>数据成员使用let关键字进行赋值,</li><li>对于tablegen中解析的成员必须都初始化(为定义的值可以使用?初始化为’未初始化值’), 否则会导致编译失败. 若一个definition  record包含一个未初始化成员, 其值将从该definition的superclass中获取.  若tablegen中未解析该成员则不赋值也不会报错.</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 以下是class，是一个比如在x86,arm，acend都会用到的一个指令</span><br><span class="line">class AsmParser &#123;</span><br><span class="line">  string AsmParserClassName  = &quot;AsmParser&quot;;</span><br><span class="line">  string AsmParserInstCleanup  = &quot;&quot;;</span><br><span class="line">  bit ShouldEmitMatchRegisterName = 1;</span><br><span class="line">  bit ShouldEmitMatchRegisterAltName = 0;</span><br><span class="line">  bit AllowDuplicateRegisterNames = 0;</span><br><span class="line">  bit HasMnemonicFirst = 1;</span><br><span class="line">  bit ReportMultipleNearMisses = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Hexagon架构的Asmarser，然后在高通架构下对上面的class重新写，因为在不同的后端比如x86,arm，acend，他们的指令操作码不一样</span><br><span class="line">// Hexagon架构的Asmarser如下(defined in lib/Target/Hexagon/Hexagon.td):</span><br><span class="line">def HexagonAsmParser : AsmParser &#123;</span><br><span class="line">  // 使用`let`作为赋值语句。</span><br><span class="line">  let ShouldEmitMatchRegisterAltName = 1;</span><br><span class="line">  bit HasMnemonicFirst = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">llvm-tblgen test.td # 命令行中运行,在默认参数下会输出所有的class和defs。在每条记录定义后的注释表明了ADD所有的类别。</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 再举一个例子</span></span><br><span class="line"><span class="comment">// cat register.td</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Register</span>&lt;<span class="type">int</span> _size, string _alias=<span class="string">&quot;&quot;</span>&gt; &#123;</span><br><span class="line">  <span class="type">int</span> size = _size;</span><br><span class="line">  string alias = _alias;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 64 bit general purpose registers are X&lt;N&gt;.</span></span><br><span class="line">def X0: Register&lt;<span class="number">8</span>&gt; &#123;&#125;</span><br><span class="line"><span class="comment">// Some have special alternate names.</span></span><br><span class="line">def X29: Register&lt;<span class="number">8</span>, <span class="string">&quot;frame pointer&quot;</span>&gt; &#123;&#125;</span><br><span class="line"><span class="comment">// Some registers omitted...</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">执行tablegen命令./bin/llvm-tblgen register.td</span><br><span class="line"></span><br><span class="line">------------- Classes -----------------</span><br><span class="line">class Register&lt;int Register:_size = ?, string Register:_alias = <span class="string">&quot;&quot;</span>&gt; &#123;</span><br><span class="line"> int size = Register:_size;</span><br><span class="line"> string <span class="built_in">alias</span> = Register:_alias;</span><br><span class="line">&#125;</span><br><span class="line">------------- Defs -----------------</span><br><span class="line">def X0 &#123;        // Register</span><br><span class="line"> int size = 8;</span><br><span class="line"> string <span class="built_in">alias</span> = <span class="string">&quot;&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">def X29 &#123;       // Register</span><br><span class="line"> int size = 8;</span><br><span class="line"> string <span class="built_in">alias</span> = <span class="string">&quot;frame pointer&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;LLVM和LLVM tablegen学习笔记&lt;/h1&gt;
&lt;h2 id=&quot;llvm介绍&quot;&gt;LLVM介绍&lt;/h2&gt;
&lt;p&gt;LLVM 是一个跨平台（可在 Linux、Windows 和 Mac 上使用）C/C++ 编译器工具集，像 GCC一样。 LLVM 可以编译用  C、C+</summary>
      
    
    
    
    <category term="编译" scheme="http://outbreak-sen.github.io/categories/%E7%BC%96%E8%AF%91/"/>
    
    
    <category term="LLVM" scheme="http://outbreak-sen.github.io/tags/LLVM/"/>
    
  </entry>
  
  <entry>
    <title>大恒相机硬触发</title>
    <link href="http://outbreak-sen.github.io/2025/02/11/%E5%A4%A7%E6%81%92%E7%9B%B8%E6%9C%BA%E7%A1%AC%E8%A7%A6%E5%8F%91/"/>
    <id>http://outbreak-sen.github.io/2025/02/11/%E5%A4%A7%E6%81%92%E7%9B%B8%E6%9C%BA%E7%A1%AC%E8%A7%A6%E5%8F%91/</id>
    <published>2025-02-11T01:51:43.000Z</published>
    <updated>2025-02-11T02:17:00.136Z</updated>
    
    <content type="html"><![CDATA[<h1>大恒相机硬触发说明文档</h1><p>相机硬触发是区别于软触发，利用IO或者光耦等外部控制信号触发相机快门的技术。</p><p>大恒相机有IO触发和光耦触发两种硬触发方式，其中光耦触发隔离了光电回路，对于相机更加安全，但是由于存在光电转换过程所以触发时间延迟了30us左右。硬触发方式只有单次触发，也就是说想要连续获得图片必须向相机发射多次发射方波信号。</p><p><strong>硬触发只能通过回调函数获得图片，对于大恒相机只能通过已经定义的回调函数获得图片，回调的数据类型已经确定。</strong></p><h2 id="利用io信号控制相机硬触发">利用IO信号控制相机硬触发</h2><p>在IO控制线中有line0，line1，line2，line3三根线，前两根是光耦触发线，后两根是IO输入/输出线。注意使用IO控制时还应连接IO地线GND。</p><p><img src="./%E5%A4%A7%E6%81%92%E7%9B%B8%E6%9C%BA%E7%A1%AC%E8%A7%A6%E5%8F%91/1.png" alt=""></p><p><strong>这里我接了line2（5）和GND（2）然后line2接到一个单片机上的GPIO口上，推挽输出，输出电压为5V，然后完成以下设置之后，只要单片机的IO口输出一个高电平，相机就会采集一张图片。</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">````</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;time.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;opencv2/opencv.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;stdio.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;GxIAPI.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//定义全局变量，用来存图和计时</span></span><br><span class="line"><span class="function">cv::Mat <span class="title">empty</span><span class="params">(<span class="number">1024</span>, <span class="number">1280</span>, CV_8UC3, cv::Scalar::all(<span class="number">0</span>))</span></span>;</span><br><span class="line">timeval tv;</span><br><span class="line"><span class="type">long</span> time_end;</span><br><span class="line"><span class="type">long</span> time_start;</span><br><span class="line"><span class="comment">//图 像 回 调 处 理 函 数</span></span><br><span class="line"><span class="comment">//传回来的GX_FRAME_CALLBACK_PARAM *pFrame包含了图像所在指针，大小，长度等一系列信息，需要解码之后变成RGB图片</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> GX_STDC <span class="title">OnFrameCallbackFun</span><span class="params">(GX_FRAME_CALLBACK_PARAM *pFrame)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (pFrame-&gt;status == <span class="number">0</span>)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="built_in">gettimeofday</span>(&amp;tv, <span class="literal">NULL</span>);</span><br><span class="line">      time_end = tv.tv_sec * <span class="number">1000000</span> + tv.tv_usec;</span><br><span class="line">      std::cout &lt;&lt; <span class="number">1000000</span> / (time_end - time_start) &lt;&lt; <span class="string">&quot;fps&quot;</span></span><br><span class="line">                &lt;&lt; <span class="string">&quot;get an image&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">      time_start = time_end;</span><br><span class="line">      <span class="type">void</span> *rgb_buffer = <span class="built_in">malloc</span>(<span class="number">3</span> * pFrame-&gt;nImgSize);</span><br><span class="line">      <span class="built_in">DxRaw8toRGB24</span>((<span class="type">void</span> *)pFrame-&gt;pImgBuf, rgb_buffer, pFrame-&gt;nWidth, pFrame-&gt;nHeight, RAW2RGB_NEIGHBOUR, BAYERRG, <span class="literal">false</span>);</span><br><span class="line">      cv::Mat result = cv::<span class="built_in">Mat</span>(pFrame-&gt;nHeight, pFrame-&gt;nWidth, CV_8UC3, rgb_buffer);</span><br><span class="line">      result.<span class="built_in">copyTo</span>(empty);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">   &#123;</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;fuck,trigger is failed&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//打开设备和打开库方式相同，关键在于设置触发</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   GX_STATUS status = GX_STATUS_SUCCESS;</span><br><span class="line">   GX_DEV_HANDLE hDevice = <span class="literal">NULL</span>;</span><br><span class="line">   GX_OPEN_PARAM stOpenParam;</span><br><span class="line">   <span class="type">uint32_t</span> nDeviceNum = <span class="number">0</span>;</span><br><span class="line">   <span class="built_in">gettimeofday</span>(&amp;tv, <span class="literal">NULL</span>);</span><br><span class="line">   time_end = tv.tv_sec * <span class="number">1000000</span> + tv.tv_usec;</span><br><span class="line">   time_start = tv.tv_sec * <span class="number">1000000</span> + tv.tv_usec;</span><br><span class="line">   <span class="comment">//初 始 化 库</span></span><br><span class="line">   status = <span class="built_in">GXInitLib</span>();</span><br><span class="line">   <span class="comment">//枚 举 设 备 列 表</span></span><br><span class="line">   status = <span class="built_in">GXUpdateDeviceList</span>(&amp;nDeviceNum, <span class="number">1000</span>);</span><br><span class="line">   <span class="keyword">if</span> ((status != GX_STATUS_SUCCESS) || (nDeviceNum &lt;= <span class="number">0</span>))</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">//打 开 设 备</span></span><br><span class="line">   stOpenParam.accessMode = GX_ACCESS_EXCLUSIVE;</span><br><span class="line">   stOpenParam.openMode = GX_OPEN_INDEX;</span><br><span class="line">   stOpenParam.pszContent = <span class="string">&quot;1&quot;</span>;</span><br><span class="line">   status = <span class="built_in">GXOpenDevice</span>(&amp;stOpenParam, &amp;hDevice);</span><br><span class="line">   <span class="keyword">if</span> (status == GX_STATUS_SUCCESS)</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="comment">//设 置 触 发 模 式 为 ON</span></span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_TRIGGER_MODE, GX_TRIGGER_MODE_ON);</span><br><span class="line">      <span class="comment">//设 置 触 发 激 活 方 式 为 上 升 沿，还可以设置下降沿触发，指电平上升或下降时为一次触发</span></span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_TRIGGER_ACTIVATION, GX_TRIGGER_ACTIVATION_RISINGEDGE);</span><br><span class="line">      <span class="comment">//设置触发开关为line2</span></span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_TRIGGER_SOURCE, GX_TRIGGER_SOURCE_LINE2);</span><br><span class="line">      <span class="comment">//Selects the physical line (or pin) of the external device connector to configure，我也不知道是啥反正加去了</span></span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_LINE_SELECTOR, GX_ENUM_LINE_SELECTOR_LINE2);</span><br><span class="line">      <span class="comment">//设置line2模式为input，同样可以设置为outpot，则可以通过相机控制外部设备</span></span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_LINE_MODE, GX_ENUM_LINE_MODE_INPUT);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      <span class="comment">// GX_ENUM_TRIGGER_MODE: 触发模式, 枚举值参考 GX_TRIGGER_MODE_ENTRY </span></span><br><span class="line">      <span class="comment">// GX_COMMAND_TRIGGER_SOFTWARE : 软触发命令 </span></span><br><span class="line">      <span class="comment">// GX_ENUM_TRIGGER_ACTIVATION : 触发极性, 枚举值参考 </span></span><br><span class="line">      <span class="comment">// GX_TRIGGER_ACTIVATION_ENTRY GX_ENUM_TRIGGER_SWITCH : 外触发开关, 参考 </span></span><br><span class="line">      <span class="comment">// GX_TRIGGER_SWITCH_ENTRY GX_ENUM_TRIGGER_SOURCE : 触发源, 枚举值参考 </span></span><br><span class="line">      <span class="comment">// GX_TRIGGER_SOURCE_ENTRY GX_ENUM_TRIGGER_SELECTOR : 触发类型选择, 参考 </span></span><br><span class="line">      <span class="comment">// GX_TRIGGER_SELECTOR_ENTRY GX_FLOAT_TRIGGER_DELAY : 触发延迟</span></span><br><span class="line">      <span class="comment">//设置曝光和增益等参数和原先在一致</span></span><br><span class="line">      status = <span class="built_in">GXSetFloat</span>(hDevice, GX_FLOAT_EXPOSURE_TIME, (<span class="type">float</span>)<span class="number">3000</span>);</span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_BALANCE_RATIO_SELECTOR, GX_BALANCE_RATIO_SELECTOR_RED);</span><br><span class="line">      status = <span class="built_in">GXSetFloat</span>(hDevice, GX_FLOAT_BALANCE_RATIO, <span class="number">1.6484</span>);</span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_BALANCE_RATIO_SELECTOR, GX_BALANCE_RATIO_SELECTOR_BLUE);</span><br><span class="line">      status = <span class="built_in">GXSetFloat</span>(hDevice, GX_FLOAT_BALANCE_RATIO, <span class="number">1.5664</span>);</span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_BALANCE_RATIO_SELECTOR, GX_BALANCE_RATIO_SELECTOR_GREEN);</span><br><span class="line">      status = <span class="built_in">GXSetFloat</span>(hDevice, GX_FLOAT_BALANCE_RATIO, <span class="number">1.000</span>);</span><br><span class="line">      status = <span class="built_in">GXSetEnum</span>(hDevice, GX_ENUM_GAIN_SELECTOR, GX_GAIN_SELECTOR_ALL);</span><br><span class="line">      status = <span class="built_in">GXSetFloat</span>(hDevice, GX_FLOAT_GAIN, <span class="number">10.0</span>);</span><br><span class="line">  <span class="comment">//注 册 图 像 处 理 回 调 函 数，每次接受到一个电平变化就会回调</span></span><br><span class="line">      status = <span class="built_in">GXRegisterCaptureCallback</span>(hDevice, <span class="literal">NULL</span>, OnFrameCallbackFun);   </span><br><span class="line">      <span class="comment">//发 送 开 采 命 令</span></span><br><span class="line">      status = <span class="built_in">GXSendCommand</span>(hDevice, GX_COMMAND_ACQUISITION_START);</span><br><span class="line">   &#125;</span><br><span class="line">    <span class="comment">//所有引脚状态</span></span><br><span class="line">   <span class="type">int64_t</span> nAllLineStatus = <span class="number">0</span>; </span><br><span class="line">   </span><br><span class="line">   <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">   &#123;</span><br><span class="line">      cv::<span class="built_in">imshow</span>(<span class="string">&quot;test&quot;</span>, empty);</span><br><span class="line">      <span class="keyword">if</span> (cv::<span class="built_in">waitKey</span>(<span class="number">1</span>) == <span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">      &#123;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (cv::<span class="built_in">waitKey</span>(<span class="number">1</span>) == <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="comment">//输出所有引脚的电平，0xc默认是未触发状态，但是实际上0xe是未触发</span></span><br><span class="line">         GX_STATUS Status = <span class="built_in">GXGetInt</span>(hDevice, GX_INT_LINE_STATUS_ALL, &amp;nAllLineStatus);</span><br><span class="line">         std::cout</span><br><span class="line">             &lt;&lt; <span class="string">&quot;line status:&quot;</span> &lt;&lt; nAllLineStatus &lt;&lt; std::endl; </span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (cv::<span class="built_in">waitKey</span>(<span class="number">1</span>) == <span class="string">&#x27;q&#x27;</span>)</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="comment">//</span></span><br><span class="line">         <span class="comment">//在 发 送 停 采 命 令 前 如 果 产 生 了 有 效 触 发 , 那 么 图 像</span></span><br><span class="line">         <span class="comment">//会 通 过 OnFrameCallbackFun 接 口 返 给 用 户</span></span><br><span class="line">         <span class="comment">//---------------------</span></span><br><span class="line">         <span class="comment">//发 送 停 采 命 令</span></span><br><span class="line">         status = <span class="built_in">GXSendCommand</span>(hDevice, GX_COMMAND_ACQUISITION_STOP);</span><br><span class="line">         <span class="comment">//注 销 采 集 回 调</span></span><br><span class="line">         status = <span class="built_in">GXUnregisterCaptureCallback</span>(hDevice);</span><br><span class="line">         status = <span class="built_in">GXCloseDevice</span>(hDevice);</span><br><span class="line">         hDevice = <span class="literal">NULL</span>;</span><br><span class="line">         status = <span class="built_in">GXCloseLib</span>();</span><br><span class="line">         std::cout &lt;&lt; <span class="string">&quot;end captrue&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">         <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="io控制的电控代码">IO控制的电控代码</h2><p>我设计的电控方案是摁一下摁建就会有回调函数触发，回调函数就会展示这张照片，如果没有摁摁建就不会有图片，不会触发。如有需要可以联系我</p><p>设置曝光为3000us，查看大恒的图像传输过程大概是300us，取一次传图的周期为5000us，即200hz，则也应设置电控发送200hz的IO变化电平，实际在视觉收到的图片速率也在200hz作有，有不到10hz的变化，这个挺简单的，我就不切系统复制电控的代码了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;大恒相机硬触发说明文档&lt;/h1&gt;
&lt;p&gt;相机硬触发是区别于软触发，利用IO或者光耦等外部控制信号触发相机快门的技术。&lt;/p&gt;
&lt;p&gt;大恒相机有IO触发和光耦触发两种硬触发方式，其中光耦触发隔离了光电回路，对于相机更加安全，但是由于存在光电转换过程所以触发时间延迟了30us</summary>
      
    
    
    
    <category term="相机驱动开发" scheme="http://outbreak-sen.github.io/categories/%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="大恒" scheme="http://outbreak-sen.github.io/tags/%E5%A4%A7%E6%81%92/"/>
    
    <category term="硬触发" scheme="http://outbreak-sen.github.io/tags/%E7%A1%AC%E8%A7%A6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>mindspore.mint接口测试任务</title>
    <link href="http://outbreak-sen.github.io/2025/02/11/%E6%98%93%E7%94%A8%E6%80%A7mint%E7%AE%97%E5%AD%90%E6%B5%8B%E8%AF%95%E6%97%A5%E8%AE%B0/"/>
    <id>http://outbreak-sen.github.io/2025/02/11/%E6%98%93%E7%94%A8%E6%80%A7mint%E7%AE%97%E5%AD%90%E6%B5%8B%E8%AF%95%E6%97%A5%E8%AE%B0/</id>
    <published>2025-02-11T01:51:43.000Z</published>
    <updated>2025-03-19T09:11:03.981Z</updated>
    
    <content type="html"><![CDATA[<h1>mindspore.mint接口测试任务</h1><h2 id="任务">任务</h2><h3 id="任务背景">任务背景</h3><p>mindspore.mint提供了大量的functional、nn、优化器接口，API用法及功能等与业界主流用法一致，方便用户参考使用。 mint接口当前是实验性接口，在图编译模式为O0和PyNative模式下性能比ops更优。当前暂不支持图下沉模式及CPU、GPU后端，后续会逐步完善。</p><p>mindspore.mint.div逐元素计算 input 除以 other 的商。</p><p>mindspore.mint.divide</p><p>mindspore.mint.erf</p><p>mindspore.mint.erfc</p><p>mindspore.mint.erfinv</p><h3 id="需求描述">需求描述</h3><ol><li>对应Pytorch 的相应接口进行测试：<br>a) 测试random输入不同dtype，对比两个框架的支持度<br>b) 测试固定dtype，random输入值，对比两个框架输出是否相等（误差范围为小于1e-3）<br>c) 测试固定shape，固定输入值，不同输入参数（string\bool等类型），两个框架的支持度<br>d) 测试随机混乱输入，报错信息的准确性</li><li>测试使用接口构造函数/神经网络的准确性<br>a) Github搜索带有该接口的代码片段/神经网络<br>b) 使用Pytorch和MindSpore，固定输入和权重，测试正向推理结果（误差范围小于1e-3，若报错则记录报错信息）<br>c) 测试该神经网络/函数反向，如果是神经网络，则测试Parameter的梯度，如果是函数，则测试函数输入的梯度</li></ol><h3 id="验收标准">验收标准</h3><p>测试过程中遇到的其他问题记录，包括但不限于：<br>a) 环境安装<br>b) 框架运行时报错（如memcpy、 CANN报错等等）<br>c) 感觉不好用或者和Pytorch无法对齐的地方<br>将测试代码写成测试用例形式，提交打包：<br>a) 文件名命名为test_xxx.py，xxx为测试的接口名<br>b) 每个测试点构造一个函数，函数名为test_xxx，需要在函数名体现清晰的测试内容信息，如：test_linear_random_shape</p><h2 id="背景知识-别上传这一部分">背景知识（别上传这一部分）</h2><ul><li><p>numpy.allclose</p><p>Returns True if two arrays are element-wise equal within a tolerance.</p></li><li><p>MindSpore支持两种运行模式：<a href="https://www.mindspore.cn/tutorials/zh-CN/r1.3/intermediate/pynative_mode_and_graph_mode.html">参考文献</a></p><ul><li>Graph模式：静态图模式或者图模式，将神经网络模型编译成一整张图，然后下发执行。该模式利用图优化等技术提高运行性能，同时有助于规模部署和跨平台运行。</li><li>PyNative模式：动态图模式，将神经网络中的各个算子逐一下发执行，方便用户编写和调试神经网络模型。</li></ul><p>默认情况下，MindSpore处于Graph模式，可以通过<code>context.set_context(mode=context.PYNATIVE_MODE)</code>切换为PyNative模式；同样地，MindSpore处于PyNative模式时，可以通过 <code>context.set_context(mode=context.GRAPH_MODE)</code>切换为Graph模式。</p><p>Graph和PyNative两种模式的区别主要有：</p><ul><li>使用场景：Graph模式需要一开始就构建好网络结构，然后框架做整图优化和执行，比较适合网络固定没有变化，且需要高性能的场景。而PyNative模式逐行执行算子，支持单独求梯度。</li><li>网络执行：Graph模式和PyNative模式在执行相同的网络和算子时，精度效果是一致的。由于Graph模式运用了图优化、计算图整图下沉等技术，Graph模式执行网络的性能和效率更高。</li><li>代码调试：在脚本开发和网络流程调试中，推荐使用PyNative模式进行调试。在PyNative模式下，可以方便地设置断点，获取网络执行的中间结果，也可以通过pdb的方式对网络进行调试。而Graph模式无法设置断点，只能先指定算子进行打印，然后在网络执行完成后查看输出结果。</li></ul><p>下面以Graph模式为例，演示MindSpore单算子、普通函数、模型的执行方式，并进一步说明如何在PyNative模式下进行性能改进及梯度求取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> mindspore.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> mindspore <span class="keyword">import</span> context, Tensor, ParameterTuple, ms_function</span><br><span class="line"><span class="keyword">import</span> mindspore.ops <span class="keyword">as</span> ops</span><br><span class="line"><span class="keyword">from</span> mindspore <span class="keyword">import</span> dtype <span class="keyword">as</span> mstype</span><br><span class="line"><span class="keyword">from</span> mindspore.common.initializer <span class="keyword">import</span> Normal</span><br><span class="line"><span class="keyword">from</span> mindspore.nn <span class="keyword">import</span> Dense, WithLossCell, SoftmaxCrossEntropyWithLogits, Momentum</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定为Graph模式，也可替换为PYNATIVE_MODE</span></span><br><span class="line"><span class="comment"># MindSpore的默认方式GRAPH_MODE</span></span><br><span class="line">context.set_context(mode=context.GRAPH_MODE, device_target=<span class="string">&quot;Ascend&quot;</span>)</span><br><span class="line">conv = nn.Conv2d(<span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, bias_init=<span class="string">&#x27;zeros&#x27;</span>)</span><br><span class="line">input_data = Tensor(np.ones([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">5</span>]).astype(np.float32))</span><br><span class="line">output = conv(input_data)</span><br><span class="line"><span class="built_in">print</span>(output.asnumpy())</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>CANN错误分析，参考文献来自<a href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0/debug/error_analyze.html?highlight=cann">错误分析</a></p><p>只适用于Ascend平台。CANN（Compute Architecture for Neural Networks）是华为针对AI场景推出的异构计算架构，Ascend平台的MindSpore运行在CANN之上。这类报错一般在日志中会有<code>Ascend error occurred</code>关键字，报错消息由错误码和错误内容组成</p></li></ul><h3 id="pytest">pytest</h3><p>pytest是一个用于 Python 的<a href="https://so.csdn.net/so/search?q=%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6&amp;spm=1001.2101.3001.7020">测试框架</a>，支持简单的单元测试和复杂的功能测试。它以其<strong>简单</strong>、<strong>易用</strong>、<strong>灵活</strong>的特点，受到了许多开发者的青睐。<strong>强大的断言</strong>：内置丰富的断言方法，提供详细的失败信息。<strong>自动发现</strong>：自动发现测试文件和测试函数，无需显式地注册测试。</p><p>​把函数和类用@pytest修饰之后，运行pytest+文件名称，即可测试所有带修饰的函数和类。</p><h4 id="编写要求">编写要求</h4><ul><li><p>默认测试用例的格式：</p><ul><li><p>模块名：模块名（文件名）通常被统一放在一个testcases文件夹中，然后需要保证模块名以test_开头或_test结尾，例如test_demo1或demo2_test</p></li><li><p>类名：测试类类名必须以Test开头，并且不能带有init方法</p></li><li><p>方法名：测试方法名（Case 名）必须以test_开头，例如test_demo1(self)、test_demo2(self)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># test_demo1.py</span><br><span class="line">class TestDemo:</span><br><span class="line">    def test_demo1(self):</span><br><span class="line">        print(&quot;测试用例1&quot;)</span><br><span class="line"></span><br><span class="line">    def test_demo2(self):</span><br><span class="line">        print(&quot;测试用例2&quot;)</span><br><span class="line">    workage2 = 5</span><br><span class="line">    workage3 = 20</span><br><span class="line">    </span><br><span class="line">    # 只需采用 skip 或 skipif 方法来指定参数并贴在方法上即可跳过。满足条件就不会测试</span><br><span class="line">    @pytest.mark.skip(reason=&quot;无理由跳过&quot;)</span><br><span class="line">    def test_demo1(self):</span><br><span class="line">        print(&quot;我被跳过了&quot;)</span><br><span class="line">    @pytest.mark.skipif(workage2&lt;10,reason=&quot;工作经验少于10年跳过&quot;)    </span><br><span class="line">    def test_demo2(self):</span><br><span class="line">        print(&quot;由于经验不足，我被跳过了&quot;)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    # 我们在Case上采用@pytest.mark. + 分组名称，就相当于该方法被划分为该分组中</span><br><span class="line">    # 注意：一个分组可以有多个方法，一个方法也可以被划分到多个分组中，运行时候pytest -vs -m user_manage指定分组</span><br><span class="line">    @pytest.mark.user_manage</span><br><span class="line">    def test_demo1(self):</span><br><span class="line">        print(&quot;user_manage_test1&quot;)</span><br><span class="line"></span><br><span class="line">    @pytest.mark.product_manage</span><br><span class="line">    def test_demo2(self):</span><br><span class="line">        print(&quot;product_manage_test1&quot;)</span><br><span class="line">   </span><br></pre></td></tr></table></figure></li></ul></li><li><p>如果不想用默认的格式，可在根目录下自己写一个pytest.ini</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[pytest]</span><br><span class="line">#参数</span><br><span class="line">addopts = ‐vs</span><br><span class="line"># 默认的执行路径，它会默认执行该文件夹下所有的满足条件的测试case</span><br><span class="line">testpaths = ./testcases</span><br><span class="line"># 文件命名规则</span><br><span class="line">python_files = test_*.py</span><br><span class="line"># 类名命名规则</span><br><span class="line">python_classes = Test*</span><br><span class="line"># Case命名规则</span><br><span class="line">python_functions = test_*</span><br><span class="line"></span><br><span class="line"># 标记</span><br><span class="line">markers =</span><br><span class="line"># 冒烟规则</span><br><span class="line">smoke:冒烟用例 </span><br><span class="line">product_manage:商品管理</span><br></pre></td></tr></table></figure></li></ul><h4 id="指定执行顺序">指定执行顺序</h4><ol><li>默认方法（固件方法）：如果说有些函数需要指定在某个时间才能运行，则需要<strong>加修饰词和使用指定的函数名</strong></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import unittest</span><br><span class="line"></span><br><span class="line">class TestLogin(unittest.TestCase):</span><br><span class="line"></span><br><span class="line">    # 以下是用过修饰词使这两个函数必须在类内所有方法的前后去执行该操作，无论类的方法执行多少次，它只会调用一次</span><br><span class="line">    # 在执行该类前所需要调用的方法，函数名称必须这么写</span><br><span class="line">    @classmethod</span><br><span class="line">    def setUpClass(cls) -&gt; None:</span><br><span class="line">    print(&#x27;------打开浏览器&#x27;)</span><br><span class="line">    </span><br><span class="line">    # 在执行该类后所需要调用的方法</span><br><span class="line">    @classmethod</span><br><span class="line">    def tearDownClass(cls) -&gt; None:</span><br><span class="line">    print(&#x27;------关闭浏览器&#x27;)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    # 以下是使这两个函数必须在测试函数Case1和Case的指定时间运行，它会在每个方法执行前后去执行该操作</span><br><span class="line">    # 每个测试方法执行之前都会先调用的方法，函数名称必须这么写</span><br><span class="line">    def setUp(self):</span><br><span class="line">    print(&#x27;输入网址......&#x27;)</span><br><span class="line">    # 每个测试方法执行之后都会调用的方法</span><br><span class="line">    def tearDown(self) -&gt; None:</span><br><span class="line">    print(&#x27;关闭当前页面......&#x27;)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    # 以下是两个测试的例子</span><br><span class="line">    # 测试Case1</span><br><span class="line">    def test_1(self):</span><br><span class="line">    print(&#x27;输入正确用户名密码验证码,点击登录 1&#x27;)</span><br><span class="line"># 测试Case2</span><br><span class="line">    def test_2(self):</span><br><span class="line">    print(&#x27;输入错误用户名密码验证码,点击登录 2&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li><p>Fixtrue自定义方法</p><p><a href="https://blog.csdn.net/qq_45609369/article/details/140007322%EF%BC%8C%E5%94%89%EF%BC%8C%E4%B8%8D%E6%83%B3%E7%9C%8B%E4%BA%86%EF%BC%8C%E5%9B%9E%E5%AE%B6">https://blog.csdn.net/qq_45609369/article/details/140007322，唉，不想看了，回家</a></p></li></ol><h4 id="执行">执行</h4><p>只需采用 skip 或 skipif 方法来指定参数并贴在方法上即可跳过。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># -vs： -v输出详细信息 -s输出调试信息</span><br><span class="line">pytest -vs</span><br><span class="line"></span><br><span class="line"># -n： 多线程运行（前提安装插件：pytest-xdist）</span><br><span class="line">pytest -vs -n=2</span><br><span class="line"></span><br><span class="line"># --reruns num: 失败重跑（前提安装插件：pytest-rerunfailres）</span><br><span class="line">pytest -vs --reruns=2</span><br><span class="line"></span><br><span class="line"># -x: 出现一个用例失败则停止测试</span><br><span class="line">pytest -vs -x</span><br><span class="line"></span><br><span class="line"># --maxfail: 出现几个失败才终止</span><br><span class="line">pytest -vs --maxfail=2</span><br><span class="line"></span><br><span class="line"># --html: 生成html的测试报告,后面 需要跟上所创建的文件位置及文件名称（前提安装插件：pytest-html）</span><br><span class="line">pytest -vs --html ./reports/result.html</span><br><span class="line"></span><br><span class="line"># -k： 运行测试用例名称中包含某个字符串的测试用例，我们可以采用or表示或者，采用and表示都</span><br><span class="line">pytest -vs -k &quot;qiuluo&quot;</span><br><span class="line">pytest -vs -k &quot;qiuluo or weiliang&quot;</span><br><span class="line">pytest -vs -k &quot;qiuluo and weiliang&quot;</span><br><span class="line"></span><br><span class="line"># -m：冒烟用例执行，后面需要跟一个冒烟名称，执行user_manage这个分组</span><br><span class="line">pytest -vs -m user_manage</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="pytest-mark-parametrize">@pytest.mark.parametrize</h4><p>Pytest参数化有两种方式：</p><ol><li>@pytest.fixture(<a href="https://so.csdn.net/so/search?q=params&amp;spm=1001.2101.3001.7020">params</a>=[])</li><li>@pytest.mark.parametrize()，@pytest.mark.parametrize()使用方法更丰富一些</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@pytest.mark.parametrize(self,argnames, argvalues, indirect=False, ids=None, scope=None))：</span><br><span class="line">argnames 必传，参数名, 以逗号分隔的字符串,表示一个或多个参数名称(key),或参数字符串的列表/元组</span><br><span class="line">argvalues 必传，参数值，若argnames有一个刚单值列表传入，若argnames有多个，以套用元组的列表展示，无组内与参数名一一对应</span><br><span class="line">indirect 为true时，那argnames一定是一个fixture函数名称，argvalues值将传入对应的fixture内，相当于@pytest.fixture(params=)的用法，默认False</span><br><span class="line">ids 标记子用例执行名称，与argvalues数量一致，未指定自动生成,默认None</span><br><span class="line">scope 如果指定，则表示参数的范围。范围用于按参数实例对测试进行分组</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>快速入门</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、单个参数【测试方法入参只有一个参数】</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"><span class="string">&quot;a&quot;</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span>)    </span><span class="comment"># 参数a被赋予3个值，test_a将会运行3遍</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_a</span>(<span class="params">self, a</span>):    <span class="comment"># 参数必须和parametrize里面的参数一致</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n------------------&gt; test_a has ran, and a = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a))</span><br><span class="line">    <span class="keyword">assert</span> <span class="number">1</span> == a <span class="comment"># 不是1就会报错</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pytest.main([<span class="string">&#x27;-s&#x27;</span>, <span class="string">&#x27;test_parametrize.py&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、多个参数【测试方法入参有多个参数】</span></span><br><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test_D</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;a,b&quot;</span>, [(<span class="params"><span class="number">1</span>, <span class="number">2</span></span>), (<span class="params"><span class="number">2</span>, <span class="number">3</span></span>), (<span class="params"><span class="number">3</span>, <span class="number">4</span></span>)]</span>)    </span><span class="comment"># 参数a,b均被赋予三个值，函数会运行三遍</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_b</span>(<span class="params">self, a, b</span>):    <span class="comment"># 参数必须和parametrize里面的参数一致</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\n------------------&gt; test_b has ran, and a = &#123;&#125;, b = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a, b))</span><br><span class="line">        <span class="keyword">assert</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pytest.main([<span class="string">&#x27;-s&#x27;</span>, <span class="string">&#x27;test_parametrize.py&#x27;</span>])       </span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、利用函数的返回值进行用例参数化file_name: test_parametrize.py</span></span><br><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">return_test_data</span>():<span class="comment"># 定义返回参数值的函数</span></span><br><span class="line">    <span class="keyword">return</span> [(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">3</span>), (<span class="number">3</span>, <span class="number">4</span>)]</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test_D</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;a,b&quot;</span>, return_test_data(<span class="params"></span>)</span>)    </span><span class="comment"># 使用函数返回值的方式传入参数值</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_c</span>(<span class="params">self, a, b</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\n------------------&gt; test_c has ran, and a = &#123;&#125;, b = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a, b))</span><br><span class="line">        <span class="keyword">assert</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pytest.main([<span class="string">&#x27;-s&#x27;</span>, <span class="string">&#x27;test_parametrize.py&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、堆叠使用参数化装饰器 file_name: test_parametrize.py</span></span><br><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test_D</span>:</span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;x&quot;</span>, [<span class="number">1</span>, <span class="number">2</span>]</span>)</span></span><br><span class="line"><span class="meta">    @pytest.mark.parametrize(<span class="params"><span class="string">&quot;y&quot;</span>, [<span class="number">3</span>, <span class="number">4</span>]</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_d</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n------------------&gt; test_d has ran, and x=&#123;&#125;, y=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(x, y))</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pytest.main([<span class="string">&#x27;-s&#x27;</span>, <span class="string">&#x27;test_parametrize.py&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="程序">程序</h2><p>查阅<a href="https://www.mindspore.cn/docs/zh-CN/master/note/api_mapping/pytorch_api_mapping.html">API对应表</a></p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>mindspore.mint.div</td><td><a href="https://pytorch.org/docs/2.1/generated/torch.div.html">torch.div</a></td><td>逐元素计算 input 除以 other 的商。</td></tr><tr><td>mindspore.mint.divide</td><td><a href="https://pytorch.org/docs/2.1/generated/torch.divide.html">torch.divide</a></td><td><a href="https://www.mindspore.cn/docs/zh-CN/master/api_python/mint/mindspore.mint.div.html#mindspore.mint.div"><code>mindspore.mint.div()</code></a> 的别名。那就只需要写一个</td></tr><tr><td>mindspore.mint.erf</td><td><a href="https://pytorch.org/docs/2.1/generated/torch.erf.html">torch.erf</a></td><td>逐元素计算 input 的高斯误差</td></tr><tr><td>mindspore.mint.erfc</td><td><a href="https://pytorch.org/docs/2.1/generated/torch.erfc.html">torch.erfc</a></td><td>逐元素计算 input 的互补误差函数</td></tr><tr><td>mindspore.mint.erfinv</td><td><a href="https://pytorch.org/docs/2.1/generated/torch.erfinv.html">torch.erfinv</a></td><td>计算输入的逆误差函数。</td></tr></tbody></table><p>注意：任务b实际上测试的是除了计算参数之外的设定，比如div函数的rounding参数，如果没有多余参数可以不测试</p><h3 id="任务a">任务a</h3><ol><li>查API支持的数据类型，如mindspore.mint.erf标注支持数据类型：Ascend： float16、float32、float64、int64、bool、bfloat16。则设置在两种模式下分别进行计算。</li><li>如果支持这个参数则跳过，不支持则打印</li><li>如果两个框架都支持这个类型的参数则比较两个计算结果是否相同</li></ol><h3 id="任务b">任务b</h3><ol><li>设置类型为常见的float32，但是输入的tensor大小给出多种，然后创建随机tensor，注意erfinv的数据要在-1到1之间，在两种模式下分别进行计算。</li><li>如果该模式下的计算结果和torch的相同则跳过，不相同则打印</li></ol><h3 id="任务c">任务c</h3><ol><li>针对比如div函数需要rounding参数，    parameters = [None, “trunc”, “floor”]，分别传入这个参数，然后和任务b一样进行计算。</li><li>如果该模式下的计算结果和torch的相同则跳过，不相同则打印</li></ol><h3 id="任务d">任务d</h3><ol><li>在API页面含有报错抛出信息，进行测试比如mindspore.mint.erf，异常为<ul><li><strong>TypeError</strong> - input 不是Tensor。</li><li><strong>TypeError</strong> -Ascend: 如果 input 的数据类型不是float16、float32、float64、int64、bool、bfloat16。</li></ul></li></ol><h3 id="任务2">任务2</h3><p>固定一个尺寸固定数据的tensor，计算正向传播和梯度，进行对比</p><h2 id="服务器使用">服务器使用</h2><p>启智社区注册账号，建立项目，然后建立一个环境，环境选择Acend910b，镜像选择为mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0，上传代码，代码会默认压缩安放在/tmp/code/master.zip，首先需要解压。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">unzip master.zip</span><br><span class="line"><span class="comment"># 每次打开终端安装环境</span></span><br><span class="line">pip install pytest</span><br><span class="line">pip install torch==2.6</span><br><span class="line">pip install mindspore==2.4</span><br><span class="line"><span class="comment"># 然后需要解决一个报错，注意这个libgomp每次打开终端后面的版本号可能不同</span></span><br><span class="line"><span class="built_in">export</span> LD_PRELOAD=<span class="variable">$LD_PRELOAD</span>:/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch.libs/libgomp-74ff64e9.so.1.0.0 </span><br><span class="line"><span class="comment"># 注意每次创建一个终端都需安装环境</span></span><br><span class="line"><span class="comment"># 然后运行脚本，保存日志</span></span><br><span class="line">pytest -vs test_div.py&gt;test_div.txt</span><br><span class="line"><span class="comment"># 把日志dowload下来看，因为这个启智社区的网络连接是真的烂</span></span><br></pre></td></tr></table></figure><h2 id="结果">结果</h2><h3 id="div">div</h3><p>环境信息：</p><p>硬件： 新疆大学智算中心NPU: 1*Ascend-D910B(显存: 32GB), CPU: 20, 内存: 60GB</p><p>镜像：mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0</p><p>命令行：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每次打开终端安装环境</span></span><br><span class="line">pip install pytest</span><br><span class="line">pip install torch==2.6</span><br><span class="line">pip install mindspore==2.4</span><br><span class="line"><span class="comment"># 然后需要解决一个报错，注意这个libgomp每次打开终端后面的版本号可能不同</span></span><br><span class="line"><span class="built_in">export</span> LD_PRELOAD=<span class="variable">$LD_PRELOAD</span>:/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch.libs/libgomp-74ff64e9.so.1.0.0 </span><br></pre></td></tr></table></figure><ol><li>类型支持测试，API未编写支持类型，但是不支持UInt16，UInt32，UInt64，BFloat16</li></ol><table><thead><tr><th>环境</th><th>不支持的数据类型</th><th>支持的数据类型</th><th>错误</th></tr></thead><tbody><tr><td>mindspore (GRAPH_MODE)</td><td>UInt16<br/>UInt32<br/>UInt64<br/>BFloat16</td><td>ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8,ms.float16, ms.float32, ms.float64, ms.bool_</td><td></td></tr><tr><td>mindspore(PYNATIVE_MODE)</td><td>UInt16<br/>UInt32<br/>UInt64<br/>BFloat16</td><td>ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8,ms.float16, ms.float32, ms.float64, ms.bool_</td><td></td></tr><tr><td>torch</td><td>torch.bfloat16</td><td>torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bool</td><td></td></tr></tbody></table><ol start="2"><li>计算测试，通过</li></ol><p>test_div.py::test_div_random_input_fixed_dtype[0] PASSED<br>test_div.py::test_div_random_input_fixed_dtype[1] PASSED</p><ol start="3"><li><p>参数输入</p><table><thead><tr><th>模式</th><th>参数</th><th>计算结果是否通过</th></tr></thead><tbody><tr><td>GRAPH_MODE</td><td>None</td><td>通过</td></tr><tr><td></td><td>trunc</td><td>通过</td></tr><tr><td></td><td>floor</td><td>通过</td></tr><tr><td>GRAPH_MODE</td><td>None</td><td>通过</td></tr><tr><td></td><td>trunc</td><td>通过</td></tr><tr><td></td><td>floor</td><td>通过</td></tr></tbody></table></li><li><p>报错测试</p><p>均通过</p></li><li><p>梯度测试</p><p>均通过</p></li></ol><h3 id="divide">divide</h3><p>环境信息：</p><p>硬件： 新疆大学智算中心NPU: 1*Ascend-D910B(显存: 32GB), CPU: 20, 内存: 60GB</p><p>镜像：mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0</p><p>命令行：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每次打开终端安装环境</span></span><br><span class="line">pip install pytest</span><br><span class="line">pip install torch==2.6</span><br><span class="line">pip install mindspore==2.4</span><br><span class="line"><span class="comment"># 然后需要解决一个报错，注意这个libgomp每次打开终端后面的版本号可能不同</span></span><br><span class="line"><span class="built_in">export</span> LD_PRELOAD=<span class="variable">$LD_PRELOAD</span>:/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch.libs/libgomp-74ff64e9.so.1.0.0 </span><br></pre></td></tr></table></figure><ol><li>类型支持测试，API未编写支持类型，但是不支持UInt16，UInt32，UInt64，BFloat16</li></ol><table><thead><tr><th>环境</th><th>不支持的数据类型</th><th>支持的数据类型</th><th>错误</th></tr></thead><tbody><tr><td>mindspore (GRAPH_MODE)</td><td>UInt16<br/>UInt32<br/>UInt64<br/>BFloat16</td><td>ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8,ms.float16, ms.float32, ms.float64, ms.bool_</td><td></td></tr><tr><td>mindspore(PYNATIVE_MODE)</td><td>UInt16<br/>UInt32<br/>UInt64<br/>BFloat16</td><td>ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8,ms.float16, ms.float32, ms.float64, ms.bool_</td><td></td></tr><tr><td>torch</td><td>torch.bfloat16</td><td>torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bool</td><td></td></tr></tbody></table><ol start="2"><li>计算测试，通过</li></ol><p>test_div.py::test_divide_random_input_fixed_dtype[0] PASSED<br>test_div.py::test_divide_random_input_fixed_dtype[1] PASSED</p><ol start="3"><li><p>参数输入</p><table><thead><tr><th>模式</th><th>参数</th><th>计算结果是否通过</th></tr></thead><tbody><tr><td>GRAPH_MODE</td><td>None</td><td>通过</td></tr><tr><td></td><td>trunc</td><td>通过</td></tr><tr><td></td><td>floor</td><td>通过</td></tr><tr><td>GRAPH_MODE</td><td>None</td><td>通过</td></tr><tr><td></td><td>trunc</td><td>通过</td></tr><tr><td></td><td>floor</td><td>通过</td></tr></tbody></table></li><li><p>报错测试</p><p>均通过</p></li><li><p>梯度测试</p><p>均通过</p></li></ol><h3 id="erf">erf</h3><p>环境信息：</p><p>硬件： 新疆大学智算中心NPU: 1*Ascend-D910B(显存: 32GB), CPU: 20, 内存: 60GB</p><p>镜像：mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0</p><p>命令行：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每次打开终端安装环境</span></span><br><span class="line">pip install pytest</span><br><span class="line">pip install torch==2.6</span><br><span class="line">pip install mindspore==2.4</span><br><span class="line"><span class="comment"># 然后需要解决一个报错，注意这个libgomp每次打开终端后面的版本号可能不同</span></span><br><span class="line"><span class="built_in">export</span> LD_PRELOAD=<span class="variable">$LD_PRELOAD</span>:/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch.libs/libgomp-74ff64e9.so.1.0.0 </span><br></pre></td></tr></table></figure><ol><li>类型支持测试，不通过，需要支持 BFloat16</li></ol><table><thead><tr><th>环境</th><th>不支持的数据类型</th><th>支持的数据类型</th><th>错误</th></tr></thead><tbody><tr><td>mindspore (GRAPH_MODE)</td><td>BFloat16</td><td>ms.float16, ms.float32, ms.float64, ms.int64, ms.bool_, ms.bfloat16</td><td>Float32,Int64,Bool和torch的计算结果不同</td></tr><tr><td>mindspore(PYNATIVE_MODE)</td><td>BFloat16</td><td>ms.float16, ms.float32, ms.float64, ms.int64, ms.bool_, ms.bfloat16</td><td>Float32,Int64,Bool和torch的计算结果不同</td></tr><tr><td>torch</td><td>torch.bfloat16</td><td>torch.float16, torch.float32, torch.float64, torch.int64, torch.bool, torch.bfloat16</td><td></td></tr></tbody></table><ol start="2"><li><p>计算测试</p><ol><li><p>测试组，小数点后5位不同，不知道是否算测试通过</p><p>input_data: [-0.37975368 -0.34422294 -1.42222966 -1.04481118  0.95105012]<br>ms_result: [-0.4087475  -0.37358218 -0.9556926  -0.860494    0.8213899 ]<br>torch_result: [-0.408769   -0.37360325 -0.95571023 -0.8604813   0.8213707 ]</p></li><li><p>测试组，小数点后5位不同<br>input_data: [ 2.22057531 -1.10386126 -0.54387706  0.14834316  1.51924453]<br>ms_result: [ 0.99830514 -0.8815062  -0.5581943   0.16617936  0.96830803]<br>torch_result: [ 0.99831253 -0.88149875 -0.5582007   0.16616759  0.96832895]</p></li></ol></li><li><p>参数输入</p><p>无参数设置，均通过</p></li><li><p>报错测试</p><p>均通过</p></li><li><p>梯度测试</p><p>均通过</p></li></ol><h3 id="erfc">erfc</h3><p>环境信息：</p><p>硬件： 新疆大学智算中心NPU: 1*Ascend-D910B(显存: 32GB), CPU: 20, 内存: 60GB</p><p>镜像：mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0</p><p>命令行：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每次打开终端安装环境</span></span><br><span class="line">pip install pytest</span><br><span class="line">pip install torch==2.6</span><br><span class="line">pip install mindspore==2.4</span><br><span class="line"><span class="comment"># 然后需要解决一个报错，注意这个libgomp每次打开终端后面的版本号可能不同</span></span><br><span class="line"><span class="built_in">export</span> LD_PRELOAD=<span class="variable">$LD_PRELOAD</span>:/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch.libs/libgomp-74ff64e9.so.1.0.0 </span><br></pre></td></tr></table></figure><ol><li>类型支持测试，不通过，需要支持 BFloat16</li></ol><table><thead><tr><th>环境</th><th>不支持的数据类型</th><th>支持的数据类型</th><th>错误</th></tr></thead><tbody><tr><td>mindspore (GRAPH_MODE)</td><td>BFloat16</td><td>ms.float16, ms.float32, ms.float64, ms.int64, ms.bool_, ms.bfloat16</td><td>Float32,Int64,Bool和torch的计算结果不同</td></tr><tr><td>mindspore(PYNATIVE_MODE)</td><td>BFloat16</td><td>ms.float16, ms.float32, ms.float64, ms.int64, ms.bool_, ms.bfloat16</td><td>Float32,Int64,Bool和torch的计算结果不同</td></tr><tr><td>torch</td><td>torch.bfloat16</td><td>torch.float16, torch.float32, torch.float64, torch.int64, torch.bool, torch.bfloat16</td><td></td></tr></tbody></table><ol start="2"><li><p>计算测试</p><ol><li><p>测试组，小数点后5位不同，不知道是否算测试通过</p><p>input_data: [ 0.55593791  0.44808426 -2.71790637 -0.53732477 -0.45158543]<br>ms_result: [0.43174636 0.5263032  1.9998777  1.5526736  1.4769242 ]<br>torch_result: [0.4317416  0.52628523 1.9998788  1.5526809  1.4769417 ]</p></li><li><p>测试组，小数点后5位不同</p><p>input_data: [ 0.53237093 -0.99921068  0.81374149  0.05919775 -0.15359628]<br>ms_result: [0.45152628 1.8423889  0.24979174 0.93325967 1.1719722 ]<br>torch_result: [0.4515183  1.8423729  0.24981277 0.93328047 1.1719615 ]</p></li></ol></li><li><p>参数输入</p><p>无参数设置，均通过</p></li><li><p>报错测试</p><p>均通过</p></li><li><p>梯度测试</p><p>均通过</p></li></ol><h3 id="erfinv">erfinv</h3><p>环境信息：</p><p>硬件： 新疆大学智算中心NPU: 1*Ascend-D910B(显存: 32GB), CPU: 20, 内存: 60GB</p><p>镜像：mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0</p><p>命令行：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每次打开终端安装环境</span></span><br><span class="line">pip install pytest</span><br><span class="line">pip install torch==2.6</span><br><span class="line">pip install mindspore==2.4</span><br><span class="line"><span class="comment"># 然后需要解决一个报错，注意这个libgomp每次打开终端后面的版本号可能不同</span></span><br><span class="line"><span class="built_in">export</span> LD_PRELOAD=<span class="variable">$LD_PRELOAD</span>:/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch.libs/libgomp-74ff64e9.so.1.0.0 </span><br></pre></td></tr></table></figure><ol><li>类型支持测试，通过</li></ol><table><thead><tr><th>环境</th><th>不支持的数据类型</th><th>支持的数据类型</th><th>错误</th></tr></thead><tbody><tr><td>mindspore (GRAPH_MODE)</td><td></td><td>ms.float16, ms.float32, ms.int8, ms.int16,ms.int32, ms.int64, ms.uint8, ms.bool_</td><td></td></tr><tr><td>mindspore(PYNATIVE_MODE)</td><td></td><td>ms.float16, ms.float32, ms.float64, ms.int64, ms.bool_, ms.bfloat16</td><td></td></tr><tr><td>torch</td><td></td><td>torch.float16, torch.float32, torch.int8, torch.int16,torch.int32, torch.int64, torch.uint8, torch.bool</td><td></td></tr></tbody></table><ol start="2"><li><p>计算测试，通过</p><p>在GRAPH模式下，tensor大小在为[4, 6, 7, 8] 时计算结果与torch不同，但是差距很小</p><p>在PYNATIVE模式下，tensor大小在[5，4, 3]时与torch不同，但是差距很小</p><p>input_data: [[[-0.16848439 -0.2019851   0.36715633]<br>[ 0.3096696  -0.11560675  0.91190031]<br>[ 0.94261078  0.95440446 -0.5036123 ]<br>[ 0.95595146 -0.54710461 -0.42151996]]</p><p>[[ 0.69609619  0.33447626 -0.91189684]<br>[-0.44852735  0.45557708  0.03501383]<br>[ 0.2079667   0.10272845 -0.29821255]<br>[-0.17657432  0.57332459  0.78557388]]</p><p>[[-0.92765529  0.46980589 -0.54225893]<br>[ 0.46168587 -0.29652803  0.94215718]<br>[ 0.34109872  0.2191107   0.21868642]<br>[-0.54319334 -0.30351475 -0.53197152]]</p><p>[[ 0.19239459 -0.52627742 -0.80364875]<br>[ 0.8073855   0.70755351  0.08547598]<br>[ 0.3102941  -0.44570836 -0.50435729]<br>[-0.63445313 -0.98493728 -0.24300708]]</p><p>[[-0.57635299 -0.52763846 -0.63903526]<br>[-0.2464637  -0.30461796 -0.35513484]<br>[ 0.66277941  0.006608    0.56438567]<br>[ 0.94051533 -0.03502053 -0.54777088]]]<br>ms_result: [[[-0.15044294 -0.18096098  0.33780497]<br>[ 0.28171614 -0.10281489  1.2059761 ]<br>[ 1.3437392   1.4135892  -0.48096272]<br>[ 1.4238497  -0.53075176 -0.39287293]]</p><p>[[ 0.72697484  0.3056821  -1.205963  ]<br>[-0.42112073  0.4286044   0.03104022]<br>[ 0.18644391  0.09129365 -0.27075744]<br>[-0.15778473  0.5620745   0.8778638 ]]</p><p>[[-1.2706298   0.44385767 -0.5250773 ]<br>[ 0.43512827 -0.26915175  1.3413013 ]<br>[ 0.3121386   0.19668916  0.1962984 ]<br>[-0.52616894 -0.27582082 -0.5131406 ]]</p><p>[[ 0.17219217 -0.50659615 -0.9135943 ]<br>[ 0.92127806  0.74442077  0.07589649]<br>[ 0.28231534 -0.4181416  -0.48179516]<br>[-0.6398228  -1.7188823  -0.21880175]]</p><p>[[-0.56576306 -0.5081564  -0.645962  ]<br>[-0.22201757 -0.2768761  -0.3259106 ]<br>[ 0.67859024  0.00585618  0.55127466]<br>[ 1.3326088  -0.03104615 -0.5315348 ]]]<br>torch_result: [[[-0.15044273 -0.18096067  0.33780485]<br>[ 0.2817161  -0.10281495  1.2059764 ]<br>[ 1.3437395   1.4135904  -0.48096296]<br>[ 1.4238504  -0.530752   -0.39287296]]</p><p>[[ 0.7269749   0.3056819  -1.2059633 ]<br>[-0.42112085  0.42860448  0.03104016]<br>[ 0.18644369  0.09129371 -0.27075735]<br>[-0.1577846   0.5620746   0.87786347]]</p><p>[[-1.2706304   0.44385782 -0.5250774 ]<br>[ 0.4351283  -0.26915163  1.3413019 ]<br>[ 0.3121386   0.19668904  0.19629823]<br>[-0.52616906 -0.2758207  -0.51314074]]</p><p>[[ 0.17219207 -0.50659627 -0.91359407]<br>[ 0.9212778   0.74442065  0.07589659]<br>[ 0.28231534 -0.41814157 -0.48179537]<br>[-0.6398229  -1.7188824  -0.21880147]]</p><p>[[-0.5657633  -0.5081566  -0.6459621 ]<br>[-0.22201732 -0.276876   -0.32591063]<br>[ 0.6785902   0.00585625  0.5512749 ]<br>[ 1.332609   -0.03104611 -0.5315349 ]]]</p></li><li><p>无参数设置，均通过</p></li><li><p>报错测试</p><p>均通过</p></li><li><p>梯度测试</p><p>均通过</p></li></ol><h2 id="如何进行任务提交">如何进行任务提交</h2><ul><li><p>哪里有问题，就在mindspore的gitee仓库提交issue，里面有模板，需要填写硬件和软件以及报错截图。基本上每个函数都要提交一个issue</p></li><li><p>然后在mindspore的gitee仓库mindspore-test仓库提交一个pullreuqust，内容就是把issue列进去，然后把test文件贴进去</p><ol><li><p>在gitee或者github，fork原仓库A到我的仓库B（B是A的fork版本）</p></li><li><p>将仓库B clone到我本地电脑<br>git clone XXX</p><ol><li><p>kex_exchange_identification: Connection closed by remote host<br>Connection closed by 20.205.243.166 port 22<br>fatal: 无法读取远程仓库。</p><p>请确认您有正确的访问权限并且仓库存在。</p><ol><li>临时关闭代理</li></ol><p>虽然关闭代理最简单，但是可能会导致下载速度过慢<br>2. 修改代理软件配置，22 端口走直连</p><p>最安全的办法是修改代理软件的配置，将 22 端口走直连，不同的代理软件配置方式不同，这里就不详细介绍了<br>3. 改用 HTTPS 协议，走 443 端口</p><p>个人最推荐的办法是改用 HTTPS 协议，走 443 端口，因为这样不仅可以解决上面的问题，还可以通过代理提高下载速度</p></li></ol></li><li><p>在本地创建一个分支，如bugfix/issue-12，该分支用于存放我的代码修改。同时在我的github上的仓库B也创建一个同名的该分支</p></li><li><p>切换到该分支bugfix/issue-12，修改代码<br>git checkout -b bugfix/issue-12</p></li><li><p>修改好了，add，commit，然后push到我远程的仓库B的bugfix/issue-12分支<br>git push -u origin bugfix/issue-12</p></li><li><p>在我的github的仓库B中创建pull request。选择仓库B的该分支，推送到原仓库A的某一个分支。具体是哪个分支，参考仓库A的contributing说明，一般是dev分支；如果没说，就只能选择master分支咯</p></li></ol></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;mindspore.mint接口测试任务&lt;/h1&gt;
&lt;h2 id=&quot;任务&quot;&gt;任务&lt;/h2&gt;
&lt;h3 id=&quot;任务背景&quot;&gt;任务背景&lt;/h3&gt;
&lt;p&gt;mindspore.mint提供了大量的functional、nn、优化器接口，API用法及功能等与业界主流用法一致，方便用户</summary>
      
    
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="mindspore实习" scheme="http://outbreak-sen.github.io/tags/mindspore%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 BigBird 的块稀疏注意力</title>
    <link href="http://outbreak-sen.github.io/2025/02/11/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-BigBird-%E7%9A%84%E5%9D%97%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9B/"/>
    <id>http://outbreak-sen.github.io/2025/02/11/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-BigBird-%E7%9A%84%E5%9D%97%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9B/</id>
    <published>2025-02-11T01:51:43.000Z</published>
    <updated>2025-03-19T09:10:27.313Z</updated>
    
    <content type="html"><![CDATA[<h1>深入理解 BigBird 的块稀疏注意力</h1><p><a href="https://github.com/huggingface/blog/blob/main/zh/big-bird.md">文档来自</a></p><h2 id="引言">引言</h2><p>基于 transformer 的模型已被证明对很多 NLP 任务都非常有用。然而，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的时间和内存复杂度 (其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> 是序列长度) 使得在长序列 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&gt;</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">n &gt; 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span>) 上应用它们变得非常昂贵，因而大大限制了其应用。最近的几篇论文，如 <code>Longformer</code> 、<code>Performer</code> 、<code>Reformer</code> 、<code>簇状注意力</code> 都试图通过对完整注意力矩阵进行近似来解决这个问题。如果你不熟悉这些模型，可以查看 🤗 之前的 <a href="https://huggingface.co/blog/zh/long-range-transformers">博文</a>。</p><p><code>BigBird</code> (由 <a href="https://arxiv.org/abs/2007.14062">该论文</a> 引入) 是解决这个问题的最新模型之一。 <code>BigBird</code> 依赖于 <strong>块稀疏注意力</strong> 而不是普通注意力 ( <em>即</em> BERT 的注意力)，与 BERT 相比，这一新算法能以低得多的计算成本处理长达 <strong>4096</strong> 的序列。在涉及很长序列的各种任务上，该模型都实现了 SOTA，例如长文档摘要、长上下文问答。</p><p><strong>RoBERTa 架构的 BigBird</strong> 模型现已集成入 🤗 transformers 中。本文的目的是让读者 <strong>深入</strong> 了解 BigBird 的实现，并让读者能在 🤗 transformers 中轻松使用 BigBird。但是，在更深入之前，一定记住 <code>BigBird</code> 注意力只是 <code>BERT</code> 完全注意力的一个近似，因此我们并不纠结于让它比 <code>BERT</code> 完全注意力 <strong>更好</strong>，而是致力于让它更有效率。有了它，transformer 模型就可以作用于更长的序列，因为 BERT 的二次方内存需求很快会变得难以为继。简而言之，如果我们有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span> 计算和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">∞</span></span></span></span> 时间，那么用 BERT 注意力就好了，完全没必要用本文讨论的块稀疏注意力。</p><p>如果你想知道为什么在处理较长序列时需要更多计算，那么本文正合你意！</p><hr><p>在使用标准的 <code>BERT</code> 类注意力时可能会遇到以下几个主要问题:</p><ul><li>每个词元真的都必须关注所有其他词元吗？</li><li>为什么不只计算重要词元的注意力？</li><li>如何决定哪些词元重要？</li><li>如何以高效的方式处理少量词元？</li></ul><hr><p>本文，我们将尝试回答这些问题。</p><h3 id="应该关注哪些词元？">应该关注哪些词元？</h3><p>下面，我们将以句子 <code>BigBird is now available in HuggingFace for extractive Question Answering</code> 为例来说明注意力是如何工作的。在 <code>BERT</code> 这类的注意力机制中，每个词元都简单粗暴地关注所有其他词元。从数学上来讲，这意味着每个查询的词元 $ \text{query-token} \in {\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering}} $,<br>将关注每个键词元 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>key-tokens</mtext><mo>=</mo><mrow><mo fence="true">[</mo><mtext>BigBird</mtext><mo separator="true">,</mo><mtext>is</mtext><mo separator="true">,</mo><mtext>now</mtext><mo separator="true">,</mo><mtext>available</mtext><mo separator="true">,</mo><mtext>in</mtext><mo separator="true">,</mo><mtext>HuggingFace</mtext><mo separator="true">,</mo><mtext>for</mtext><mo separator="true">,</mo><mtext>extractive</mtext><mo separator="true">,</mo><mtext>question</mtext><mo separator="true">,</mo><mtext>answering</mtext><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\text{key-tokens} = \left[\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering} \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">key-tokens</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord text"><span class="mord">BigBird</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">is</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">now</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">available</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">in</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">HuggingFace</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">for</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">extractive</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">question</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">answering</span></span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span>。</p><p>我们考虑一下 <code>每个查询词元应如何明智地选择它实际上应该关注的键词元</code> 这个问题，下面我们通过编写伪代码的方式来整理思考过程。</p><p>假设 <code>available</code> 是当前查询词元，我们来构建一个合理的、需要关注的键词元列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下面的句子为例</span></span><br><span class="line">example = [<span class="string">&#x27;BigBird&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;now&#x27;</span>, <span class="string">&#x27;available&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;HuggingFace&#x27;</span>, <span class="string">&#x27;for&#x27;</span>, <span class="string">&#x27;extractive&#x27;</span>, <span class="string">&#x27;question&#x27;</span>, <span class="string">&#x27;answering&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设当前需要计算 &#x27;available&#x27; 这个词的表征</span></span><br><span class="line">query_token = <span class="string">&#x27;available&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一个空集合，用于放 &#x27;available&#x27; 这个词的键词元</span></span><br><span class="line">key_tokens = [] <span class="comment"># =&gt; 目前，&#x27;available&#x27; 词元不关注任何词元</span></span><br></pre></td></tr></table></figure><p>邻近词元当然很重要，因为在一个句子 (单词序列) 中，当前词高度依赖于前后的邻近词。<code>滑动注意力</code> 即基于该直觉。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 考虑滑动窗大小为 3, 即将 &#x27;available&#x27; 的左边一个词和右边一个词纳入考量</span></span><br><span class="line"><span class="comment"># 左词: &#x27;now&#x27;; 右词: &#x27;in&#x27;</span></span><br><span class="line">sliding_tokens = [<span class="string">&quot;now&quot;</span>, <span class="string">&quot;available&quot;</span>, <span class="string">&quot;in&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用以上词元更新集合</span></span><br><span class="line">key_tokens.append(sliding_tokens)</span><br></pre></td></tr></table></figure><p><strong>长程依赖关系:</strong> 对某些任务而言，捕获词元间的长程关系至关重要。 <em>例如</em> ，在问答类任务中，模型需要将上下文的每个词元与整个问题进行比较，以便能够找出上下文的哪一部分对正确答案有用。如果大多数上下文词元仅关注其他上下文词元，而不关注问题，那么模型从不太重要的上下文词元中过滤重要的上下文词元就会变得更加困难。</p><p><code>BigBird</code> 提出了两种允许长程注意力依赖的方法，这两种方法都能保证计算效率。</p><ul><li><strong>全局词元:</strong> 引入一些词元，这些词元将关注每个词元并且被每个词元关注。例如，对 <em>“HuggingFace is building nice libraries for easy NLP”</em> ，现在假设 <em>‘building’</em> 被定义为全局词元，而对某些任务而言，模型需要知道 <em>‘NLP’</em> 和 <em>‘HuggingFace’</em> 之间的关系 (注意: 这 2 个词元位于句子的两端); 现在让 <em>‘building’</em> 在全局范围内关注所有其他词元，会对模型将 <em>‘NLP’</em> 与 <em>‘HuggingFace’</em> 关联起来有帮助。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们假设第一个和最后一个词元是全局的，则有:</span></span><br><span class="line">global_tokens = [<span class="string">&quot;BigBird&quot;</span>, <span class="string">&quot;answering&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将全局词元加入到集合中</span></span><br><span class="line">key_tokens.append(global_tokens)</span><br></pre></td></tr></table></figure><ul><li><strong>随机词元:</strong> 随机选择一些词元，这些词元将通过关注其他词元来传输信息，而那些词元又可以传输信息到其他词元。这可以降低直接从一个词元到另一个词元的信息传输成本。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 现在，我们可以从句子中随机选择 `r` 个词元。这里，假设 `r` 为 1， 选择了 `is` 这个词元</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_tokens = [<span class="string">&quot;is&quot;</span>] <span class="comment"># 注意: 这个是完全随机选择的，因此可以是任意词元。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将随机词元加入到集合中</span></span><br><span class="line">key_tokens.append(random_tokens)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在看下 `key_tokens` 集合中有哪些词元</span></span><br><span class="line">key_tokens</span><br><span class="line">&#123;<span class="string">&#x27;now&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;answering&#x27;</span>, <span class="string">&#x27;available&#x27;</span>, <span class="string">&#x27;BigBird&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 至此，查询词 &#x27;available&#x27; 仅关注集合中的这些词元，而不用关心全部</span></span><br></pre></td></tr></table></figure><p>这样，查询词元仅关注所有词元的一个子集，该子集能够产生完全注意力值的一个不错的近似。相同的方法将用于所有其他查询词元。但请记住，这里的重点是尽可能有效地接近 <code>BERT</code> 的完全注意力。BERT 那种简单地让每个查询词元关注所有键词元的做法可以建模为一系列矩阵乘法，从而在现代硬件 (如 GPU) 上进行高效计算。然而，滑动、全局和随机注意力的组合似乎意味着稀疏矩阵乘法，这在现代硬件上很难高效实现。<code>BigBird</code> 的主要贡献之一是提出了 <code>块稀疏</code> 注意力机制，该机制可以高效计算滑动、全局和随机注意力。我们来看看吧！</p><h3 id="图解全局-滑动-随机注意力的概念">图解全局、滑动、随机注意力的概念</h3><p>首先，我们借助图来帮助理解“全局”、“滑动”和“随机”注意力，并尝试理解这三种注意力机制的组合是如何较好地近似标准 BERT 类注意力的。</p><img src="https://huggingface.co/blog/assets/18_big_bird/global.png" width=250 height=250><img src="https://huggingface.co/blog/assets/18_big_bird/sliding.png" width=250 height=250><img src="https://huggingface.co/blog/assets/18_big_bird/random.png" width=250 height=250> <br><p><em>上图分别把“全局”(左) 、“滑动”(中) 和“随机”(右) 连接建模成一个图。每个节点对应一个词元，每条边代表一个注意力分数。如果 2 个词元之间没有边连接，则其注意力分数为 0。</em></p><p><img src="https://huggingface.co/blog/assets/18_big_bird/graph.gif" alt=""></p><img src="https://huggingface.co/blog/assets/18_big_bird/full.png" width=230 height=230><p><strong>BigBird 块稀疏注意力</strong> 是滑动连接、全局连接和随机连接 (总共 10 个连接) 的组合，如上图左侧动图所示。而 <strong>完全注意力</strong> 图 (右侧) 则是有全部 15 个连接 (注意: 总共有 6 个节点)。你可以简单地将完全注意力视为所有词元都是全局词元 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">{}^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>。</p><p><strong>完全注意力:</strong> 模型可以直接在单个层中将信息从一个词元传输到另一个词元，因为每个词元都会对每个其他词元进行查询，并且受到其他每个词元的关注。我们考虑一个与上图类似的例子，如果模型需要将 <em>‘going’</em> 与 <em>‘now’</em> 关联起来，它可以简单地在单层中执行此操作，因为它们两个是有直接连接的。</p><p><strong>块稀疏注意力:</strong> 如果模型需要在两个节点 (或词元) 之间共享信息，则对于某些词元，信息将必须经过路径中的各个其他节点; 因为不是所有节点都有直接连接的。<br><em>例如</em> ，假设模型需要将 <code>going</code> 与 <code>now</code> 关联起来，那么如果仅存在滑动注意力，则这两个词元之间的信息流由路径 <code>going -&gt; am -&gt; i -&gt; now</code> 来定义，也就是说它必须经过 2 个其他词元。因此，我们可能需要多个层来捕获序列的全部信息，而正常的注意力可以在单层中捕捉到这一点。在极端情况下，这可能意味着需要与输入词元一样多的层。然而，如果我们引入一些全局词元，信息可以通过以下路径传播 <code>going -&gt; i -&gt; now</code> ，这可以帮助缩短路径。如果我们再另外引入随机连接，它就可以通过 <code>going -&gt; am -&gt; now</code> 传播。借助随机连接和全局连接，信息可以非常快速地 (只需几层) 从一个词元传输到下一个词元。</p><p>如果我们有很多全局词元，那么我们可能不需要随机连接，因为信息可以通过多个短路径传播。这就是在使用 BigBird 的变体 (称为 ETC) 时设置 <code>num_random_tokens = 0</code> 的动机 (稍后部分将会详细介绍)。</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">{}^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> 在这些图中，我们假设注意力矩阵是对称的 <strong>即</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi mathvariant="bold">A</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{A} _{ij} = \mathbf{A}_ {ji}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.972218em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">A</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.972218em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">A</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 因为在图中如果某个词元 <strong>A</strong> 关注 <strong>B</strong>，那么 <strong>B</strong> 也会关注 <strong>A</strong>。从下一节所示的注意力矩阵图中可以看出，这个假设对于 BigBird 中的大多数词元都成立。</p><table><thead><tr><th>注意力类型</th><th>全局词元</th><th>滑动词元</th><th>随机词元</th></tr></thead><tbody><tr><td>原始完全注意力</td><td><code>n</code></td><td>0</td><td>0</td></tr><tr><td>块稀疏注意力</td><td>2 x <code>block_size</code></td><td>3 x <code>block_size</code></td><td><code>num_random_blocks</code> x <code>block_size</code></td></tr></tbody></table><p>原始完全注意力即 <code>BERT</code> 的注意力，而块稀疏注意力则是 <code>BigBird</code> 的注意力。想知道 <code>block_size</code> 是什么？请继续阅读下文。<em>现在，为简单起见，将其视为 1。</em></p><h2 id="bigbird-块稀疏注意力">BigBird 块稀疏注意力</h2><p>BigBird 块稀疏注意力是我们上文讨论的内容的高效实现。每个词元都关注某些 <strong>全局词元</strong> 、 <strong>滑动词元</strong> 和 <strong>随机词元</strong>，而不管其他 <strong>所有</strong> 词元。作者分别实现了每类查询注意力矩阵，并使用了一个很酷的技巧来加速 GPU 和 TPU 上的训练/推理。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/attn.png" alt="BigBird 块稀疏注意力"></p><p><em>注意: 在上图的顶部有 2 个额外的句子。正如你所注意到的，两个句子中的每个词元都只是交换了一个位置。这就是滑动注意力的实现方式。当 <code>q[i]</code> 与 <code>k[i,0:3]</code> 相乘时，我们会得到 <code>q[i]</code> 的滑动注意力分数 (其中<code>i</code> 是序列中元素的索引)。</em></p><p>你可以在 <a href="https://github.com/vasudevgupta7/transformers/blob/5f2d6a0c93ca2017961199aa04a344b9b779d454/src/transformers/models/big_bird/modeling_big_bird.py#L513">这儿</a> 找到 <code>block_sparse</code> 注意力的具体实现。现在看起来可能非常可怕😨😨，但这篇文章肯定会让你轻松理解它。</p><h3 id="全局注意力">全局注意力</h3><p>对于全局注意力而言，每个查询词元关注序列中的所有其他词元，并且被其他每个词元关注。我们假设 <code>Vasudev</code> (第一个词元) 和 <code>them</code> (最后一个词元) 是全局的 (如上图所示)。你可以看到这些词元直接连接到所有其他词元 (蓝色框)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 伪代码</span></span><br><span class="line"></span><br><span class="line">Q -&gt; Query martix (seq_length, head_dim)</span><br><span class="line">K -&gt; Key matrix (seq_length, head_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个和最后一个词元关注所有其他词元</span></span><br><span class="line">Q[<span class="number">0</span>] x [K[<span class="number">0</span>], K[<span class="number">1</span>], K[<span class="number">2</span>], ......, K[n-<span class="number">1</span>]]</span><br><span class="line">Q[n-<span class="number">1</span>] x [K[<span class="number">0</span>], K[<span class="number">1</span>], K[<span class="number">2</span>], ......, K[n-<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个和最后一个词元也被其他所有词元关注</span></span><br><span class="line">K[<span class="number">0</span>] x [Q[<span class="number">0</span>], Q[<span class="number">1</span>], Q[<span class="number">2</span>], ......, Q[n-<span class="number">1</span>]]</span><br><span class="line">K[n-<span class="number">1</span>] x [Q[<span class="number">0</span>], Q[<span class="number">1</span>], Q[<span class="number">2</span>], ......, Q[n-<span class="number">1</span>]]</span><br></pre></td></tr></table></figure><h3 id="滑动注意力">滑动注意力</h3><p>键词元序列被复制两次，其中一份每个词元向右移动一步，另一份每个词元向左移动一步。现在，如果我们将查询序列向量乘以这 3 个序列向量，我们将覆盖所有滑动词元。计算复杂度就是 <code>O(3n) = O(n)</code> 。参考上图，橙色框代表滑动注意力。你可以在图的顶部看到 3 个序列，其中 2 个序列各移动了一个词元 (1 个向左，1 个向右)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们想做的</span></span><br><span class="line">Q[i] x [K[i-<span class="number">1</span>], K[i], K[i+<span class="number">1</span>]] <span class="keyword">for</span> i = <span class="number">1</span>:-<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 高效的代码实现 (👇 乘法为点乘)</span></span><br><span class="line">[Q[<span class="number">0</span>], Q[<span class="number">1</span>], Q[<span class="number">2</span>], ......, Q[n-<span class="number">2</span>], Q[n-<span class="number">1</span>]] x [K[<span class="number">1</span>], K[<span class="number">2</span>], K[<span class="number">3</span>], ......, K[n-<span class="number">1</span>], K[<span class="number">0</span>]]</span><br><span class="line">[Q[<span class="number">0</span>], Q[<span class="number">1</span>], Q[<span class="number">2</span>], ......, Q[n-<span class="number">1</span>]] x [K[n-<span class="number">1</span>], K[<span class="number">0</span>], K[<span class="number">1</span>], ......, K[n-<span class="number">2</span>]]</span><br><span class="line">[Q[<span class="number">0</span>], Q[<span class="number">1</span>], Q[<span class="number">2</span>], ......, Q[n-<span class="number">1</span>]] x [K[<span class="number">0</span>], K[<span class="number">1</span>], K[<span class="number">2</span>], ......, K[n-<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个序列被乘 3 词， 即 `window_size = 3`。为示意，仅列出主要计算，省略了一些计算。</span></span><br></pre></td></tr></table></figure><h3 id="随机注意力">随机注意力</h3><p>随机注意力确保每个查询词元也会关注一些随机词元。对实现而言，这意味着模型随机选取一些词元并计算它们的注意力分数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># r1, r2, r 为随机索引; 注意 r1, r2, r 每行取值不同 👇</span></span><br><span class="line">Q[<span class="number">1</span>] x [Q[r1], Q[r2], ......, Q[r]]</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">Q[n-<span class="number">2</span>] x [Q[r1], Q[r2], ......, Q[r]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不用管第 0 个和第 n-1 个词元，因为它们已经是全局词元了。</span></span><br></pre></td></tr></table></figure><p><strong>注意:</strong> 当前的实现进一步将序列划分为块，并且每个符号都依块而定义而非依词元而定义。我们在下一节中会更详细地讨论这个问题。</p><h3 id="实现">实现</h3><p><strong>回顾:</strong> 在常规 BERT 注意力中，一系列词元，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">X = x_1, x_2, …., x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 通过线性层投影到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mtext>，</mtext><mi>K</mi><mtext>，</mtext><mi>V</mi></mrow><annotation encoding="application/x-tex">Q，K，V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">Q</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span></span></span></span>，并基于它们计算注意力分数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span></span></span></span>，公式为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z=Softmax(QK^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord mathdefault">Q</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。使用 BigBird 块稀疏注意力时，我们使用相同的算法，但仅针对一些选定的查询和键向量进行计算。</p><p>我们来看看 BigBird 块稀疏注意力是如何实现的。首先，我们用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mtext>、</mtext><mi>r</mi><mtext>、</mtext><mi>s</mi><mtext>、</mtext><mi>g</mi></mrow><annotation encoding="application/x-tex">b、r、s、g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">b</span><span class="mord cjk_fallback">、</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord cjk_fallback">、</span><span class="mord mathdefault">s</span><span class="mord cjk_fallback">、</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span> 分别代表 <code>block_size</code> 、<code>num_random_blocks</code> 、<code>num_sliding_blocks</code> 、<code>num_global_blocks</code> 。我们以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><mn>4</mn><mtext>，</mtext><mi>r</mi><mo>=</mo><mn>1</mn><mtext>，</mtext><mi>g</mi><mo>=</mo><mn>2</mn><mtext>，</mtext><mi>s</mi><mo>=</mo><mn>3</mn><mtext>，</mtext><mi>d</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">b=4，r=1，g=2，s=3，d=5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span></span></span> 为例来说明 BigBird 块稀疏注意力的机制部分，如下所示:</p><img src="https://huggingface.co/blog/assets/18_big_bird/intro.png" width=500 height=250><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub><mtext>、</mtext><msub><mi>q</mi><mn>2</mn></msub><mtext>、</mtext><msub><mi>q</mi><mrow><mn>3</mn><mo>:</mo><mi>n</mi><mo>−</mo><mn>2</mn></mrow></msub><mtext>、</mtext><msub><mi>q</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mtext>、</mtext><msub><mi>q</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{q} _{1}、{q}_ {2}、{q} _{3:n-2}、{q}_ {n-1}、{q}_{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的注意力分数分别计算如下:</p><hr><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{q}_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的注意力分数由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">a_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mn>1</mn></msub><mo>∗</mo><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a_1=Softmax(q_1 * K^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，即为第一块中的所有词元与序列中的所有其他词元之间的注意力分数。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/q1.png" alt="BigBird 块稀疏注意力"></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示第 1 块，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">g_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span> 块。我们仅在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span> (即所有键) 之间执行正常的注意力操作。</p><hr><p>为了计算第二块中词元的注意力分数，我们收集前三块、最后一块和第五块。然后我们可以计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>2</mn></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mn>2</mn></msub><mo>∗</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>5</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>7</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a_2 = Softmax(q_2 * concat(k_1, k_2, k_3, k_5, k_7))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/q2.png" alt="BigBird 块稀疏注意力"></p><p><em>这里，我用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mtext>，</mtext><mi>r</mi><mtext>，</mtext><mi>s</mi></mrow><annotation encoding="application/x-tex">g，r，s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault">s</span></span></span></span> 表示词元只是为了明确地表示它们的性质 (即是全局、随机还是滑动词元)，只用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span> 无法表示他们各自的性质。</em></p><hr><p>为了计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mn>3</mn><mo>:</mo><mi>n</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{q} _{3:n-2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 的注意力分数，我们先收集相应的全局、滑动、随机键向量，并基于它们正常计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mn>3</mn><mo>:</mo><mi>n</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{q}_ {3:n-2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span><span class="mrel mtight">:</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 上的注意力。请注意，正如前面滑动注意力部分所讨论的，滑动键是使用特殊的移位技巧来收集的。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/q_middle.png" alt="BigBird 块稀疏注意力"></p><hr><p>为了计算倒数第二块 (即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{q} _{n-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>) 中词元的注意力分数，我们收集第一块、最后三块和第三块的键向量。然后我们用公式 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∗</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>5</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>6</mn></msub><mo separator="true">,</mo><msub><mi>k</mi><mn>7</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">{a}_ {n-1} = Softmax({q}_{n-1} * concat(k_1, k_3, k_5, k_6, k_7))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> 进行计算。这和计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 非常相似。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/qlast_sec.png" alt="BigBird 块稀疏注意力"></p><hr><p>最后一块 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">q</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{q}_{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">q</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的注意力分数由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">a_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><msub><mi>q</mi><mi>n</mi></msub><mo>∗</mo><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a_n=Softmax(q_n * K^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，只不过是最后一块中的所有词元与序列中的所有其他词元之间的注意力分数。这与我们对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 所做的非常相似。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/qlast.png" alt="BigBird 块稀疏注意力"></p><hr><p>我们将上面的矩阵组合起来得到最终的注意力矩阵。该注意力矩阵可用于获取所有词元的表征。</p><p><img src="https://huggingface.co/blog/assets/18_big_bird/block-sparse-attn.gif" alt="BigBird 块稀疏注意力"></p><p><em>上图中 <code>蓝色 -&gt; 全局块</code> 、<code>红色 -&gt; 随机块</code> 、<code>橙色 -&gt; 滑动块</code> 。在前向传播过程中，我们不存储“白色”块，而是直接为每个单独的部分计算加权值矩阵 (即每个词元的表示)，如上所述。</em></p><p>现在，我们已经介绍了块稀疏注意力最难的部分，即它的实现。希望对你更好地理解实际代码有帮助。现在你可以深入研究代码了，在此过程中你可以将代码的每个部分与上面的某个部分联系起来以助于理解。</p><h2 id="时间和内存复杂度">时间和内存复杂度</h2><table><thead><tr><th>注意力类型</th><th>序列长度</th><th>时间和内存复杂度</th></tr></thead><tbody><tr><td>原始完全注意力</td><td>512</td><td><code>T</code></td></tr><tr><td></td><td>1024</td><td>4 x <code>T</code></td></tr><tr><td></td><td>4096</td><td>64 x <code>T</code></td></tr><tr><td>块稀疏注意力</td><td>1024</td><td>2 x <code>T</code></td></tr><tr><td></td><td>4096</td><td>8 x <code>T</code></td></tr></tbody></table><p><em>BERT 注意力和 BigBird 块稀疏注意力的时间和空间复杂度之比较。</em></p><details><summary> 展开以了解复杂度的计算过程。</summary><figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">BigBird 时间复杂度 = O(w x n + r x n + g x n)</span><br><span class="line">BERT 时间复杂度 = O(n^2)</span><br><span class="line"></span><br><span class="line">假设:</span><br><span class="line"><span class="code">    w = 3 x 64</span></span><br><span class="line"><span class="code">    r = 3 x 64</span></span><br><span class="line"><span class="code">    g = 2 x 64</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">当序列长度为 512 时</span><br><span class="line">=&gt; <span class="strong">**BERT 时间复杂度 = 512^2**</span></span><br><span class="line"></span><br><span class="line">当序列长度为 1024 时</span><br><span class="line">=&gt; BERT 时间复杂度 = (2 x 512)^2</span><br><span class="line">=&gt; <span class="strong">**BERT 时间复杂度 = 4 x 512^2**</span></span><br><span class="line"></span><br><span class="line">=&gt; BigBird 时间复杂度 = (8 x 64) x (2 x 512)</span><br><span class="line">=&gt; <span class="strong">**BigBird 时间复杂度 = 2 x 512^2**</span></span><br><span class="line"></span><br><span class="line">当序列长度为 4096 时</span><br><span class="line">=&gt; BERT 时间复杂度 = (8 x 512)^2</span><br><span class="line">=&gt; <span class="strong">**BERT 时间复杂度 = 64 x 512^2**</span></span><br><span class="line"></span><br><span class="line">=&gt; BigBird 时间复杂度 = (8 x 64) x (8 x 512)</span><br><span class="line">=&gt; BigBird 时间复杂度 = 8 x (512 x 512)</span><br><span class="line">=&gt; <span class="strong">**BigBird 时间复杂度 = 8 x 512^2**</span></span><br></pre></td></tr></table></figure></details><h2 id="itc-与-etc">ITC 与 ETC</h2><p>BigBird 模型可以使用 2 种不同的策略进行训练: <strong>ITC</strong> 和 <strong>ETC</strong>。 ITC (internal transformer construction，内部 transformer 构建) 就是我们上面讨论的。在 ETC (extended transformer construction，扩展 transformer 构建) 中，会有更多的全局词元，以便它们关注所有词元或者被所有词元关注。</p><p>ITC 需要的计算量较小，因为很少有词元是全局的，同时模型可以捕获足够的全局信息 (也可以借助随机注意力)。而 ETC 对于需要大量全局词元的任务非常有帮助，例如对 <strong>问答</strong> 类任务而言，整个问题应该被所有上下文关注，以便能够将上下文正确地与问题相关联。</p><p><em><strong>注意:</strong> BigBird 论文显示，在很多 ETC 实验中，随机块的数量设置为 0。考虑到我们上文图解部分的讨论，这是合理的。</em></p><p>下表总结了 ITC 和 ETC:</p><table><thead><tr><th></th><th>ITC</th><th>ETC</th></tr></thead><tbody><tr><td>全局注意力的注意力矩阵</td><td>\( A = \begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \end{bmatrix} \)</td><td>\( B = \begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \end{bmatrix} \)</td></tr><tr><td>全局词元</td><td>2 x <code>block_size</code></td><td><code>extra_tokens</code> + 2 x <code>block_size</code></td></tr><tr><td>随机词元</td><td><code>num_random_blocks</code> x <code>block_size</code></td><td><code>num_random_blocks</code> x <code>block_size</code></td></tr><tr><td>滑动词元</td><td>3 x <code>block_size</code></td><td>3 x <code>block_size</code></td></tr></tbody></table><h2 id="在-🤗transformers-中使用-bigbird">在  🤗Transformers 中使用 BigBird</h2><p>你可以像使用任何其他 🤗 模型一样使用 <code>BigBirdModel</code> 。我们看一下代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BigBirdModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从预训练 checkpoint 中加载 bigbird 模型</span></span><br><span class="line">model = BigBirdModel.from_pretrained(<span class="string">&quot;google/bigbird-roberta-base&quot;</span>)</span><br><span class="line"><span class="comment"># 使用默认配置初始化模型，如 attention_type = &quot;block_sparse&quot;，num_random_blocks = 3，block_size = 64</span></span><br><span class="line"><span class="comment"># 你也可以按照自己的需要改变这些参数。这 3 个参数只改变每个查询词元关注的词元数。</span></span><br><span class="line">model = BigBirdModel.from_pretrained(<span class="string">&quot;google/bigbird-roberta-base&quot;</span>, num_random_blocks=<span class="number">2</span>, block_size=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过把 attention_type 设成 `original_full`，BigBird 就会用复杂度为 n^2 的完全注意力。此时，BigBird 与 BERT 相似度为 99.9%。</span></span><br><span class="line">model = BigBirdModel.from_pretrained(<span class="string">&quot;google/bigbird-roberta-base&quot;</span>, attention_type=<span class="string">&quot;original_full&quot;</span>)</span><br></pre></td></tr></table></figure><p>截至现在， <strong>🤗 Hub</strong> 中总共有 <strong>3 个 BigBird checkpoint</strong>: <a href="https://huggingface.co/google/bigbird-roberta-base"><code>bigbird-roberta-base</code></a>，<a href="https://huggingface.co/google/bigbird-roberta-large"><code>bigbird-roberta-large</code></a> 以及 <a href="https://huggingface.co/google/bigbird-base-trivia-itc"><code>bigbird-base-trivia-itc</code></a>。前两个检查点是使用 <code>masked_lm 损失</code> 预训练 <code>BigBirdForPretraining</code> 而得; 而最后一个是在 <code>trivia-qa</code> 数据集上微调 <code>BigBirdForQuestionAnswering</code> 而得。</p><p>让我们看一下如果用你自己喜欢的 PyTorch 训练器，最少需要多少代码就可以使用 🤗 的 BigBird 模型来微调你自己的任务。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以问答任务为例</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BigBirdForQuestionAnswering, BigBirdTokenizer</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们用预训练权重初始化 bigbird 模型，并随机初始化其头分类器</span></span><br><span class="line">model = BigBirdForQuestionAnswering.from_pretrained(<span class="string">&quot;google/bigbird-roberta-base&quot;</span>, block_size=<span class="number">64</span>, num_random_blocks=<span class="number">3</span>)</span><br><span class="line">tokenizer = BigBirdTokenizer.from_pretrained(<span class="string">&quot;google/bigbird-roberta-base&quot;</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">dataset = <span class="string">&quot;torch.utils.data.DataLoader object&quot;</span></span><br><span class="line">optimizer = <span class="string">&quot;torch.optim object&quot;</span></span><br><span class="line">epochs = ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最简训练循环</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> dataset:</span><br><span class="line">        model.train()</span><br><span class="line">        batch = &#123;k: batch[k].to(device) <span class="keyword">for</span> k <span class="keyword">in</span> batch&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向</span></span><br><span class="line">        output = model(**batch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 后向</span></span><br><span class="line">        output[<span class="string">&quot;loss&quot;</span>].backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将最终权重存至本地目录</span></span><br><span class="line">model.save_pretrained(<span class="string">&quot;&lt;YOUR-WEIGHTS-DIR&gt;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将权重推到 🤗 Hub 中</span></span><br><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> ModelHubMixin</span><br><span class="line">ModelHubMixin.push_to_hub(<span class="string">&quot;&lt;YOUR-WEIGHTS-DIR&gt;&quot;</span>, model_id=<span class="string">&quot;&lt;YOUR-FINETUNED-ID&gt;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用微调后的模型，以用于推理</span></span><br><span class="line">question = [<span class="string">&quot;How are you doing?&quot;</span>, <span class="string">&quot;How is life going?&quot;</span>]</span><br><span class="line">context = [<span class="string">&quot;&lt;some big context having ans-1&gt;&quot;</span>, <span class="string">&quot;&lt;some big context having ans-2&gt;&quot;</span>]</span><br><span class="line">batch = tokenizer(question, context, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">batch = &#123;k: batch[k].to(device) <span class="keyword">for</span> k <span class="keyword">in</span> batch&#125;</span><br><span class="line"></span><br><span class="line">model = BigBirdForQuestionAnswering.from_pretrained(<span class="string">&quot;&lt;YOUR-FINETUNED-ID&gt;&quot;</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    start_logits, end_logits = model(**batch).to_tuple()</span><br><span class="line">    <span class="comment"># 这里，你可以使用自己的策略对 start_logits，end_logits 进行解码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意:</span></span><br><span class="line"><span class="comment"># 该代码段仅用于展示即使你想用自己的 PyTorch 训练器微调 BigBrid，这也是相当容易的。</span></span><br><span class="line"><span class="comment"># 我会建议使用 🤗 Trainer，它更简单，功能也更多。</span></span><br></pre></td></tr></table></figure><p>使用 BigBird 时，需要记住以下几点:</p><ul><li>序列长度必须是块大小的倍数，即 <code>seqlen % block_size = 0</code> 。你不必担心，因为如果 batch 的序列长度不是 <code>block_size</code> 的倍数，🤗 transformers 会自动填充至最近的整数倍。</li><li>目前，Hugging Face 的实现 <strong>尚不支持 ETC</strong>，因此只有第一个和最后一个块是全局的。</li><li>当前实现不支持 <code>num_random_blocks = 0</code> 。</li><li>论文作者建议当序列长度 &lt; 1024 时设置 <code>attention_type = &quot;original_full&quot;</code> 。</li><li>必须满足: <code>seq_length &gt; global_token + random_tokens + moving_tokens + buffer_tokens</code> ，其中 <code>global_tokens = 2 x block_size</code> 、 <code>sliding_tokens = 3 x block_size</code> 、 <code>random_tokens = num_random_blocks x block_size</code> 且 <code>buffer_tokens = num_random_blocks x block_size</code> 。如果你不能满足这一点，🤗 transformers 会自动将 <code>attention_type</code> 切换为 <code>original_full</code> 并告警。</li><li>当使用 BigBird 作为解码器 (或使用 <code>BigBirdForCasualLM</code> ) 时， <code>attention_type</code> 应该是 <code>original_full</code> 。但你不用担心，🤗 transformers 会自动将 <code>attention_type</code> 切换为 <code>original_full</code> ，以防你忘记这样做。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;深入理解 BigBird 的块稀疏注意力&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/blog/blob/main/zh/big-bird.md&quot;&gt;文档来自&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="相机驱动开发" scheme="http://outbreak-sen.github.io/categories/%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="mindspore实习" scheme="http://outbreak-sen.github.io/tags/mindspore%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Mindspore实习-AKG SIG算子addlayernorm编辑和合并</title>
    <link href="http://outbreak-sen.github.io/2025/02/10/Mindspore%E5%AE%9E%E4%B9%A0-AKG%20SIG%E7%AE%97%E5%AD%90addlayernorm%E7%BC%96%E8%BE%91%E5%92%8C%E5%90%88%E5%B9%B6/"/>
    <id>http://outbreak-sen.github.io/2025/02/10/Mindspore%E5%AE%9E%E4%B9%A0-AKG%20SIG%E7%AE%97%E5%AD%90addlayernorm%E7%BC%96%E8%BE%91%E5%92%8C%E5%90%88%E5%B9%B6/</id>
    <published>2025-02-10T04:53:11.000Z</published>
    <updated>2025-03-19T09:14:51.132Z</updated>
    
    <content type="html"><![CDATA[<h1>Mindspore实习-AKG SIG算子addlayernorm编辑和合并</h1><h2 id="什么是算子">什么是算子</h2><p>计算图和算子在计算本质上是一致的。<strong>算子是打包后的计算图，计算图是拆包后的算子</strong></p><p>比如sigmod复合算子可以看作一个计算图，由基础算子Exp，Add，Reciprocal等基础算子组成，用小规模的“基本算子”集合就可以表达任意现有计算图。</p><p>计算图可以完全由基础算子组成，但是还是得定义复合算子，比如sigmod这种，因为对于基本算子计算图来说，相邻算子之间只能通过全局内存（或显存）进行数据传递。而对于复合算子来说，相邻的基本计算之间则可以通过局部内存或者寄存器进行数据传递。除了性能之外，在一些场景下，通过算子融合也能有效减少对全局内存的的实际占用。</p><h1>mindspore的算子融合方案是什么</h1><p>在TVM、XLA等自动算子编译技术出现之前，AI框架主流采用手工融合的方式解决如上问题。主要思路是：</p><ul><li><p>手工融合: 1）识别常见的热点算子组合子图，比如： Add(Mul(x, y))。然后针对该算子子图手工实现对应融合算子； 2）将融合算子注册到AI框架，并在AI框架中增加对应的优化pass，将匹配的算子子图替换为融合算子节点。 这种方式的缺点是显而易见的。因为它只能针对若干热点场景进行融合，所以是无法做到通用和泛化的。</p></li><li><p>XLA：XLA最早基于TensorFlow开发。不过它采用了与TensorFlow不同的计算图IR表示。所以在TensorFlow中，需要将TensorFlow的计算图IR首先转换为XLA的计算图IR（HLO）。然后XLA基于HLO进行融合优化等，最后通过LLVM等后端编译生成相应融合算子。由于采用独立的IR，XLA具有较好的可移植性，目前在PyTorch、JAX等非TensorFlow框架中也有不错的表现。</p></li><li><p>TVM：TVM主要用于推理场景。在架构上，主要包括relay和tir两层。其通过relay导入推理模型，然后进行融合优化，最后通过tir生成融合算子。TVM在算子编译方面采用compute和schedule分离的技术，并且不同算子compute所需要的schedule通常是不同的。为了更好支持不同融合算子场景，TVM支持对算子进行自动tuning，来生成较优的切分参数甚至schedule。由于tuning空间较大，目前tuning时间相对还是比较长的。</p></li></ul><p>基于以上问题背景，并结合MindSpore自身需求，我们提出图算融合解决方案。其主要思路是：</p><ul><li>图算融合解决方案: 1）3.9以通用的pattern识别计算图中的融合场景，并生成融合算子子图；2）将生成的融合算子子图通过自动算子编译技术（AKG）生成对应的融合算子。</li></ul><h2 id="什么是图算融合编译技术">什么是图算融合编译技术</h2><p>我们如果需要把模型部署到CPU甚至手机上去，此时需要其他硬件及其架构的支持。开发者们往往会根据实际情况选择各种各样的深度学习顶层框架训练模型，例如昇思MindSpore等，再把训练好的模型部署到各种各样的设备后端包括GPU、CPU、FPGA、昇腾AI处理器及其它新型的AI加速器上。</p><p>考虑到不同硬件设备的特性千差万别、现有算子库中算子包含范围不同、新型加速器算子库支持不足、非常规的神经网络中存在不常见的layer等等情况，开发者要完成手写算子并保证性能，学习成本和时间成本都变得很高，所以图算融合编译技术的出现变得非常有必要。</p><p><a href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/graph_kernel_fusion.html">这里有一个介绍</a></p><h2 id="什么是自动算子编译技术akg">什么是自动算子编译技术AKG</h2><p>AKG是Auto Kernel Generator的简称，&quot;SIG&quot;是一个常见的缩写，全称为 “Special Interest Group”，中文直译为“特殊兴趣小组”或者”特殊利益集团“。</p><p>AKG(Auto Kernel Generator)对深度神经网络中的算子进行优化，并提供特定模式下的算子自动融合功能。AKG与MindSpore的图算融合功能协同工作，可提升在不同硬件后端上运行网络的性能。AKG基于polyhedral技术，多面体。</p><h1>任务-addlayernorm</h1><p>【任务背景】<br>AKG-MLIR 已经在 MindSpore Dialect 内提供了基础算子的定义和对应的Lower流程。但是，当前MindSpore  Dialect算子集是基于传统的Bert/Transformer类网络的需求梳理和统计的。随着网络的变化，我们有更多算子的需求希望添加在  MindSpore Dialect 之中。</p><p>【需求描述】</p><ol><li>在MindSporeOps.td中添加对应算子的实现</li><li>打通算子的Lower流程(直接lower到Linalg或者lower到TOSA)，相关Dialect的代码（如MindSporeToTosa.cpp或者MindSporeToLinalg.cpp）</li><li>提供对应的测试用例（算子的info文件和对应的op_dsl）</li></ol><p>【参考资料】</p><ol><li>样例代码仓:<a href="https://gitee.com/mindspore/akg/pulls/989">https://gitee.com/mindspore/akg/pulls/989</a></li><li>代码添加教程wiki:<a href="https://gitee.com/monkeykingd/akg/wikis/AKG-MLIR%E7%AE%97%E5%AD%90%E6%B7%BB%E5%8A%A0%E7%94%A8%E4%BE%8B">https://gitee.com/monkeykingd/akg/wikis/AKG-MLIR算子添加用例</a></li><li>测试用例教程wiki:<a href="https://gitee.com/monkeykingd/akg/wikis/AKG-MLIR%E5%8D%95%E7%AE%97%E5%AD%90%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%E6%9E%84%E5%BB%BA">https://gitee.com/monkeykingd/akg/wikis/AKG-MLIR单算子测试用例构建</a></li></ol><p>【验收标准】<br>根据参考资料中的参考测试文件(<a href="http://demo.info">demo.info</a>)构建测试用例，使用python  ${path_to_py_benchmark}/py_benchmark.py -e cpu -f <a href="http://mul.info">mul.info</a> --dump_ir  1运行命令，和numpy模拟的算子结果一致</p><p>【任务技术要求】<br>Python, MindSpore &gt; 2.3</p><p>我要做什么？<br>把mindspore的AKG安装起来然后根据参考资料里的，利用基础算子写addlayernorm这个算子的实现然后添加lower流程然后再写一个测试示例，把整个代码push上去，让导师通过。</p><h1>AKG安装</h1><p>官方文档里写了从MindSpore侧构建运行AKG代码但是详细细节写了个寂寞，然后全是独立构建方法</p><p><a href="https://gitee.com/mindspore/akg#%E7%8B%AC%E7%AB%8B%E6%9E%84%E5%BB%BA">AKG安装过程</a></p><h2 id="从mindspore的whl安装-失败-但是后面还是这么做了">从mindspore的whl安装，失败，但是后面还是这么做了</h2><p>独立构建方法网上有，我偏不用，看看这个从MindSpore侧怎么安装，理论上AKG是mindspore的子仓库应该是自动安装了。</p><ul><li><s>首先我创建一个一个python3.9 conda环境然后安装Mindspore2.3安装方法是下载whl包</s>，这个没有出现问题日</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mindspore-2.3.1-cp39-cp39-linux_x86_64.whl</span><br></pre></td></tr></table></figure><p>不过如果是实习的话，需要推自己的改动，那我岂不是最好git下载然后source安装mindspore，算了。<strong>后来发现确实是这样，因为这样找不到tests文件夹，就无法运行官方文档里面的设置环境变量和运行测试用例，想了一下还是进行源码安装，因为又可以看源码又可以安装环境</strong>但是后来</p><h2 id="从mindspore的源码安装">从mindspore的源码安装</h2><p>我选择安装的是CPU的ubuntu x86架构的源码，参考mindspore的仓库主页<a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md">CPU安装源码</a></p><p>首先安装以下依赖软件，我的麻</p><table><thead><tr><th>软件名称</th><th>版本</th><th>作用</th></tr></thead><tbody><tr><td>Ubuntu</td><td>18.04</td><td>编译和运行MindSpore的操作系统</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85python">Python</a></td><td>3.9-3.11</td><td>MindSpore的使用依赖Python环境</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85wheel-setuptools-pyyaml%E5%92%8Cnumpy">wheel</a></td><td>0.32.0及以上</td><td>MindSpore使用的Python打包工具</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85wheel-setuptools-pyyaml%E5%92%8Cnumpy">setuptools</a></td><td>44.0及以上</td><td>MindSpore使用的Python包管理工具</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85wheel-setuptools-pyyaml%E5%92%8Cnumpy">PyYAML</a></td><td>6.0-6.0.2</td><td>MindSpore里的算子编译功能依赖PyYAML模块</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85wheel-setuptools-pyyaml%E5%92%8Cnumpy">Numpy</a></td><td>1.19.3-1.26.4</td><td>MindSpore里的Numpy相关功能依赖Numpy模块</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85gcc-git-tclsh-patch%E5%92%8Cnuma">GCC</a></td><td>7.3.0到9.4.0之间</td><td>用于编译MindSpore的C++编译器</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85gcc-git-tclsh-patch%E5%92%8Cnuma">git</a></td><td>-</td><td>MindSpore使用的源代码管理工具</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85cmake">CMake</a></td><td>3.22.2及以上</td><td>编译构建MindSpore的工具</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85gcc-git-tclsh-patch%E5%92%8Cnuma">tclsh</a></td><td>-</td><td>MindSpore sqlite编译依赖</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85gcc-git-tclsh-patch%E5%92%8Cnuma">patch</a></td><td>2.5及以上</td><td>MindSpore使用的源代码补丁工具</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85gcc-git-tclsh-patch%E5%92%8Cnuma">NUMA</a></td><td>2.0.11及以上</td><td>MindSpore使用的非一致性内存访问库</td></tr><tr><td><a href="https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md#%E5%AE%89%E8%A3%85llvm-%E5%8F%AF%E9%80%89">LLVM</a></td><td>12.0.1</td><td>MindSpore使用的编译器框架（可选，图算融合以及稀疏计算需要）</td></tr></tbody></table><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以上依赖的安装过程</span></span><br><span class="line">conda create -n mindspore39AKGSource python=3.9</span><br><span class="line">pip install wheel</span><br><span class="line">pip install -U setuptools</span><br><span class="line">pip install pyyaml</span><br><span class="line">pip install <span class="string">&quot;numpy&gt;=1.19.3,&lt;=1.26.4&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install gcc-7 git tcl patch libnuma-dev -y <span class="comment"># 发现都安装了</span></span><br><span class="line"><span class="comment"># cmake已经安装了，但是发现了一个apt安装cmake的方法如下</span></span><br><span class="line">wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2&gt;/dev/null | <span class="built_in">sudo</span> apt-key add -</span><br><span class="line"><span class="built_in">sudo</span> apt-add-repository <span class="string">&quot;deb https://apt.kitware.com/ubuntu/ <span class="subst">$(lsb_release -cs)</span> main&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install cmake -y</span><br><span class="line"><span class="comment"># # 以上依赖中的LLVM的安装过程，安装LLVM是可选的，但是我不知道哪里可选</span></span><br><span class="line">wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | <span class="built_in">sudo</span> apt-key add -</span><br><span class="line"><span class="built_in">sudo</span> add-apt-repository <span class="string">&quot;deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-12 main&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install llvm-12-dev -y</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译安装mindspore 2.3.1 </span></span><br><span class="line">git <span class="built_in">clone</span> https://gitee.com/mindspore/mindspore.git</span><br><span class="line">git checkout  v2.3.1 <span class="comment">#要更换版本，但是后来想了一下好像也没必要</span></span><br><span class="line">bash build.sh -e cpu -j4 -S on <span class="comment"># 默认从github下载依赖源码，当-S选项设置为on时，从对应的gitee镜像下载。这一步只是编译成whl，要安装还得install</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#报错了configure: WARNING: *** Could not find Flex on your system</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install flex </span><br><span class="line"><span class="built_in">sudo</span> apt-get install bison </span><br><span class="line"><span class="comment">#又报错了PYTHON_INCLUDE_DIRS = /usr/include/python3.10 PYTHON_LIBRARIES = /usr/lib/x86_64-linux-gnu/libpython3.10.so MS LIBS CACHE PATH:  /home/outbreak/mindspore/AKG/mindspore/build/mindspore/.mslib</span></span><br><span class="line"><span class="comment">#CMake Error at cmake/gencode.cmake:13 (message):Generate operator python/c++ definitions FAILED.</span></span><br><span class="line"><span class="comment"># 然后这个报错我解决不了，艘不到也看不懂</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是我突然想到，这一步不就是生成whl的吗，所以我干脆只下载源码但是用网上编译好的whl算了，然后结合同一个版本的mindspore仓库进行编辑测试。后经过了测试，发现这样并不行，因为运行akg/test文件的时候并没有找到test_add.py，报错ERROR test_abs.py - RuntimeError: Cannot find the files.</span></span><br><span class="line"><span class="comment">#我觉得是我的whl安装过程并没有链接这个源码中的AKG的文件夹，我的猜测是这样的。所以最终怎么安装请看下面的最终解决方案</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果bash build.sh -e cpu -j4 -S on成功的话请继续</span></span><br><span class="line">pip install output/mindspore-*.whl -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"><span class="comment"># 这一步在联网状态下，安装whl包时会自动下载mindspore安装包的依赖项（依赖项详情参见setup.py中的required_package），其余情况需自行安装。运行模型时，需要根据ModelZoo中不同模型指定的requirements.txt安装额外依赖，常见依赖可以参考requirements.txt。</span></span><br><span class="line"><span class="comment"># 验证安装是否成功</span></span><br><span class="line">python -c <span class="string">&quot;import mindspore;mindspore.set_device(device_target=&#x27;CPU&#x27;);mindspore.run_check()&quot;</span></span><br><span class="line"><span class="comment"># 这一步应该会输出MindSpore version: 版本号</span></span><br><span class="line">The result of multiplication calculation is correct, MindSpore has been installed on platform [CPU] successfully!</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="最终的解决方案mindspore的whl安装-akg源码安装">最终的解决方案mindspore的whl安装+AKG源码安装</h2><p>ok fine ,最后终于成功了，整理一下思路，就是说从官网只下载AKG的源码，当然mindspore的仓库里有AKG这个子仓库，然后我用官方编译好的whl进行安装，安装版本为2.3.1，这个安装没有出现问题</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">conda create -n mindspore39NLP python=3.9</span><br><span class="line">pip install mindspore-2.3.1-cp39-cp39-linux_x86_64.whl <span class="comment">#这就安装完成了</span></span><br><span class="line"><span class="comment"># 以下为AKG的独立构建方式，针对CPU</span></span><br><span class="line">git <span class="built_in">clone</span> https://gitee.com/mindspore/akg.git </span><br><span class="line"><span class="built_in">cd</span> akg</span><br><span class="line">bash build.sh -e cpu -j8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中途报错ModuleNotFoundError: No module named &#x27;decorator&#x27;</span></span><br><span class="line">pip install decorator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中途报错OSError: /home/outbreak/anaconda3/envs/mindspore39NLP/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.30&#x27; not found (required by /home/outbreak/mindspore/AKG/akg/build/libakg.so)</span></span><br><span class="line">strings /home/outbreak/anaconda3/envs/mindspore39NLP/lib/libstdc++.so.6  | grep GLIBC <span class="comment">#这个是查询当前的conda环境里有哪些stdc++，其中发现只有GLIBCXX_3.4.29，并没有GLIBCXX_3.4.30</span></span><br><span class="line">strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX <span class="comment">#这个是查询本地环境中有哪些stdc++，conda环境里某些包需要某个版本的c++，一般会从本地环境中复制进conda环境中，如果没有则报错，解决方法是链接进conda环境里</span></span><br><span class="line"><span class="built_in">ln</span> -sf /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /home/outbreak/anaconda3/envs/mindspore39NLP/bin/../lib/libstdc++.so.6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> tests</span><br><span class="line"><span class="comment"># 设置环境变量，这里有很大的作用，source的位置一定要对，要不然找不到测试文件，卡bug</span></span><br><span class="line"><span class="built_in">source</span> ./test_env.sh cpu</span><br><span class="line"><span class="comment"># AKG测试</span></span><br><span class="line"><span class="built_in">cd</span> tests/st</span><br><span class="line">python run.py -e cpu -o add -l level0  <span class="comment"># 执行CPU Add算子的level0用例，包含了下面的test_abs</span></span><br><span class="line"><span class="built_in">cd</span> tests/st/ops/</span><br><span class="line">pytest -s test_abs.py -m <span class="string">&quot;level0 and platform_x86_cpu&quot;</span> <span class="comment"># 运行CPU level0测试用例</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1>AddLayerNorm算子的定义</h1><p>首先addlayernorm的公式是怎样的，看一下pytorch没找到，但是找到了<a href="https://www.hiascend.com/document/detail/zh/canncommercial/80RC1/apiref/appdevgapi/context/aclnnAddLayerNorm.md">升腾的一个方案</a>。文献没有找到，但是在 Transformer 架构中，残差连接（Add）与层归一化（LayerNorm）常被结合使用，是将输入的X1和X2进行逐元素相加，然后对结果进行layernorm。LayerNorm 最初由 Jimmy Lei Ba 等人在 2016 年的论文 <strong>《Layer Normalization》</strong></p><p>![image-20250210193652012](./Mindspore实习-AKG SIG算子addlayernorm编辑和合并/2.png)</p><h1>任务1在MindSporeOps.td中添加对应算子的实现</h1><p>开头已经了解了mindspore AKG是什么了，里面提供了基本算子的定义和Lower流程，但现在需要添加新的复合算子AddLayerNorm到MindSpore Dialect中。</p><p>这里需要会LLVM编译器的相关操作，所谓td文件就是其中的编辑文件</p><ul><li><strong>TableGen</strong>是LLVM生态中用于生成代码的声明式语言，通过<code>.td</code>文件定义数据模型（如操作、指令、寄存器）。</li><li><strong>在MLIR中</strong>：td文件用于定义Dialect中的算子（Op）、类型（Type）、属性（Attribute）等，生成C++代码框架。</li></ul><p>如果要写一个addLaynorm，可能如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">//有三个输入，一个输出，所以在这里定义了四个MindSpore_Tensor类型的tensor，对应五个输入X1、X2、gamma、beta和一个输出y。但是升腾的方案写的很复杂，还包括了是否要输出中间的相加结果</span><br><span class="line">// arguments：输入张量和属性（如epsilon）。</span><br><span class="line">// results：输出张量。</span><br><span class="line">// assemblyFormat：定义文本格式的语法，用于调试和序列化。</span><br><span class="line">// MindSporeOps.td中</span><br><span class="line">//===----------------------------------------------------------------------===//</span><br><span class="line">// MindSpore Operator: addlayernorm</span><br><span class="line">//===----------------------------------------------------------------------===//</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MindSpore_AddLayerNormOp</span> : MindSpore_Op&lt;<span class="string">&quot;addlayernorm&quot;</span>, [Pure]&gt; &#123;</span><br><span class="line">  let summary = <span class="string">&quot;Add followed by Layer Normalization&quot;</span>;</span><br><span class="line">  let arguments = (ins</span><br><span class="line">    MindSpore_Tensor:$input_a,</span><br><span class="line">    MindSpore_Tensor:$input_b,</span><br><span class="line">    MindSpore_Tensor:$input_gamma,</span><br><span class="line">    MindSpore_Tensor:$input_beta               </span><br><span class="line">  );</span><br><span class="line">  let results = (outs </span><br><span class="line">    MindSpore_Tensor:$output</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ins后接输入参数，out后接输出参数。在编译后会自动生成get方法来获取输入输出，并将蛇形名称转换为驼峰式命名法。在<code>akg-mlir/build/include/akg/Dialect/MindSpore/IR/MindSporeOps.cpp.inc</code>可以找到编译后的get方法</p><p>比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">::mlir::TypedValue&lt;::mlir::TensorType&gt; AccMulOp::getInputA() &#123;</span><br><span class="line">  return *getODSOperands(0).begin();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">::mlir::TypedValue&lt;::mlir::TensorType&gt; AccMulOp::getInputB() &#123;</span><br><span class="line">  return *getODSOperands(1).begin();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">::mlir::TypedValue&lt;::mlir::TensorType&gt; AccMulOp::getInputGamma() &#123;</span><br><span class="line">  return *getODSOperands(2).begin();</span><br><span class="line">&#125;</span><br><span class="line">::mlir::TypedValue&lt;::mlir::TensorType&gt; AccMulOp::getInputBeta() &#123;</span><br><span class="line">  return *getODSOperands(2).begin();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1>任务2打通算子的Lower流程</h1><h2 id="lower流程讲解">Lower流程讲解</h2><p>直接lower到Linalg或者lower到TOSA，相关Dialect的代码（如MindSporeToTosa.cpp或者MindSporeToLinalg.cpp）</p><p>在MLIR（Multi-Level Intermediate Representation）生态中，<strong>Dialect</strong>、<strong>Linalg</strong> 和 <strong>TOSA</strong> 是不同层次的中间表示（IR），用于描述和优化计算任务。</p><ul><li><p>Dialect：是 MLIR 中的用于定义特定领域或抽象层次的中间表示。每个 Dialect 包含一组操作（Op）、类型（Type）和属性（Attribute），用于描述特定领域的计算任务。</p><p>例如：</p><ul><li><strong>MindSpore Dialect</strong>：描述 MindSpore 框架中的算子（如 <code>Add</code>、<code>LayerNorm</code>）。</li><li><strong>TOSA Dialect</strong>：描述面向硬件后端的张量运算操作。</li><li><strong>Linalg Dialect</strong>：描述线性代数操作（如矩阵乘法、卷积）。</li></ul></li><li><p>Linalg：是 MLIR 中的一个 Dialect，专注于<strong>线性代数操作</strong>（如矩阵乘法、卷积、点积等）。适合循环优化和高层次中间表示。</p></li><li><p>TOSA：全称<code>Tensor Operator Set Architecture</code>。里面都是张量运算，也就是比Linalg高了一个等级，它定义了一组硬件友好的操作，适合在 AI 加速器（如 NPU、GPU）上执行。适合面向硬件后端的标准化操作。在<code>Tosa</code>中已经定义有矩阵逐元素乘的实现，如下</p><ul><li><a href="https://gitee.com/link?target=https%3A%2F%2Fmlir.llvm.org%2Fdocs%2FDialects%2FTOSA%2F%23tosamul-mlirtosamulop"><code>tosa.mul</code> (mlir::tosa::MulOp)</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fmlir.llvm.org%2Fdocs%2FDialects%2FTOSA%2F%23tosaadd-mlirtosaaddop"><code>tosa.add</code> (mlir::tosa::AddOp)</a></li><li><a href="https://gitee.com/link?target=https%3A%2F%2Fmlir.llvm.org%2Fdocs%2FDialects%2FTOSA%2F%23tosapow-mlirtosapowop"><code>tosa.pow</code> (mlir::tosa::PowOp)</a></li></ul></li><li><p>Lower流程（Lowering）：是将高层抽象的 Dialect 逐步转换为低层抽象的 Dialect 的过程。（如从MindSpore Dialect到Linalg/TOSA）。</p><ul><li><strong>MindSpore Dialect 到 Linalg</strong>：将 MindSpore 的算子（如 <code>AddLayerNorm</code>）转换为 Linalg 的线性代数操作。将 <code>AddLayerNorm</code> 分解为 <code>linalg.add</code>、<code>linalg.mul</code> 等操作。</li><li><strong>MindSpore Dialect 到 TOSA</strong>：将 MindSpore 的算子转换为 TOSA 的标准化操作。将 <code>AddLayerNorm</code> 分解为 <code>tosa.add</code>、<code>tosa.mul</code> 等操作。</li></ul><p><strong>MindSpore的Lower过程这里有两条路，可以从MindSpore转到Tosa再转到Linalg，也可以直接从MindSpore转到Linalg</strong></p></li></ul><h2 id="编写addlayernorm的lower过程">编写AddLayerNorm的Lower过程</h2><p>参考的算子编写示例中讲解，测试的时候给算子输入的是JSON格式的文件，然后呢需要首先将JSON的格式转化为MindSpore Dialect 。</p><p>然后有两个路，一个是MindSpore Dialect 转化为Tosa  Dialect 再转化为Linalg Dialect ，另一个是MindSpore Dialect 直接转化为Linalg  Dialect。</p><h3 id="jsontomindspore">JSONtoMindSpore</h3><p>在<code>akg-mlir/compiler/lib/Target/MindsporeDialect/TranslateToMindsporeDialect.cpp</code>下的<code>void MindBuilder::initMindOpFactory()</code>中，case by case的注册刚写好的AddLayerNormOp</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">this-&gt;mindOpFactory[&quot;addlayernorm&quot;] = &amp;MindBuilder::convertTernaryOp&lt;mindspore::AddLayerNormOp&gt;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="mindsporetotosa">MindSporeToTosa</h3><p>首先这个是一个AccMulOp的范例</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在MindSporeToTosa.cpp中</span></span><br><span class="line"><span class="comment">//这里写一个函数用来计算中间过程的输出尺度</span></span><br><span class="line"><span class="comment">//broadcast type</span></span><br><span class="line"><span class="function">SmallVector&lt;<span class="type">int64_t</span>&gt; <span class="title">broadcast</span><span class="params">(OpBuilder &amp;rewriter, Value M1, Value M2, Location loc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  SmallVector&lt;<span class="type">int64_t</span>&gt; R1dim1;</span><br><span class="line">  <span class="comment">//shape</span></span><br><span class="line">  <span class="keyword">auto</span> M1Type = M<span class="number">1.</span><span class="built_in">getType</span>().<span class="built_in">dyn_cast</span>&lt;ShapedType&gt;();</span><br><span class="line">  <span class="keyword">auto</span> M2Type = M<span class="number">2.</span><span class="built_in">getType</span>().<span class="built_in">dyn_cast</span>&lt;ShapedType&gt;();</span><br><span class="line">  <span class="keyword">auto</span> shape1 = M1Type.<span class="built_in">getShape</span>();</span><br><span class="line">  <span class="keyword">auto</span> shape2 = M2Type.<span class="built_in">getShape</span>();</span><br><span class="line">  <span class="type">int64_t</span> R1dimi;</span><br><span class="line"><span class="comment">//broadcast</span></span><br><span class="line">  <span class="keyword">if</span> (shape<span class="number">1.</span><span class="built_in">size</span>() == shape<span class="number">2.</span><span class="built_in">size</span>())</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> i = <span class="number">0</span>; i &lt; shape<span class="number">1.</span><span class="built_in">size</span>(); i++)</span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (shape1[i] == shape2[i])</span><br><span class="line">      &#123;</span><br><span class="line">        R1dimi = shape1[i];</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (shape1[i] != <span class="number">1</span> &amp;&amp; shape2[i] != <span class="number">1</span>)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="built_in">assert</span>(<span class="string">&quot;error&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (shape1[i] == <span class="number">1</span>)</span><br><span class="line">      &#123;</span><br><span class="line">        R1dimi = shape2[i];</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (shape2[i] == <span class="number">1</span>)</span><br><span class="line">      &#123;</span><br><span class="line">        R1dimi = shape1[i];</span><br><span class="line">      &#125;</span><br><span class="line">      R1dim<span class="number">1.</span><span class="built_in">push_back</span>(R1dimi);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> R1dim1;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//AccMulOp——Result = Mul(Mul(Q, K), V)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AccMulOpConverter</span> : <span class="keyword">public</span> OpConversionPattern&lt;mindspore::AccMulOp&gt;</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> OpConversionPattern&lt;mindspore::AccMulOp&gt;::OpConversionPattern;</span><br><span class="line">  <span class="function">LogicalResult <span class="title">matchAndRewrite</span><span class="params">(mindspore::AccMulOp mindsporeOp, AccMulOp::Adaptor adaptor, ConversionPatternRewriter &amp;rewriter)</span> <span class="type">const</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="comment">//Location</span></span><br><span class="line">    Location loc = mindsporeOp.<span class="built_in">getLoc</span>();</span><br><span class="line">    <span class="comment">//resultTypes </span></span><br><span class="line">    Type resultTypes = mindsporeOp.<span class="built_in">getResult</span>().<span class="built_in">getType</span>();</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//Q = args[0], K = args[1], V = args[2]</span></span><br><span class="line">    ValueRange args = adaptor.<span class="built_in">getOperands</span>();</span><br><span class="line"></span><br><span class="line">    Type elemType = mindsporeOp.<span class="built_in">getResult</span>().<span class="built_in">getType</span>().<span class="built_in">cast</span>&lt;ShapedType&gt;().<span class="built_in">getElementType</span>();</span><br><span class="line"></span><br><span class="line">    SmallVector&lt;<span class="type">int64_t</span>&gt; result1 = <span class="built_in">broadcast</span>(rewriter, args[<span class="number">0</span>], args[<span class="number">1</span>], loc);</span><br><span class="line">    <span class="function">ArrayRef&lt;<span class="type">int64_t</span>&gt; <span class="title">newArrayRef</span><span class="params">(result1)</span></span>;</span><br><span class="line">    <span class="keyword">auto</span> Type1 = RankedTensorType::<span class="built_in">get</span>(newArrayRef, elemType);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Q = args[0], K = args[1], V = args[2]</span></span><br><span class="line">    <span class="comment">//mulOp11 = Mul(Q，K)</span></span><br><span class="line">    Value mulOp11 = rewriter.<span class="built_in">create</span>&lt;mlir::tosa::MulOp&gt;(loc, Type1, args[<span class="number">0</span>], args[<span class="number">1</span>], <span class="number">0</span>)-&gt;<span class="built_in">getResult</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">//Mul(mulOp11，V)</span></span><br><span class="line">    <span class="keyword">auto</span> mulOp2 = rewriter.<span class="built_in">create</span>&lt;mlir::tosa::MulOp&gt;(loc, resultTypes, mulOp11, args[<span class="number">2</span>], <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    rewriter.<span class="built_in">replaceOp</span>(mindsporeOp, mulOp<span class="number">2.</span><span class="built_in">getResult</span>());</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">success</span>();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>再在<code>struct ConvertMindSporeToTosaPass : public ConvertMindSporeToTosaBase&lt;ConvertMindSporeToTosaPass&gt;</code>中添加patterns-AccMulOpConverter</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ConvertMindSporeToTosaPass</span> : <span class="keyword">public</span> ConvertMindSporeToTosaBase&lt;ConvertMindSporeToTosaPass&gt;</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">     <span class="built_in">ConvertMindSporeToTosaPass</span>() = <span class="keyword">default</span>;</span><br><span class="line">...</span><br><span class="line">     <span class="function"><span class="type">void</span> <span class="title">runOnOperation</span><span class="params">()</span> <span class="keyword">override</span></span></span><br><span class="line"><span class="function">     </span>&#123;</span><br><span class="line"></span><br><span class="line">         <span class="comment">// clang-format off</span></span><br><span class="line">         (<span class="type">void</span>)patterns.add&lt;</span><br><span class="line">        ...</span><br><span class="line">       <span class="comment">//AccMulOp</span></span><br><span class="line">        AccMulOpConverter,</span><br><span class="line">        ConvertMindSporePadOp&lt;mindspore::PadOp&gt;</span><br><span class="line">        &gt;(patterns.<span class="built_in">getContext</span>());</span><br><span class="line">        mlir::<span class="built_in">populateMindSporeLowerPattern</span>(patterns);</span><br><span class="line">    </span><br><span class="line">...</span><br><span class="line">      &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>同时，在<code>/akg-mlir/compiler/lib/Conversion/MindSporeToLinalg/MindSporeToLinalg.cpp</code>和<code>/akg-mlir/compiler/lib/Conversion/MindSporeFinalizingLower/MindSporeFinalizingLower.cpp</code>中对此算子添加了legal,通过手动添加legal，可以保证AccMul算子不在这里被lower，在此类转换中被保留</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void runOnOperation() override</span><br><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">//AccmulOp</span><br><span class="line">   target.addLegalOp&lt;mindspore::AccMulOp&gt;();</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后是一个deepseek写的addlayernorm的方案</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MindSporeToTosa.cpp</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ConvertAddLayerNormToTosa</span> : <span class="keyword">public</span> OpConversionPattern&lt;MindSpore::AddLayerNormOp&gt; &#123;</span><br><span class="line">  <span class="keyword">using</span> OpConversionPattern::OpConversionPattern;</span><br><span class="line">  </span><br><span class="line">  <span class="function">LogicalResult <span class="title">matchAndRewrite</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      MindSpore::AddLayerNormOp op,</span></span></span><br><span class="line"><span class="params"><span class="function">      OpAdaptor adaptor,</span></span></span><br><span class="line"><span class="params"><span class="function">      ConversionPatternRewriter &amp;rewriter</span></span></span><br><span class="line"><span class="params"><span class="function">  )</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取输入和属性</span></span><br><span class="line">    Value input = adaptor.<span class="built_in">getInput</span>();</span><br><span class="line">    Value gamma = adaptor.<span class="built_in">getGamma</span>();</span><br><span class="line">    Value beta = adaptor.<span class="built_in">getBeta</span>();</span><br><span class="line">    <span class="type">float</span> epsilon = op.<span class="built_in">getEpsilon</span>().<span class="built_in">convertToFloat</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 将AddLayerNorm分解为TOSA操作：</span></span><br><span class="line">    <span class="comment">// 1. 计算输入均值（mean）</span></span><br><span class="line">    <span class="comment">// 2. 计算方差（variance）</span></span><br><span class="line">    <span class="comment">// 3. 执行归一化：(input - mean) / sqrt(variance + epsilon)</span></span><br><span class="line">    <span class="comment">// 4. 应用gamma和beta</span></span><br><span class="line">    <span class="comment">// 具体实现需调用TOSA的现有操作（如tosa.add, tosa.mul等）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 伪代码示例：</span></span><br><span class="line">    <span class="keyword">auto</span> mean = rewriter.<span class="built_in">create</span>&lt;tosa::ReduceMeanOp&gt;(...);</span><br><span class="line">    <span class="keyword">auto</span> variance = rewriter.<span class="built_in">create</span>&lt;tosa::SubOp&gt;(...);</span><br><span class="line">    <span class="keyword">auto</span> normalized = rewriter.<span class="built_in">create</span>&lt;tosa::DivOp&gt;(...);</span><br><span class="line">    <span class="keyword">auto</span> scaled = rewriter.<span class="built_in">create</span>&lt;tosa::MulOp&gt;(normalized, gamma);</span><br><span class="line">    <span class="keyword">auto</span> output = rewriter.<span class="built_in">create</span>&lt;tosa::AddOp&gt;(scaled, beta);</span><br><span class="line">    </span><br><span class="line">    rewriter.<span class="built_in">replaceOp</span>(op, output);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">success</span>();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>然后要注册这个写好的pattern</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">populateMindSporeToTosaPatterns</span><span class="params">(MLIRContext *context, RewritePatternSet &amp;patterns)</span> </span>&#123;</span><br><span class="line">  patterns.<span class="built_in">add</span>&lt;ConvertAddLayerNormToTosa&gt;(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>更新Lower流程入口确保在Lower流程中调用上述Pattern：</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">LowerMindSporeToTosa</span><span class="params">(ModuleOp <span class="keyword">module</span>)</span> </span>&#123;</span><br><span class="line">  <span class="function">ConversionTarget <span class="title">target</span><span class="params">(*<span class="keyword">module</span>.getContext())</span></span>;</span><br><span class="line">  target.<span class="built_in">addLegalDialect</span>&lt;Tosa::TosaDialect&gt;();</span><br><span class="line">  target.<span class="built_in">addIllegalDialect</span>&lt;MindSpore::MindSporeDialect&gt;();</span><br><span class="line">  </span><br><span class="line">  <span class="function">RewritePatternSet <span class="title">patterns</span><span class="params">(&amp;getContext())</span></span>;</span><br><span class="line">  <span class="built_in">populateMindSporeToTosaPatterns</span>(patterns);</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">failed</span>(<span class="built_in">applyPartialConversion</span>(<span class="keyword">module</span>, target, std::<span class="built_in">move</span>(patterns)))) &#123;</span><br><span class="line">    <span class="built_in">signalPassFailure</span>();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="mindsporetolinalg">MindsporetoLinalg</h3><p>利用Linalg <strong>在这一层并没有直接的矩阵乘加指令</strong>。但在<br><code>akg/akg-mlir/compiler/lib/Conversion/MindSporeToLinalg/MindSporeToLinalg.cpp</code><br>中有已经提供了写elementwise计算的方法，所以直接在<br><code>static Value createLinalgBodyCalculationForElementwiseOp(Operation *op, ValueRange args, ArrayRef&lt;Type&gt; resultTypes, PatternRewriter &amp;rewriter)</code>中添加对应逻辑，其中<a href="https://gitee.com/link?target=https%3A%2F%2Fmlir.llvm.org%2Fdocs%2FDialects%2FArithOps%2F">arith</a>旨在容纳基本的整数和浮点数学运算</p><p>同上的流程</p><ol><li>编写MindsporetoLinalg</li><li>然后编写一个pattern</li><li>还要在<code>akg-mlir/compiler/lib/Conversion/MindSporeToTosa/MindSporeToTosa.cpp</code>对此算子手动添加egal，保证AccMul算子不在这里被lower</li></ol><p>但是我具体没有搞明白</p><h1>任务3编写对应的测试用例（算子的info文件和对应的op_dsl）</h1><p><a href="https://gitee.com/monkeykingd/akg/wikis/AKG-MLIR%E5%8D%95%E7%AE%97%E5%AD%90%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%E6%9E%84%E5%BB%BA">编写测试用例的参考资料</a></p><p>这里老师不仅讲了怎么写测试用例，还讲了怎么测试lower过程</p><p>测试的时候首先有一个正确结果benchmark，还有一个测试数据集，然后运行测试程序就可以把算子计算结果和正确结果进行对比</p><h3 id="benchmark构建">Benchmark构建</h3><p>用numpy验证计算的正确性</p><p>关benchmark记录在<code>akg-mlir/python/akg_v2/utils/op_dsl.py</code>中的<code>get_op_dsl()</code>函数中，每一个算子对应一个lambda函数作为dsl。以AccMul为例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;AccMul&quot;: lambda inputs, output, attr: accmul_str(inputs, output, attr),</span><br></pre></td></tr></table></figure><p>对应的dsl为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def accmul_str(inputs, output, attr):</span><br><span class="line">    s=&quot;%s=np.multiply(np.multiply(%s,%s),%s)&quot;% ( output[0][&#x27;tensor_name&#x27;], get_input(inputs[0][0]),get_input(inputs[1][0]),get_input(inputs[2][0]))</span><br><span class="line">    return s</span><br></pre></td></tr></table></figure><p>这里指用np的multiply函数做计算。如果算子lower成功，期待的输出如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Start running xxx</span><br><span class="line">xxxprecision correct</span><br></pre></td></tr></table></figure><h2 id="测试用例怎么写">测试用例怎么写</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"># &quot;input_desc&quot;为一个list，里面包含了每个input的信息，包括data_type, format, shape和tensor_name，这个决定了融合算子的输入</span><br><span class="line">    &quot;input_desc&quot;: [</span><br><span class="line">        [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                &quot;shape&quot;: [</span><br><span class="line">                    4096,</span><br><span class="line">                    7680</span><br><span class="line">                ],</span><br><span class="line">                &quot;tensor_name&quot;: &quot;Query&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                &quot;shape&quot;: [</span><br><span class="line">                    4096,</span><br><span class="line">                    7680</span><br><span class="line">                ],</span><br><span class="line">                &quot;tensor_name&quot;: &quot;Key&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                &quot;shape&quot;: [</span><br><span class="line">                    4096,</span><br><span class="line">                    7680</span><br><span class="line">                ],</span><br><span class="line">                &quot;tensor_name&quot;: &quot;Value&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    ],</span><br><span class="line">    </span><br><span class="line">    # &quot;op&quot;为整个融合算子的名字，对应到mlir文件的func的名字。</span><br><span class="line">    &quot;op&quot;: &quot;AccMulOp_fusion&quot;,</span><br><span class="line">    # &quot;output_desc&quot;为一个list，表示融合算子中每个单算子的名字，每一项表示每个算子的特点：</span><br><span class="line">    # attr：没有的时候要写成null</span><br><span class="line">    # input_desc：算子的输入，要求同上；</span><br><span class="line">    # name：算子的名字，必须和mindspore td内注册的算子对应；</span><br><span class="line">    # output_desc：算子的输入，要求同输入；值得注意的是，如果融合算子中一个算子的输入为前序算子的输出，tensor_name必须一致以获得对应关系；</span><br><span class="line">    &quot;op_desc&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;attr&quot;: null,</span><br><span class="line">            &quot;input_desc&quot;: [</span><br><span class="line">                [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                        &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                        &quot;name&quot;: &quot;Query&quot;,</span><br><span class="line">                        &quot;shape&quot;: [</span><br><span class="line">                            4096,</span><br><span class="line">                            7680</span><br><span class="line">                        ],</span><br><span class="line">                        &quot;tensor_name&quot;: &quot;Query&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">                [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                        &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                        &quot;name&quot;: &quot;Key&quot;,</span><br><span class="line">                        &quot;shape&quot;: [</span><br><span class="line">                            4096,</span><br><span class="line">                            7680</span><br><span class="line">                        ],</span><br><span class="line">                        &quot;tensor_name&quot;: &quot;Key&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">                [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                        &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                        &quot;name&quot;: &quot;Value&quot;,</span><br><span class="line">                        &quot;shape&quot;: [</span><br><span class="line">                            4096,</span><br><span class="line">                            7680</span><br><span class="line">                        ],</span><br><span class="line">                        &quot;tensor_name&quot;: &quot;Value&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            ],</span><br><span class="line">            &quot;name&quot;: &quot;AccMul&quot;,</span><br><span class="line">            &quot;output_desc&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">                    &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">                    &quot;name&quot;: &quot;output&quot;,</span><br><span class="line">                    &quot;shape&quot;: [</span><br><span class="line">                            4096,</span><br><span class="line">                            7680</span><br><span class="line">                    ],</span><br><span class="line">                    &quot;tensor_name&quot;: &quot;output&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    # output_desc：整个融合算子的输出。</span><br><span class="line">    &quot;output_desc&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;data_type&quot;: &quot;float32&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;DefaultFormat&quot;,</span><br><span class="line">            &quot;shape&quot;: [</span><br><span class="line">                4096,</span><br><span class="line">                7680</span><br><span class="line">            ],</span><br><span class="line">            &quot;tensor_name&quot;: &quot;output&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    # 后面的不管</span><br><span class="line">    &quot;platform&quot;: &quot;AKG&quot;,</span><br><span class="line">    &quot;process&quot;: &quot;cpu&quot;,</span><br><span class="line">    &quot;target_info&quot;: &#123;</span><br><span class="line">        &quot;arch&quot;: &quot;aarch64&quot;,</span><br><span class="line">        &quot;feature&quot;: &quot;neon&quot;,</span><br><span class="line">        &quot;system&quot;: &quot;linux&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;version&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试文件构建完成之后，我们使用<code>python/akg_v2/exec_tools/</code>目录下<code>py_benchmark.py</code>进行测试，基本指令为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python $&#123;path_to_py_benchmark&#125;/py_benchmark.py -e cpu -f mul.info --dump_ir 1</span><br></pre></td></tr></table></figure><p>其中</p><ul><li><code>-e</code>决定了后端，这里使用cpu</li><li><code>-f</code>决定了测试文件，这里使用是<code>mul.info</code></li><li><code>--dump_ir 1</code>表示dump中间结果，相关结果保存在<code>py_benchmark.py</code>对应目录下</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Mindspore实习-AKG SIG算子addlayernorm编辑和合并&lt;/h1&gt;
&lt;h2 id=&quot;什么是算子&quot;&gt;什么是算子&lt;/h2&gt;
&lt;p&gt;计算图和算子在计算本质上是一致的。&lt;strong&gt;算子是打包后的计算图，计算图是拆包后的算子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Mindspore" scheme="http://outbreak-sen.github.io/tags/Mindspore/"/>
    
    <category term="实习" scheme="http://outbreak-sen.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
    <category term="算子" scheme="http://outbreak-sen.github.io/tags/%E7%AE%97%E5%AD%90/"/>
    
  </entry>
  
  <entry>
    <title>EffiMVS全文翻译</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/EffiMVS%E5%85%A8%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/EffiMVS%E5%85%A8%E6%96%87%E7%BF%BB%E8%AF%91/</id>
    <published>2025-02-09T08:21:01.000Z</published>
    <updated>2025-02-09T08:21:48.232Z</updated>
    
    <content type="html"><![CDATA[<h1>Effi MVS翻译</h1><h2 id="摘要">摘要</h2><p>在本文中，我们提出了一种用于多视图立体的新颖的迭代动态成本量。 与其他作品相比，我们的成本量要轻得多，因此可以使用基于 2D 卷积的 GRU 进行处理。 值得注意的是，每一步GRU 的输出可进一步用于生成新的成本量。 这样，就构建了一个基于GRU的迭代优化器。 此外，我们提出了一种级联和分层细化架构来利用多尺度信息并加速收敛。 具体来说，利用轻量级 3D CNN 生成最粗糙的初始深度图，这对于启动 GRU 并保证快速收敛至关重要。 然后，深度图由作用于金字塔特征图的多级 GRU 进行细化。 对 DTU 和 Tanks &amp; Temples 基准测试的大量实验表明，我们的方法可以在准确性、速度和内存使用方面实现最先进的结果。</p><h2 id="介绍">介绍</h2><p>多视图立体 (MVS) 旨在基于一系列姿势图像和相应的相机参数重建密集的 3D 模型。 预测深度图，然后将深度图融合到点云模型中是 MVS 最常见的流程。 作为一个基本问题，MVS 在计算机视觉领域已经研究了几十年。</p><p>最近，我们见证了基于深度学习的 MVS 方法的快速发展。 一般来说，MVS任务最常见的基本结构是利用图像序列的特征来构造3D成本（相关）体积，然后用3D CNN对其进行正则化，最后对深度进行回归。 随之而来的还有大量作品管道，并且在 MVS 基准的重建精度方面优于大多数传统方法。然而，由于正则化步骤对 GPU 内存和处理时间的要求较高，现有方法CIDER, MVSNet只能处理低分辨率的图像。</p><p>显然，除了提高重建质量之外，减少运行时间和GPU内存消耗也非常重要，这使得基于学习的MVS工作能够适应内存和计算受限的设备。 最近，有人提出了一些工作来提高 MVS 的效率。 然而，同时提高精度和降低消耗仍然非常具有挑战性。 在这项工作中，我们的目标是提高高分辨率 MVS 的计算速度并减少内存消耗，并确保良好的重建质量。</p><p>我们方法的核心思想是构建一个可以迭代方式处理的轻量级动态成本量。 这一策略可以带来很多好处。 首先，由于使用了轻量级成本卷，大大降低了推理阶段的内存使用峰值。 其次，迭代和动态处理可以保证大的搜索空间，这对准确性很重要。 最后，我们的动态成本量能够在几个迭代步骤中收敛，因此我们的方法非常有效。</p><p>老实说，我们的方法部分受到[5,10,25,26]作品的启发。 在[5,10,25]的工作中，提出了级联自适应成本量。 相比之下，我们进一步缩小了成本量的大小，并将这种多阶段策略扩展到迭代方式。 我们的迭代想法也受到最近的光学估计工作的启发[26]。 与[26]相比，我们放弃了全尺寸静态相关卷，因为它对内存不友好。 更重要的是，与光流估计不同，我们利用轻量级 3D CNN 来估计粗略深度图作为 GRU 的初始化，我们发现这对于 GRU 在 MVS 上的快速收敛非常重要。 另外，由于3D CNN非常轻，对效率影响较小。 总之，我们的贡献可以总结为：</p><ol><li>我们提出了一种新颖的动态成本卷，它非常轻量级，可以通过基于 2D 卷积的 GRU 迭代处理。 这样我们就避免了大尺寸静态成本卷的内存和耗时问题。</li><li>我们提出了一种级联和分层细化架构来利用多尺度信息并加速收敛。 具体来说，通过轻量级 3DCNN，我们为 GRU 提供可靠的初始化，这对于快速收敛和最终性能至关重要。</li><li>我们的方法在准确性、推理速度和 GPU 内存消耗方面实现了最先进的性能（参见图 1）。 至于准确性，我们的方法在 DTU [1] 和 Tanks &amp; Temples 数据集 [13] 的高级序列上取得了最好的结果。 更重要的是，由于内存消耗较少，我们的方法比亚军快 2 倍。</li></ol><h2 id="2-相关工作">2.相关工作</h2><h3 id="2-1-传统-mvs-方法">2.1. 传统 MVS 方法</h3><p>传统的MVS方法大致可分为四类：基于体素的方法[24, 27]、基于表面的方法[7, 14]、基于块的方法[8, 16]和基于深度图的方法[9, 21, 30]。 在这些方法中，基于深度图的方法具有更好的灵活性和可扩展性。 Gipuma [9]提出了一种更适合并行计算的基于棋盘格的传播方案，并将PatchMatch [2]立体方法扩展到多视图立体。 COLMAP [21]通过联合估计像素级视图选择、深度图和表面法线来增强算法的鲁棒性。 ACMM [30]提出了一种具有自适应棋盘传播和多假设联合视图选择的多尺度 MVS 框架。 虽然这些方法可以获得鲁棒的3D重建结果，但它们存在计算要求高和重建质量差的问题。</p><p>2.2. 基于学习的 MVS 方法<br>最近，已经提出了大量基于深度学习的多视图立体工作[5,10,12,28,34-36]。 SurfaceNet[12]是早期的代表作品之一，它构建体素体来聚合多视图信息，并使用3D CNN对其进行正则化。 基于可微单应性 [6]，Yao 等人。 [35]提出了一种广泛使用的基于深度学习的MVS管道。 具体来说，MVSNet [35] 首先提取每个视图图像的特征图，然后构建一个成本卷，该成本卷基于一组深度假设聚合几何信息。 此外，通过 3D CNN 对成本量进行正则化，并通过回归策略预测最终深度。 然而，由于构建和正则化成本卷的内存使用量和计算要求较高，<br>MVSNet 只能处理低分辨率的图像。 为了减少内存消耗，R-MVSNet [36] 通过沿深度维度处理成本量，利用循环神经网络代替 3D CNN 正则化，这减少了内存需求，但增加了运行时间。 D2 HC-RMVSNet [33]提出了一种具有动态一致性检查的高效且有效的密集混合循环多视图立体网络。 AttMVS [18]提出了一种新颖的注意力增强匹配置信度和注意力引导正则化模块来提高匹配的鲁棒性。 Vis-MVSNet [38]通过匹配不确定性估计明确推断并集成了 MVS 网络中的像素级遮挡信息。 AA-RMVSnet [29]提出了一种自适应聚合模块，并利用具有循环结构的混合网络进行成本量正则化。</p><p>近年来，MVS的效率越来越受到人们的关注。 Fast-MVSNet [37]提出了一种新颖的从稀疏到密集从粗到细的框架，以实现快速准确的深度<br>MVS 中的估计。 通常，许多工作利用从粗到细的策略来减少内存消耗并提高准确性和速度[5,10,34]。 CVP-MVSNet [34]和CasMVSNet [10]基于金字塔特征图构建了级联成本卷。 UCS-Net [5]提出了一种利用不确定性估计来优化深度假设的策略。 值得注意的是，最近，Patchmatch-Net [28]将传统的 PatchMatch 算法引入深度学习框架，从而大大减少了运行时间和内存消耗。 与 PatchmatchNet 相比，我们的方法可以以更少的运行时间和内存消耗实现更好的重建质量。</p><h2 id="方法">方法</h2><p>如图 2 所示，我们的方法由多尺度特征提取器和基于 GRU 的优化器组成。 更具体地说，基于 GRU 的优化器包括动态成本量构造器和 GRU 模块。 与许多以前的工作不同，我们的动态成本量不仅可以聚合几何信息，还可以聚合上下文和深度信息。 更重要的是，它可以由 GRU 以迭代方式进行处理。 具体来说，在每个更新步骤中，我们首先构建一个建议的动态成本量，然后通过 GRU 更新深度图。 此外，我们提出了一种级联和分层细化架构来利用多尺度信息并加速收敛。 具体来说，利用轻量级 3D CNN 生成最粗糙的深度图，该深度图可用作下一个 GRU 的可靠初始化。 然后，深度图由作用于金字塔特征图的多级 GRU 进行细化。 值得注意的是，在每个阶段 k，给定初始深度图 Dk0，所提出的基于 GRU 的优化器可以迭代更新多次并输出最终深度图。 接下来，我们给出我们方法的更多细节。</p><h3 id="3-2-动态成本量">3.2. 动态成本量</h3><p>成本量在 MVS 问题中起着至关重要的作用。 如图3所示，与许多以前的工作中的静态成本量不同，我们聚合了几何特征、深度特征和上下文特征来构建我们的动态成本量。 分别从局部成本量、深度特征和参考图像中提取几何特征、深度特征和上下文特征。 更重要的是，受益于迭代策略，我们可以在狭窄的逆深度范围内更新深度假设，以在每次迭代中构造局部成本量，这使得我们的动态成本量与静态成本量相比要轻得多。</p><h4 id="3-2-1局部成本量">3.2.1局部成本量</h4><p>与之前的 MVS 工作[19,28,29,31]类似，给定参考视图的 D 深度假设 {dj |j = 1, …, D}，我们构造一个局部成本量来表示相关性 参考和源特征之间。 具体来说，对于参考视图中的每个像素 p，我们利用可微单应性通过将源特征 Fi 扭曲为第 j 个深度假设 dj 来计算相应的像素 p i,j ：</p><p>这里Ki表示视图i的内在矩阵。 R0,i 和 t0,i 表示参考视图和源视图 i 之间的相对旋转和平移参数。 给定 p i,j 和源特征图 Fi ，我们通过可微双线性插值重建扭曲的源特征图 Fi 。 遵循 MVSNet [35]，成本图是 −1 N − 1 扭曲源特征图 {Fi }N i=1 的方差<br>然而，考虑到基于 GRU 的优化器可以迭代更新深度图，我们在每次迭代中仅在狭窄的逆深度范围内采样一些深度假设。 具体来说，对于阶段 k 和迭代 t 的每个像素 p，我们在逆深度范围 Rk 中均匀采样 Dk 深度假设：</p><p>这里Im表示最小深度假设平面间隔，在4.2节中有详细介绍。 Dkt−1 是迭代 t − 1 中更新的深度图。为了用 2D CNN 处理局部成本量并将其与上下文和深度信息融合，我们取消深度维度并沿通道维度连接成本图。 因此，与 MVSNet [35] 不同，我们的局部成本量的形状是 CL ∈ RW ×H×(C×D) ，其中 C 和 D 分别表示通道和深度维度。</p><h4 id="3-2-2-特征聚合">3.2.2 特征聚合</h4><p>如图 3 所示，在每次迭代 t 中，我们使用两个轻量级提取器（由两个 2D 卷积层组成）从局部成本量和深度图 Dkt−1 中提取几何特征和深度特征。 上下文特征来自多尺度上下文特征提取器，每个阶段只需要提取一次。</p><p>为了构造最终的动态成本量 CD ，我们首先利用 2D 卷积层来处理几何特征和深度特征的串联。 然后，输出与上下文特征连接以形成动态成本量。 所有的级联操作都是在通道维度中执行的。</p><h3 id="3-3-多级-gru">3.3. 多级 GRU</h3><p>我们的动态成本量由 GRU 以迭代方式处理。 此外，为了利用多尺度信息并加速收敛，我们构建了多级 GRU 架构。 这样，动态成本量就构建在金字塔特征图上，并分别由多尺度 GRU 进行处理。 更具体地，在每个阶段k，优化模块将深度图更新T k 次，并输出一组更新量Δdkt ，其中t从1到T k 。 在每次迭代 t 中，输入深度图 Dkt−1 将更新为Dkt = Dkt−1 + Δdkt ，然后作为下一次迭代 t + 1 的输入。更重要的是，每个阶段最后一次迭代的深度图 DkT k 都会被上采样为 DkT k +1 。<br>然后，DkT k+1 将作为下一阶段的初始深度图Dk+1 0 。</p><p>如图4所示，深度图的质量可以是每次迭代后都有显着改善。 特别是，从图 4 中我们可以看到，基于 GRU 的优化模块可以填充无纹理区域中的孔洞并锐化边界。</p><h4 id="3-3-1初始深度预测">3.3.1初始深度预测</h4><p>基于GRU的优化模块根据局部空间信息更新深度值，这使得它对初始深度值敏感。 由于常见的<br>针对MVS中弱纹理区域和相似区域的问题，不可靠的初始深度图将使基于GRU的优化更容易输出错误的深度值。 因此，我们提出了一种初始深度值预测模块来在最粗阶段预测可靠的初始深度值。 受其他基于学习的 MVS 方法 [19,28,29,31] 的启发，我们通过三个模块预测概率体积 Pd 和相应的深度图：成本体积构建、3D CNN 正则化和回归。 初始深度预测模块的架构如图 5 所示。按照 MVSNet [35] 的工作，我们构建了一个微小的成本卷，它由稀疏深度假设组成，但包括足够大的逆深度范围。 然后，我们利用轻量级 3D CNN 对成本量进行正则化，得到与每个深度假设 d 对应的概率量 Pd。 最后，我们用 sof targmin 回归初始深度图 Dinit：</p><h4 id="3-3-2-gru">3.3.2 GRU</h4><p>受[11,26]的启发，我们设计了一个GRU模块来更新深度图。 我们的GRU模块的详细信息如下：<br>这里 σ 是 sigmoid 激活函数，W 表示对应的卷积网络的参数，conv 表示一个小的 2D 卷积模块，由 1 × 5 卷积和 5 × 1 卷积组成。<br>我们 GRU 的输入是动态成本量 t−1 。 动态 Ct−1 D 以及潜在隐藏状态 h t−1 成本量 CD 可以由先前的深度图 Dkt−1 刷新。 此外，在每个阶段，初始隐藏状态 h0 由上下文特征网络初始化。<br>基于隐藏状态 ht ，我们利用深度头模块来预测残差深度 Δdt 。 深度头模块包含两个卷积层，并使用 tanh 激活函数来约束输出值的范围。<br>在每个阶段 k 的最后一次迭代 T k 之后，我们使用掩模上采样模块 [26] 对当前深度 HW× 23−k 进行上采样。 更具体地说，基于最后一个 hidmap( 23−k k T den state h ，我们利用两个卷积层来预测 HW× 23−k× (2 × 2 × 9) 掩码，它表示邻居的 a 23−k 权重 然后可以根据预测的掩模通过加权组合将深度 HW×22−k 图上采样到 22−k 的分辨率。</p><h3 id="3-4-损失函数">3.4. 损失函数</h3><p>在训练阶段，我们的方法可以在不同的迭代步骤中从初始深度预测模块和基于 GRU 的多阶段优化模块输出几个深度图。 我们使用相应分辨率的地面真实深度图计算所有输出深度图上的 L1 损失。 因此，最终的损失是所有损失的加权和：</p><p>其中Linit是初始深度预测模块获得的初始深度图的损失。 Tk 是阶段 k 的优化迭代次数。 {Lki |i = 1…Tk + 1} 是 Tk 输出深度图和阶段 k 的上采样深度图的损失，λki 是相应的权重</p><h2 id="4-实验">4.实验</h2><p>我们在 DTU [1] 和 Tanks &amp; Temples 数据集 [13] 上评估了我们的方法。 进行了大量的实验来验证我们方法的准确性和效率。</p><h3 id="4-1-数据集">4.1. 数据集</h3><p>DTU数据集DTU数据集[1]是一个大规模的室内MVS数据集，包含不同光照条件下的128个不同的扫描和49个视图。 所有扫描都是在实验室环境下以相同的相机轨迹收集的。 DTU 提供 79 次训练扫描的地面真实深度图和 22 次评估扫描的 3D 点云。 遵循大多数 MVS 工作 [19,28,29,31] 中的配置，我们应用 DTU 数据集来训练和评估我们的网络。</p><p>Tanks &amp; Temples 数据集 Tanks &amp; Temples 数据集[13]是一个大规模的户外 MVS 数据集，它为不同的扫描提供了一组真实环境中的视频序列。 分为中级和高级两套，共14个场景。 我们还使用在 DTU 数据集 [1] 上训练的模型在中级和高级集上评估我们的方法，无需进行微调。</p><h3 id="4-2-实施细节">4.2. 实施细节</h3><p>训练在DTU数据集[1]上进行训练时，我们将输入图像的分辨率设置为640×512，输入图像的数量设置为N = 5。对于初始深度预测模块，我们将深度假设的数量设置为48。 对于局部成本量，我们将所有阶段的深度假设 Dk 的数量设置为 4。 我们定义逆深度的最小假设平面间隔 Im：<br>我们将Z设置为384，并将阶段0、1、2的深度假设间隔设置为4Im、2Im、Im（阶段0是粗略阶段，分辨率为W×H=80×64）。 对于每个阶段的优化模块，我们在阶段 0、1、2 到 3、3、3 设置迭代次数 T k。我们在 OneCycleLR 调度器下使用 AdamW 训练模型 48 个周期，学习率为 0.001。 我们将批量大小设置为 4，并在 1 个 NVIDIA GeForce RTX 3090 GPU 上训练我们的模型。</p><p>评估</p><p>我们在 DTU 评估集 [1] 以及 Tanks &amp; Temples 数据集 [13] 的中级和高级数据集上评估我们提出的方法。 对于 DTU 的评估，我们将输入图像的数量 N 设置为 5，输入图像的大小为 1600 × 1184。对于 Tanks &amp; Temples 数据集的评估，我们使用在 DTU 上训练的模型，无需任何微调。 我们将视图数量 N 设置为 7，输入图像大小为 1920 × 1056，初始深度预测模块中的深度假设数量为 96。Tanks &amp; Temples 数据集的相机位置、稀疏点云和深度范围 由开源 SfM 软件 OpenMVG 恢复[20]。</p><p>过滤与融合<br>与其他基于学习的 MVS 方法类似，我们根据光度和几何一致性。 我们对过滤算法进行了一些改进[22]，具体细节在补充材料中给出。 同时，我们对从初始深度预测模块获得的概率体积Pd进行上采样，作为每个像素的置信度测量，并丢弃估计深度概率低于0.3的像素。</p><h3 id="4-3-基准性能benchmark-performance">4.3. 基准性能Benchmark Performance</h3><p>我们将我们的方法与最近发布的基于学习的 MVS 方法在重建质量、运行时间和 GPU 内存消耗方面进行了比较。 如表所示。 如图 1、3 所示，我们的方法在 DTU 数据集 [1] 和 Tanks &amp; Temples 数据集 [13] 的高级序列上实现了最佳性能。 至于 Tanks &amp; Temples 数据集的中间序列，我们也取得了非常有竞争力的结果。 我们进一步比较我们的<br>方法与最近发表的基于学习的 MVS 方法[5,10,28,34,37,38]一起致力于提高表中的效率。 2 在时间和内存消耗方面。 我们使用原始尺寸图像为所有方法设置相同的配置，并在 DTU 和 Tanks &amp; Temples 数据集上分别将输入视图数设置为 5 和 7。 如表所示。 2、我们的方法在运行时间和内存消耗方面更加高效。 值得注意的是，我们的快速版本（Iters：1 11）几乎比 PatchmatchNet [28] 最接近的亚军快 2 倍。 更令人惊讶的是，我们的快速版本（Iters：1 1 1）仍然可以实现非常高的重建精度，如表所示。 1.这些实验结果明显表明我们的方法不仅可以提高计算速度并减少内存消耗，而且可以保证高质量的重建。</p><p>在图 6 中，我们在 DTU 数据集上对我们的方法和一些最先进的方法进行了更多质量比较。 从图 6 中我们可以看到，与 CVP-MVSNet [34] 和 PatchmatchNet [28] 相比，我们的方法提供了更准确的边界，并且在 3D 点云的结构细节上表现得更好。 此外，Tank &amp; Temples数据集上的一些3D点云重建结果如图7所示。从图7中我们可以看到，即使对于具有挑战性的高级序列，该方法的重建结果也是高质量的。 最后，表中列出了更全面的数量结果。 3、我们的方法在大多数评价指标上都取得了非常有竞争力的结果。</p><h3 id="4-4-消融研究">4.4. 消融研究</h3><p>在本节中，我们提供了广泛的消融实验来分析迭代次数、初始深度预测、动态成本量的组成部分和阶段数的影响。</p><h4 id="4-4-1-迭代次数">4.4.1 迭代次数</h4><p>按照 4.2 节中介绍的相同实验配置，我们进行不同迭代次数的消融实验。 这样我们就想验证一下迭代次数的效果。<br>结果列于表中。 4. 从表中。 从图4可以看出，迭代次数对于点云的完整性尤为重要。 这并不奇怪，因为我们的动态成本量可以聚合独特的上下文信息，GRU 可以进一步利用这些信息来填补漏洞。 类似的结论也可以在图4中得到证明，其中随着迭代次数的增加，孔被填充。 在这里，我们还想说我们的方法相当灵活，即我们可以根据实际任务需求调整测试阶段的迭代次数以平衡重建质量、速度和内存消耗。</p><h4 id="4-4-2-初始深度预测">4.4.2 初始深度预测</h4><p>在这个实验中，我们设计了一个额外的基于 GRU 的优化模块，进行 4 次迭代，以取代最粗阶段的初始深度预测 (IDP) 模块。 对于这个优化模块，我们将深度假设的数量设置为8，深度假设的间隔为16Im，逆深度范围的中值(dmin + dmax)/2用作初始输入深度图。</p><p>如表所示。 如图5所示，我们使用初始深度预测模块的方法在重建质量方面显然表现更好。 我们基于3DCNN的初始深度预测模块可以获得相当可靠的深度图，可以有效避免基于GRU的优化单元的局部优化问题。 特别是，我们的方法在完整性方面表现得更好，这进一步证明了所提出的初始深度预测模块的重要性。</p><h4 id="4-4-3-动态成本量的组成部分">4.4.3 动态成本量的组成部分</h4><p>在本实验中，我们在DTU的评估集上评估了深度特征（DF）和上下文特征（CF）在动态成本量构建过程中的有益效果[1]。 如表所示。 6、深度特征和上下文特征对重建结果的完整性影响很大，可以将完整性误差从0.368降低到0.313。 没有深度特征和上下文特征，动态成本量只能提供从局部成本中提取的几何特征信息</p><p>实验结果还证明，通过聚合附加深度特征信息和上下文特征信息构建动态成本量是我们的方法在 DTU 评估集上实现最先进性能的关键。</p><h4 id="4-4-4级数number-of-stages">4.4.4级数Number of Stages</h4><p>我们进一步在总阶段数为 2 和 4 的情况下评估我们的方法，相应的最精细阶段的分辨率分别为 H4 × W 4 和 H×W 。 我们从重建质量、运行时间和 GPU 内存消耗方面评估了 DTU [1] 和 Tanks &amp; Temples [13] 上的所有模型。 值得注意的是，我们设置了不同的上采样模块比率，以使所有模型输出全分辨率深度图。 如表所示。 7、随着阶段数量的增加，在DTU和Tanks &amp; Temples基准上性能有了显着提升，但同时运行时间和GPU显存消耗也显着增加。</p><h2 id="5-结论">5. 结论</h2><p>在这项工作中，我们提出了一种新颖的迭代动态成本量，可以由我们提出的多级 GRU 进行处理。 我们的方法非常有效，可以处理非常高分辨率的图像。 和…相比<br>与其他基于学习的 MVS 方法相比，我们的方法在准确性、速度和内存使用方面达到了最先进的结果。 此外，我们的方法非常灵活，可以通过调整测试阶段的迭代次数在准确性和效率之间取得更好的平衡。 未来，我们希望利用更强大的特征提取器来进一步提高性能。</p><h2 id="致谢">致谢</h2><p>该工作得到了国家自然科学基金项目（62001394、61871325）和国家重点研发计划项目（2018AAA0102803）的部分支持。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Effi MVS翻译&lt;/h1&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;在本文中，我们提出了一种用于多视图立体的新颖的迭代动态成本量。 与其他作品相比，我们的成本量要轻得多，因此可以使用基于 2D 卷积的 GRU 进行处理。 值得注意的是，每一步GRU 的输出可进一</summary>
      
    
    
    
    <category term="基于深度学习的多视角立体匹配技术" scheme="http://outbreak-sen.github.io/categories/%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%A4%9A%E8%A7%86%E8%A7%92%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="MVS" scheme="http://outbreak-sen.github.io/tags/MVS/"/>
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>colmap介绍和使用</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/colmap%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/colmap%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/</id>
    <published>2025-02-09T08:12:29.000Z</published>
    <updated>2025-02-09T08:12:59.310Z</updated>
    
    <content type="html"><![CDATA[<h1>colmap官方教程的笔记</h1><h2 id="需要cuda才能稠密重建-否则只能稀疏重建">需要CUDA才能稠密重建，否则只能稀疏重建</h2><p><a href="https://blog.csdn.net/weixin_44120025/article/details/123769174">Colmap论文——《Structure-from-Motion Revisited》论文阅读笔记</a></p><h2 id="tutorial">Tutorial</h2><p>传统上，基于图像的3D重建首先使用“运动结构Structure-from-Motion”来恢复场景的稀疏表示和输入图像的相机姿态。然后，此输出用作“多视图立体Multi-View Stereo”的输入，以恢复场景的密集表示。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/path/to/project/...</span><br><span class="line">+── images</span><br><span class="line">│   +── image1.jpg</span><br><span class="line">│   +── image2.jpg</span><br><span class="line">│   +── ...</span><br><span class="line">│   +── imageN.jpg</span><br><span class="line">+── database.db</span><br><span class="line">+── project.ini</span><br></pre></td></tr></table></figure><h3 id="重建的过程">重建的过程</h3><ul><li><p>Structure-from-Motion</p><ul><li>是将3D结构从投影重建为一系列图像的过程。输入是从不同视点拍摄的同一对象的一组重叠图像。输出是物体的三维重建，以及所有图像的重建的内在和外在相机参数。</li><li>通常，“运动结构”系统将此过程分为三个阶段： 特征检测与提取 特征匹配和几何验证 结构和运动重建</li><li>为了更好的重建需要：<ul><li>捕捉纹理良好的图像。如果场景本身没有包含足够的纹理，可以放置其他背景对象，如海报等。</li><li>在相似的照明条件下拍摄图像。避免高动态范围的场景（例如，有阴影的阳光照片或透过门/窗的照片）。避免在有光泽的表面上出现镜面反射。 拍摄具有高度视觉重叠的图像</li><li>确保每个对象至少在3张图像中可见——图像越多越好。 从不同的视角拍摄图像。不要仅通过旋转相机从同一位置拍摄图像，例如，在每次拍摄后走几步。同时，尽量从相对相似的角度获得足够的图像。请注意，更多的图像并不一定更好，并且可能导致重建过程缓慢。如果使用视频作为输入，请考虑对帧速率进行下采样。</li></ul></li></ul></li><li><p>Multi-View Stereo</p><ul><li>用SfM的输出来计算图像中每个像素的深度和/或法线信息。3D中多个图像的深度图和法线图的融合然后产生场景的密集点云。结合融合点云的深度和法线信息，利用泊松表面重建算法可以恢复场景的3D表面几何形状。</li></ul></li><li><p>Feature Detection and Extraction</p><ul><li>首先决定使用的内部摄影机模型，可以从嵌入的EXIF信息中自动提取信息然后在大型相机模型数据库中查找相机规格，也可以手动指定固有参数</li><li>如果您的所有图像都是由相同的物理相机以相同的缩放因子拍摄的，建议在所有图像之间共享内部信息。</li><li>如果在所有图像之间共享相同的相机型号，但并非所有图像都具有相同的大小或EXIF焦距，则程序将不正常地退出。</li><li>可以从图像中检测和提取新SIFT特征，也可以从文本文件中导入现有特征，如果导入现有功能，则每张图像旁边都必须有一个文本文件（例如/path/to/image1.jpg和/path/to/image1.jpg.txt）。</li><li>按照惯例，图像的左上角具有坐标（0，0），最左上角像素的中心具有坐标（0.5，0.5）</li></ul></li><li><p>特征匹配与几何验证</p><ul><li>找到不同图像中特征点之间的对应关系。</li><li>多种匹配方法：<ul><li>穷举<strong>Exhaustive</strong>匹配：像数量相对较低（数百张），则这种匹配模式应该足够快，并产生最佳的重建结果。</li><li>顺序<strong>Sequential</strong> 匹配：如果图像是按顺序采集的，例如通过摄像机采集，则此模式非常有用。在这种情况下，连续帧具有视觉重叠，并且不需要完全匹配所有图像对。</li><li>词汇树<strong>Vocabulary Tree</strong>匹配：在这种匹配模式中，使用具有空间重新排序的词汇树，将每个图像与其视觉上最近的邻居进行匹配。这是大型图像集合（数千个）的推荐匹配模式。这需要一个预先训练好的词汇树。</li><li>空间<strong>Spatial</strong> 匹配：这种匹配模式将每个图像与其空间上最近的邻居进行匹配。空间位置可以在数据库管理中手动设置。默认情况下，COLMAP还会从EXIF中提取GPS信息，并将其用于空间最近邻搜索。</li><li>传递<strong>Transitive</strong>匹配：如果图像A与图像B匹配并且B与C匹配，则该匹配器尝试直接将A与C匹配。</li><li>自定义<strong>Custom</strong> 匹配：此模式允许指定单个图像对进行匹配或导入单个特征匹配。要指定图像对，必须为文本文件提供每行一个图像对：</li></ul></li><li>详尽匹配的预期时间从几十张图像的几分钟到数百张图像的几个小时，再到数千张图像的数天或数周。</li></ul></li><li><p>稀疏重建</p><ul><li>COLMAP首先将所有从数据库中提取的数据加载到存储器中，并从初始图像对中对重建进行种子化。然后，通过注册新图像和三角测量新点来逐步扩展场景。</li></ul></li><li><p>导入和导出</p><ul><li>建议以COLMAP的数据格式导出重建，方法是选择“文件”&gt;“导出”导出当前查看的模型，或选择“文件&gt;全部导出”导出所有重建的模型。使用重建的摄影机、图像和点的单独文本文件将模型导出到选定文件夹中。当以COLMAP的数据格式导出时，您可以重新导入重建，以便以后进行可视化、图像不失真，或者从它停止的地方继续现有的重建。要导入模型，请选择“文件”&gt;“导入”，然后选择导出文件夹路径。</li><li>也可以通过选择“文件”&gt;“导出为…”以各种其他格式导出模型，如Bundler、VisualSfM 1、PLY或VRML。</li></ul></li><li><p>密集重建</p><ul><li><p>为所有注册图像生成深度图和法线图，将深度图和法向图融合为具有法线信息的密集点云，并最终使用Poisson或Delaunay重建从融合的点云中估计密集表面。</p></li><li><p>点云的重建法线不能在COLMAP中直接可视化，但例如在Meshlab中，通过启用“渲染&gt;显示法线/曲率”（Render&gt;Show Normal/Curvature）。同样，重建的密集表面网格模型必须使用外部软件进行可视化。</p></li><li><p>除了内部密集重建功能外，COLMAP还导出到其他几个密集重建库，如CMVS/PMVS或CMP-MVS。请选择“附加”&gt;“无失真图像”（Extras &gt; Undistort images），然后选择适当的格式。输出文件夹包含重建图像和未失真图像。此外，这些文件夹还包含用于执行密集重建的示例shell脚本。要运行PMVS2，请执行以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./path/to/pmvs2 /path/to/undistortion/folder/pmvs/ option-all</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="数据格式">数据格式</h2><ul><li><p>COLMAP将所有提取的信息存储在一个SQLite数据库文件中。可以使用COLMAP  GUI中的数据库管理工具包、提供的C++数据库API（请参阅src/COLMAP/scene/database.h）或您选择的脚本语言（请参阅scripts/python/database.py），该数据库包含以下表格：</p><ul><li><p>cameras：相机和图像之间的关系是1比N</p></li><li><p>images</p></li><li><p>keypoints：关键点被存储为前两列分别是图像中的X和Y位置float32二进制。第三列是特征的比例，第四列是特征方向（根据SIFT约定）</p></li><li><p>descriptors：描述符被存储为行主uint8二进制Blob，其中每一行描述关键点表中相应条目的特征外观，行表指定每个图像检测到的特征数量</p></li><li><p>matches：特征匹配将其输出存储在匹配表中</p></li><li><p>two_view_geometries：几何验证存储在two_view_geometries表中</p></li></ul></li></ul><h2 id="相机模型分类">相机模型分类</h2><ul><li>SIMPLE_PINHOLE，PINHOLE：如果您的图像事先没有失真，请使用这些相机模型。它们分别使用一个和两个焦距参数。</li><li>IMPLE_RADIAL，RADIAL：如果内部未知，并且每张图像都有不同的相机校准，例如，在互联网照片的情况下，这应该是选择的相机型号。这两个模型都是OPENCV模型的简化版本，仅分别用一个和两个参数对径向畸变效应进行建模。</li><li>OPENCV，FULL_OPENCV：如果事先知道校准参数，请使用这些相机模型。<ul><li>SIMPLE_RADIAL_FISHEEYE、RADIAL_FISHEEYE、OPENCV_FISHEEY、FOV、THIN_PRISM_FISHEYE：将这些相机模型用于鱼眼镜头·</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;colmap官方教程的笔记&lt;/h1&gt;
&lt;h2 id=&quot;需要cuda才能稠密重建-否则只能稀疏重建&quot;&gt;需要CUDA才能稠密重建，否则只能稀疏重建&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_44120025/article/d</summary>
      
    
    
    
    <category term="传统图形学" scheme="http://outbreak-sen.github.io/categories/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
    <category term="SFM" scheme="http://outbreak-sen.github.io/tags/SFM/"/>
    
    <category term="colmap" scheme="http://outbreak-sen.github.io/tags/colmap/"/>
    
  </entry>
  
  <entry>
    <title>HuggingFace的模型和数据集dataset</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/HuggingFace%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/HuggingFace%E7%9A%84%E4%BD%BF%E7%94%A8/</id>
    <published>2025-02-09T08:10:15.000Z</published>
    <updated>2025-03-19T09:12:40.069Z</updated>
    
    <content type="html"><![CDATA[<h1>HuggingFace的模型和数据集dataset</h1><p>微调数据集：wikitext-103-v1</p><p>模型：BigBirdPegasusForCausalLM</p><h2 id="如何下载模型和数据集并调用">如何下载模型和数据集并调用</h2><p>这里的模型和数据集是需要在huggingface上找到专门的名称的，然后有多种下载方法，默认会下载到.cache/huggingface/hub/,但是后面.cache可能会被清空。加载的时候，直接传入地址即可</p><ol><li><p>通过 huggingface model hub 网页的下载按钮进行下载。模型项目页的 <code>Files</code> 栏中可以获取文件的下载链接。<strong>无需登录</strong>直接点击下载</p></li><li><p>通过 huggingface 的 huggingface_hub 工具进行下载</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pip install huggingface_hub</span><br><span class="line">huggingface-cli download internlm/internlm2-chat-7b</span><br><span class="line"># 但是直接这么下载还是网络超时，所以使用镜像</span><br><span class="line">python -m pip install huggingface_hub</span><br><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line">huggingface-cli download --resume-download gpt2 --local-dir gpt2</span><br><span class="line">可选参数 --resume-download （已废弃）现在默认断点续传</span><br><span class="line">可选参数 --local-dir-use-symlinks False 因为huggingface的工具链默认会使用符号链接来存储下载的文件，导致--local-dir指定的目录中都是一些“链接文件”，真实模型则存储在~/.cache/huggingface下，如果不喜欢这个可以用 --local-dir-use-symlinks False取消这个逻辑。 但是这样的话每次调用的时候都必须输入绝对路径了。</span><br><span class="line">huggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitext</span><br></pre></td></tr></table></figure></li><li><p>使用 huggingface 的 transformers 库实例化模型进而将模型下载到缓存目录。就是说写代码什么时候需要什么时候下载，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from transformers import AutoTokenizer, AutoModelForCausalLM</span><br><span class="line">import os</span><br><span class="line"># 设置 HF_ENDPOINT 环境变量</span><br><span class="line">os.environ[&quot;HF_ENDPOINT&quot;] = &quot;https://hf-mirror.com&quot;</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(&quot;/home/&#123;username&#125;/huggingface/internlm2-chat-7b&quot;, trust_remote_code=True)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(&quot;/home/&#123;username&#125;/huggingface/internlm2-chat-7b&quot;, torch_dtype=torch.float16, trust_remote_code=True).cuda()</span><br></pre></td></tr></table></figure></li><li><p>使用**<a href="https://gist.github.com/padeoe/697678ab8e528b85a2a7bddafea1fa4f">hfd</a>** 是国人开发的 huggingface 专用下载工具，基于成熟工具 <code>aria2</code>，可以做到稳定高速下载不断线。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://hf-mirror.com/hfd/hfd.shchmod a+x hfd.sh</span><br><span class="line">chmod a+x hfd.sh</span><br><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line">./hfd.sh gpt2</span><br><span class="line">./hfd.sh wikitext --dataset</span><br></pre></td></tr></table></figure></li></ol><h2 id="dataset库的使用">Dataset库的使用</h2><p>Dataset库其实也是huggingface的，维护了很多数据集</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">pip install datasets</span><br><span class="line">import os #据说这样可以开启代理 </span><br><span class="line">os.environ[&#x27;HTTP_PROXY&#x27;] = &#x27;http://127.0.0.1:7890&#x27;</span><br><span class="line">os.environ[&#x27;HTTPS_PROXY&#x27;] = &#x27;http://127.0.0.1:7890&#x27;</span><br><span class="line">from datasets import load_dataset</span><br><span class="line">ds = load_dataset(&quot;fancyzhx/ag_news&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看数据集的组成，用feature，然后可以看到分为text和每个text的label，这是一个文本分类任务</span><br><span class="line">ds[&quot;train&quot;].features</span><br><span class="line"># &#123;&#x27;text&#x27;: Value(dtype=&#x27;string&#x27;, id=None),&#x27;label&#x27;: ClassLabel(names=[&#x27;World&#x27;, &#x27;Sports&#x27;, &#x27;Business&#x27;, &#x27;Sci/Tech&#x27;], id=None)&#125;</span><br><span class="line"></span><br><span class="line"># 直接这样也可以输出ds的构成，是分为train和test</span><br><span class="line">ds</span><br><span class="line">print(ds)</span><br><span class="line"># DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 120000</span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;, &#x27;label&#x27;],</span><br><span class="line">        num_rows: 7600</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>filter</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 传入一个lamda函数，其中要求数据的label为2</span><br><span class="line">tmp = ds[&quot;train&quot;].filter(lambda x: x[&quot;label&quot;] == 2)</span><br><span class="line">print(tmp)</span><br><span class="line">print(tmp[0])</span><br></pre></td></tr></table></figure></li><li><p>map，对于数据集中的分类进行修改，或者对于内容进行扩充</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">prompt_cls = &quot;&quot;&quot;你是文本分类领域的专家，请你给下述文本分类，把它分到下述类别中：</span><br><span class="line">* World</span><br><span class="line">* Sports</span><br><span class="line">* Business</span><br><span class="line">* Science / Technology&#x27;</span><br><span class="line"></span><br><span class="line">text是待分类的文本，label是文本的类别：</span><br><span class="line">text: &#123;text&#125;</span><br><span class="line">label: </span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"># 这个lamda函数定义了一个把prompt_cls中的text部分替换为输入的text，也可以是text</span><br><span class="line">def trans2llm(item):</span><br><span class="line">    item[&quot;text&quot;] = prompt_cls.format(text=item[&quot;text&quot;])</span><br><span class="line">    return item</span><br><span class="line"></span><br><span class="line">tmp = ds[&quot;test&quot;].map(trans2llm)</span><br><span class="line">print(tmp[0])</span><br></pre></td></tr></table></figure></li><li><p>select 数据集采样，随机采样、下标采样等；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ds[&quot;train&quot;].select([0, 10, 20, 30, 40, 50])# 需要加下标</span><br><span class="line"># 如果想要随机取1000个</span><br><span class="line">import random  </span><br><span class="line">numbers = list(range(1000))</span><br><span class="line">random_numbers = random.sample(numbers, 100)</span><br><span class="line">ds[&quot;train&quot;].select(random_numbers)</span><br></pre></td></tr></table></figure></li><li><p>concatenate_datasets数据集拼接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from datasets import concatenate_datasets</span><br><span class="line">dataset = concatenate_datasets([true_dataset, false_dataset])</span><br></pre></td></tr></table></figure></li><li><p>train_test_split区分训练集和测试集，并且自动加一个纬度划分为test和train</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dataset.train_test_split(train_size=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;wikitext&quot;</span>, <span class="string">&quot;wikitext-103-v1&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(dataset)</span><br><span class="line">dataset = dataset.select(<span class="built_in">range</span>(<span class="number">1000</span>))  <span class="comment"># Use a subset for quick testing</span></span><br><span class="line">train_test_split = dataset.train_test_split(test_size=<span class="number">0.1</span>)</span><br><span class="line"><span class="built_in">print</span>(train_test_split)</span><br><span class="line">train_dataset = train_test_split[<span class="string">&#x27;train&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(train_dataset)</span><br><span class="line">eval_dataset = train_test_split[<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(eval_dataset)</span><br><span class="line"><span class="built_in">print</span>(train_dataset[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;text&#x27;],</span><br><span class="line">    num_rows: 1801350</span><br><span class="line">&#125;)</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;],</span><br><span class="line">        num_rows: 900</span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [&#x27;text&#x27;],</span><br><span class="line">        num_rows: 100</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;text&#x27;],</span><br><span class="line">    num_rows: 900</span><br><span class="line">&#125;)</span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;text&#x27;],</span><br><span class="line">    num_rows: 100</span><br><span class="line">&#125;)</span><br><span class="line">&#123;&#x27;text&#x27;: &quot; The ship was assigned to the Austro @-@ Hungarian Fleet &#x27;s 1st Battle Squadron after her 1911 commissioning . In 1912 , Zrínyi and her two sister ships conducted two training cruises into the eastern Mediterranean Sea . On the second cruise into the Aegean Sea , conducted from November to December , Zrínyi and her sister ships were accompanied by the cruiser SMS Admiral Spaun and a pair of destroyers . After returning to Pola , the entire fleet mobilized for possible hostilities , as tensions flared in the Balkans . \n&quot;&#125;</span><br></pre></td></tr></table></figure></li><li><p>add_column添加属性列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset[&quot;train&quot;] = dataset[&quot;train&quot;].add_column(&quot;index&quot;, list(range(786701)))</span><br></pre></td></tr></table></figure></li><li><p>rename_column属性列重命名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset[&quot;train&quot;] = dataset[&quot;train&quot;].rename_column(&quot;idx&quot;, &quot;file_sent_index&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h2 id="train-loss">train loss</h2><p>对比微调训练的loss变化</p><table><thead><tr><th>epoch</th><th>mindnlp+mindspore</th><th>transformer+torch（4060）</th></tr></thead><tbody><tr><td>1</td><td>2.9176</td><td>8.7301</td></tr><tr><td>2</td><td>2.79</td><td>8.1557</td></tr><tr><td>3</td><td>2.593</td><td>7.7516</td></tr><tr><td>4</td><td>2.4875</td><td>7.5017</td></tr><tr><td>5</td><td>2.3831</td><td>7.2614</td></tr><tr><td>6</td><td>2.2631</td><td>7.0559</td></tr><tr><td>7</td><td>2.2369</td><td>6.8405</td></tr><tr><td>8</td><td>2.1732</td><td>6.7297</td></tr><tr><td>9</td><td>2.1717</td><td>6.7136</td></tr><tr><td>10</td><td>2.1833</td><td>6.6279</td></tr></tbody></table><h2 id="eval-loss">eval loss</h2><p>对比评估得分</p><table><thead><tr><th>epoch</th><th>mindnlp+mindspore</th><th>transformer+torch（4060）</th></tr></thead><tbody><tr><td>1</td><td>2.6390955448150635</td><td>6.3235931396484375</td></tr></tbody></table><p># 测试样例（包含真实标签）</p><p>test_data = [</p><p>​    {“text”: “I am a little confused on all of the models of the 88-89 bonnevilles.\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\ndifferences are far as features or performance. I am also curious to\nknow what the book value is for prefereably the 89 model. And how much\nless than book value can you usually get them for. In other words how\nmuch are they in demand this time of year. I have heard that the mid-spring\nearly summer is the best time to buy.”</p><p>​     , “true_label”: “rec.autos”},</p><p>​    {“text”: “I’m not familiar at all with the format of these X-Face:thingies, but\nafter seeing them in some folks’ headers, I’ve <em>got</em> to <em>see</em> them (and\nmaybe make one of my own)!\n\nI’ve got dpg-viewon my Linux box (which displays uncompressed X-Faces)\nand I’ve managed to compile [un]compface too… but now that I’m <em>looking</em>\nfor them, I can’t seem to find any X-Face:'s in anyones news headers!  :-(\n\nCould you, would you, please send me your X-Face:header\n\nI know* I’ll probably get a little swamped, but I can handle it.\n\n\t…I hope.”</p><p>​     , “true_label”: “comp.windows.x”},</p><p>​    {“text”: “\nIn a word, yes.\n”</p><p>​        , “true_label”: “alt.atheism”},</p><p>​    {“text”: “\nThey were attacking the Iraqis to drive them out of Kuwait,\na country whose citizens have close blood and business ties\nto Saudi citizens.  And me thinks if the US had not helped out\nthe Iraqis would have swallowed Saudi Arabia, too (or at \nleast the eastern oilfields).  And no Muslim country was doing\nmuch of anything to help liberate Kuwait and protect Saudi\nArabia; indeed, in some masses of citizens were demonstrating\nin favor of that butcher Saddam (who killed lotsa Muslims),\njust because he was killing, raping, and looting relatively\nrich Muslims and also thumbing his nose at the West.\n\nSo how would have <em>you</em> defended Saudi Arabia and rolled\nback the Iraqi invasion, were you in charge of Saudi Arabia???\n\n\nI think that it is a very good idea to not have governments have an\nofficial religion (de facto or de jure), because with human nature\nlike it is, the ambitious and not the pious will always be the\nones who rise to power.  There are just too many people in this\nworld (or any country) for the citizens to really know if a \nleader is really devout or if he is just a slick operator.\n\n\nYou make it sound like these guys are angels, Ilyess.  (In your\nclarinet posting you edited out some stuff; was it the following???)\nFriday’s New York Times reported that this group definitely is\nmore conservative than even Sheikh Baz and his followers (who\nthink that the House of Saud does not rule the country conservatively\nenough).  The NYT reported that, besides complaining that the\ngovernment was not conservative enough, they have:\n\n\t- asserted that the (approx. 500,000) Shiites in the Kingdom\n\t  are apostates, a charge that under Saudi (and Islamic) law\n\t  brings the death penalty.  \n\n\t  Diplomatic guy (Sheikh bin Jibrin), isn’t he Ilyess?\n\n\t- called for severe punishment of the 40 or so women who\n\t  drove in public a while back to protest the ban on\n\t  women driving.  The guy from the group who said this,\n\t  Abdelhamoud al-Toweijri, said that these women should\n\t  be fired from their jobs, jailed, and branded as\n\t  prostitutes.\n\n\t  Is this what you want to see happen, Ilyess?  I’ve\n\t  heard many Muslims say that the ban on women driving\n\t  has no basis in the Qur’an, the ahadith, etc.\n\t  Yet these folks not only like the ban, they want\n\t  these women falsely called prostitutes?  \n\n\t  If I were you, I’d choose my heroes wisely,\n\t  Ilyess, not just reflexively rally behind\n\t  anyone who hates anyone you hate.\n\n\t- say that women should not be allowed to work.\n\n\t- say that TV and radio are too immoral in the Kingdom.\n\nNow, the House of Saud is neither my least nor my most favorite government\non earth; I think they restrict religious and political reedom a lot, among\nother things.  I just think that the most likely replacements\nfor them are going to be a lot worse for the citizens of the country.\nBut I think the House of Saud is feeling the heat lately.  In the\nlast six months or so I’ve read there have been stepped up harassing\nby the muttawain (religious police—<em>not</em> government) of Western women\nnot fully veiled (something stupid for women to do, IMO, because it\nsends the wrong signals about your morality).  And I’ve read that\nthey’ve cracked down on the few, home-based expartiate religious\ngatherings, and even posted rewards in (government-owned) newspapers\noffering money for anyone who turns in a group of expartiates who\ndare worship in their homes or any other secret place. So the\ngovernment has grown even more intolerant to try to take some of\nthe wind out of the sails of the more-conservative opposition.\nAs unislamic as some of these things are, they’re just a small\ntaste of what would happen if these guys overthrow the House of\nSaud, like they’re trying to in the long run.\n\nIs this really what you (and Rached and others in the general\nwest-is-evil-zionists-rule-hate-west-or-you-are-a-puppet crowd)\nwant, Ilyess?\n”</p><p>​     , “true_label”: “talk.politics.mideast”}</p><p>]</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;HuggingFace的模型和数据集dataset&lt;/h1&gt;
&lt;p&gt;微调数据集：wikitext-103-v1&lt;/p&gt;
&lt;p&gt;模型：BigBirdPegasusForCausalLM&lt;/p&gt;
&lt;h2 id=&quot;如何下载模型和数据集并调用&quot;&gt;如何下载模型和数据集并调用&lt;/h2</summary>
      
    
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="huggingface" scheme="http://outbreak-sen.github.io/tags/huggingface/"/>
    
  </entry>
  
  <entry>
    <title>GAN生成对抗模型入门</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/</id>
    <published>2025-02-09T08:10:15.000Z</published>
    <updated>2025-02-11T01:53:32.114Z</updated>
    
    <content type="html"><![CDATA[<h1>GAN笔记</h1><h2 id="简介">简介</h2><p>GAN的思想来自零和博弈理论，由两个部分组成，一个是生成器Generator，随机接收一个随机噪声来生成图像。一个是鉴别器Discriminator，判断一张图像是不是“真实的”，输入是一张图像，输出是该图像为真实图像的概率，介于0-1之间，概率值越小认为生成图像不真实的可能性越大。生成器的目标是通过生成接近真实的图像来欺骗判别器，而判别器的目标是尽量辨别出生成器生成的假图像和真实图像的区别。</p><p>自编码器（Auto-Encoder)以及变分自编码器（Variational  Auto-Encoder)都是典型的生成器。输入通过Encoder编码成code，然后code通过Decoder重建原图，其中自编码器中的Decoder就是生成器，code可随机取值，产生不同的输出。 <strong>自编码器</strong>是一种能够通过无监督学习，对输入数据进行特征提取，学习到数据的抽象表示，称为编码过程，编码结果往往维度远小于输入数据，自编码器可以用于降维和特征提取，</p><p><strong>变分自编码器</strong>（Variational auto-encoder，VAE）是一类重要的生成模型（generative model），它于2013年由Diederik P.Kingma和Max Welling提出，是自动编码器的升级版，</p><p>生成器和判别器都可以自我训练，但生成器自我训练产生的图像是模糊的，无法产生逼近真实图像的假图像</p><p>而判别器也可以自我训练，给定一个输入图像，输出一个概率置信度，介于0-1之间</p><h2 id="发展">发展</h2><p><a href="https://cloud.tencent.com/developer/article/1645877">参考</a></p><ul><li><p>GAN（Generative Adversarial Network）生成对抗网络，由Ian Goodfellow在2014年提出。</p><ul><li>《Conditional Generative Adversarial Nets》2014</li><li>为MNIST手写数码数据集、CIFAR-10小件图片数据集、多伦多人像数据集生成新案例。</li></ul></li><li><p>CGAN(Conditional Generative Adversarial Nets，可用条件约束的对抗神经网络)</p><ul><li>《Conditional Generative Adversarial Nets》</li><li>一个假设的数据分布，但是这样自由散漫的方式对于较大的图像就不太可控了，CGAN方法<strong>提出了一种带有条件约束的GAN，将额外信息y输送给判别模型和生成模型,作为输入层的一部分,从而实现条件GAN，是在Mnist数据集上以类别标签为条件变量，生成指定类别的图像，把纯无监督的GAN变成有监督的模型。</strong></li><li>Conditional GANs 是最先进的GAN的核心主题。这篇论文展示了如何整合数据的标签，从而实现更稳定的GAN训练，对于关注图像到图像或文本到图像的论文尤其重要。</li></ul></li><li><p>DCGAN(深度卷积GAN)</p><ul><li>《unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》</li><li>通过卷积的方式将100维的随机噪声输入映射成一张图像，使用卷积层代替了全连接层，采用带步长的卷积代替上采样，更好的提取图像特征，判别器和生成器对称存在，极大的提升了GAN训练的稳定性和生成结果的质量。判别器中采用leakyRELU而不是RELU来防止梯度稀疏，而生成器仍然采用RELU，但输出层采用tanh。并没有从根本上解决GAN训练不稳定的问题，往往是训练一个多次，训练另一个一次。</li><li><strong>展示了卷积层与 GAN 是怎样组合的</strong>，还提供了其他一系列其他的参考架构。论文还讨论了诸如<a href="https://so.csdn.net/so/search?q=%E5%8F%AF%E8%A7%86%E5%8C%96&amp;spm=1001.2101.3001.7020">可视化</a>GAN特征，潜在空间插值，用鉴别器特征训练分类器，结果评价等方面。DCGAN 论文是必读的 GAN 论文，因为它的结构非常清晰，代码容易使用，可以马上用在您的 GAN 开发中。</li></ul></li><li><p>Pix2Pix</p><ul><li>《Image-to-Image Translation with Conditional Adversarial Networks》</li><li><strong>Pix2Pix是另一种图像到图像转换的GAN模型</strong>。该框架使用配对的训练样本，并在GAN模型中使用许多不同的配置。PatchGAN观察图像的70 x 70区域，以确定它们是真实的还是虚假的，而不是查看整个图像。该模型还提出了一个有趣的U-Net风格生成器结构，以及在生成器模型中使用ResNet样式的跳跃连接。有许多很酷的应用，例如边缘图到照片般真实的图像。</li><li>生成高质量的图像，并且可以通过人为控制生成的图像。</li></ul></li><li><p>CycleGAN</p><ul><li>《Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks》朱俊彦等人于2017年发表题为《使用一致循环生成网络进行非配对图像转换》的论文</li><li><strong>讨论了图像到图像的迁移问题</strong>而不是随机向量的图像合成问题。CycleGAN可以更具体地处理没有配对的图像转换的训练样本。因为循环一致性损失公式的优雅以及如何稳定GAN训练的方式。有许多有趣的程序使用CycleGAN，例如超分辨率，风格迁移，让马变为斑马。</li><li><strong>pix2pix对训练样本要求较高，需要成对的数据集，而这种样本的获取往往需要耗费很大精力。CycleGAN恰巧解决了该问题，实现两个domain之间的转换，即只需要准备两种风格的数据集，让GAN去学习</strong>将domain X中的图片转换成domain Y的风格(不改变domain X原图中物体，仅仅实现风格转换)。</li></ul></li><li><p>StyleGAN</p><ul><li><p>A Style-Based Generator Architecture for Generative Adversarial Networks</p></li><li><p>对于discriminator，它的输入是一张图片，它需要去鉴别出这张图片是真实图片还是generator产生的图片，同时它还需要分辨出这张输入的图片来自于哪个domain(哪种风格)。对于generator，它有两个输入，分别是目标domain和输入图片，它的输出是一张符合目标domain风格的图片。</p></li><li><p>CycleGAN的优点是它可以实现跨域图像翻译，不需要大量的并行数据，并且可以处理不同分辨率的图像。CycleGAN的缺点是它的生成器网络结构相对简单，生成的图像质量可能不如StyleGAN高。</p><p>StyleGAN的优点是它可以生成高质量的图像，并且具有更好的控制性。StyleGAN的缺点是它需要大量的高质量数据进行训练，并且不能实现跨域图像翻译。</p></li></ul></li><li><p>StackGAN</p><ul><li>《Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks》</li><li>堆叠生成对抗网络（StackGan）非常独特，因为它是<strong>从自然语言文本到图像的转换</strong>。它非常类似于Conditional GANs和Progressively Growing GANs。StackGAN模型的工作方式类似于Progressively Growing GANs，因为它可以在多尺度上工作。StackGAN首先输出64 * 64的图像，然后将其作为先验信息生成256 * 256的图像。</li><li>第一阶段的GAN根据文字描述草绘出一张简单形状和基本颜色符合的低分辨率图片，第二阶段的GAN把第一阶段的结果和文字条件作为输入，生成具有照片真实感的高分辨率的图片。</li></ul></li><li><p>StarGAN</p><ul><li>《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》</li><li>有的时候我们可能希望图片能在n个domain当中互转，那依据CycleGAN的设计思路，理论上我们需要训练<img src="https://i-blog.csdnimg.cn/blog_migrate/0fada3075772b779cf7c96d2ecbbef5a.png" alt="img">个generato 。很明显这需要训练的generator太多了。那为了用更少的generator实现多个风格之间的互转，StarGAN被提出了。</li><li>鉴别器D 学习去辨别真实图像和生成图像，以及对图像进行所属域的分类（<em><strong>两个输出</strong></em>）。生成器接受图像和目标域标签（<em><strong>两个输入</strong></em>）</li></ul></li><li><p>BigGAN</p><ul><li>《Large Scale GAN Training for High Fidelity Natural Image Synthesis》</li><li>是ImageNet的当前最新技术。这种模型很难在本地机器上实现，并且模型中有许多组件，如自注意力，频谱归一化和带有投影鉴别器的cGAN，这些都在他们的论文中得到了很好的解释。而且论文对当前最新技术的基础论文进行了全面的概述。</li><li>《Large Scale GAN Training for High Fidelity Natural Image Synthesis》展现了用BigGAN技术生成合成照片的案例</li></ul></li><li><p>Omni-GAN</p><ul><li>《On the Secrets of cGANs and Beyond》</li><li>条件生成对抗网络 (cGAN) 是生成高质量图像的强大工具，但现有方法大多性能不令人满意或存在模式坍塌的风险。OmniGAN，是 cGAN 的一种变体，针对训练合适判别器的问题。关键是要确保判别器接受强监督并适度正则化以避免坍塌。</li></ul></li><li><p>infinite conditional GANs 或 MIC-GANs</p><ul><li>《Unsupervised Image Generation with Infifinite Generative Adversarial Networks》</li><li>旨在用简约的先验知识生成图像。</li></ul></li><li><p>WGAN(Wasserstein GAN)</p><ul><li>《Wasserstein GAN》</li><li>将原来的二分类任务变为回归任务，用最小二乘损失函数来优化。从<strong>损失函数</strong>的角度对GAN进行了改进，理论上给出了GAN训练不稳定的原因，提出的<strong>Wassertein距离</strong>来衡量数据分布和真实数据分布之间的距离，理论上解决了训练不稳定的问题。也解决了<strong>模式崩溃问题（collapse mode）</strong>（生成器倾向于生成一些有把握但相似的图片，而不敢轻易地尝试去生成没把握的新图片，从而缺乏多样性的情况），使得生成器生成结果更加多样。</li></ul></li><li><p>WGAN-GP(WGAN的改进版本)</p><ul><li>《Improved Training of Wasserstein GANs》</li><li>WGAN有时候也会伴随样本质量低、难以收敛等问题，WGAN-GP是WGAN的改进版</li></ul></li><li><p>LSGAN(<strong>最小二乘GAN</strong>)</p><ul><li>《Least Squares Generative Adversarial Networks》</li><li>以交叉熵作为损失，会使得生成器不会再优化那些被判别器识别为真实图片的生成图片，因为生成器已经完成我们为它设定的目标——尽可能地混淆判别器，交叉熵损失已经很小了，而最小二乘就不一样了，要想最小二乘损失比较小，在混淆判别器的前提下还得让生成器把距离决策边界比较远的生成图片拉向决策边界。</li></ul></li><li><p>BEGAN（Boundary Equilibrium GAN）</p><ul><li>《BEGAN: Boundary Equilibrium Generative Adversarial Networks》</li><li>边界均衡GAN，基于<strong>均衡思想</strong>的改进，其不需要训练的技巧，使用标准的训练步骤就可以快速稳定的收敛，BEGAN使用了<strong>自动编码器（auto-encoder）作为判别器</strong>，判别器的输入是图片，输出是经过编码解码后的图片，使用重构误差来衡量样本是生成的还是真实的</li></ul></li></ul><h1>应用</h1><p><a href="https://cloud.tencent.com/developer/article/2011384">参考</a></p><ul><li>《Detail Me More: Improving GAN’s photo-realism of complex scenes》</li><li>如果在场景的特定区域检测到或需要一盏灯，代理会为该图像块分配一个细粒度的灯判别器。这可以促使生成器学习灯的形状和阴影模型。在生成对抗网络（GAN）中添加一个“代理”模块来解决这个问题。代理任务是在图像区域中调解多个判别器的使用。</li></ul><h3 id="图像编辑-基于stylegan"><strong>图像编辑-基于StyleGAN</strong></h3><ul><li>StyleCLIP<ul><li>《Text-Driven Manipulation of StyleGAN Imagery》</li><li>利用最近引入的对比语言图像预训练 (CLIP) 模型，以便为 StyleGAN <a href="https://cloud.tencent.com/product/tiia?from_column=20065&amp;from=20065">图像处理</a>开发一个基于文本的界面。提出一种将文本映射到 StyleGAN 风格空间中的方法，实现交互式文本驱动的图像操作。</li></ul></li></ul><h3 id="图像转换">图像转换</h3><ul><li>SPatchGAN<ul><li>《SPatchGAN: A Statistical Feature Based Discriminator for Unsupervised Image-to-Image Translation》</li><li>对于无监督的图像到图像转换，提出一种判别器架构专注于统计特征而不是单个patch感受野。与现有方法对生成器施加越来越多的约束不同，方法通过简化框架促进了形状变形并增强细节。</li></ul></li></ul><h3 id="文字生成图像">文字生成图像</h3><ul><li><strong>DAE-GAN</strong><ul><li>《DAE-GAN: Dynamic Aspect-aware GAN for Text-to-Image Synthesis》</li><li>文本转换生成图像是指，从给定的文本描述中生成图像，保持照片真实性和语义一致性。此前方法通常使用句子特征嵌入去生成初始图像，然后用细粒度的词特征嵌入对初始效果进行细化。</li><li>本文提出一种动态 Aspect-awarE GAN (DAE-GAN)，从多个粒度（包括句子级、词级和aspect级）全面地表示文本信息。</li></ul></li></ul><h3 id="风格迁移">风格迁移</h3><ul><li>DRB-GAN<ul><li>《 DRB-GAN: A Dynamic ResBlock Generative Adversarial Network for Artistic Style Transfer》</li><li>提出一种用于艺术风格迁移的动态 ResBlock 生成对抗网络（DRB-GAN）。风格码被建模为连接风格编码网络和迁移网络的动态 ResBlocks 的共享参数。</li><li>在编码网络中，融入了风格的类感知注意机制；在迁移网络中，多个 Dynamic ResBlocks 来整合风格码和提取的 CNN 语义特征，然后输入到空间实例归一化（SWLIN）解码器，实现艺术风格迁移。</li></ul></li></ul><h3 id="动漫风格化">动漫风格化</h3><ul><li>AnimeGAN<ul><li>AnimeGAN仍然存在一些明显的问题，例如模型生成的图像中存在高频伪影。nime GAN由于使用了实例归一化，很容易产生高频伪影，这与styleGAN产生高频伪影的原因是一样的。AnimeGANv2使用与AnimeGAN相同的判别器，不同之处在于判别器使用层归一化而不是实例归一化。AnimeGANv2通过简单的改变网络中特征的归一化来防止高频伪影的产生。</li></ul></li><li>makeGirlsMoe<ul><li>《Towards the Automatic Anime Characters Creation with Generative Adversarial Networks》</li><li>还带一个网站https://make.girls.moe/#/</li></ul></li></ul><h3 id="图像编辑-人脸">图像编辑-人脸</h3><ul><li>latent-transformer<ul><li>《A Latent Transformer for Disentangled Face Editing in Images and Videos》</li><li>过 StyleGAN 生成器的潜在空间来编辑人脸属性，训练专用的潜在转换网络，并在损失函数中加入显式解耦和ID保留损失项。并将方法推广到视频。</li></ul></li></ul><h3 id="生成正面人像图片">生成正面人像图片</h3><ul><li>《人脸转正：使用全球及地方GAN感知合成拟真正面人像图片》</li></ul><h3 id="消除雨">消除雨</h3><ul><li>《使用条件性GAN消除图片中的雨》</li></ul><h3 id="生成人体新体态">生成人体新体态</h3><ul><li>《Pose Guided Person Image Generation》</li></ul><h3 id="面部老化">面部老化</h3><ul><li>《Face aging with conditional generative adversarial networks》<ul><li>Grigory Antipov等人于2017年发表了题为《使用条件性GAN进行面部老化处理》的论文。文中介绍了使用GAN生成不同年龄段人脸图片的方法。</li></ul></li></ul><h3 id="图片混合">图片混合</h3><ul><li>GP-GAN<ul><li>《GP-GAN: Towards Realistic High-Resolution Image Blending》</li><li>Huikai Wu等人于2017年发表了题为《GP-GAN：关于现实高保真照片的混合》文中展示了GAN在混合照片，尤其是混合田野、大山及其大型物体照片中的应用。</li></ul></li></ul><h3 id="图像恢复-超分">图像恢复-超分</h3><ul><li>Fourier Space Losses for Efficient Perceptual Image Super-Resolution<ul><li>许多超分辨率 (SR) 模型仅针对精度效果进行优化，模型庞大、缺乏效率。利用傅立叶空间监督损失来改进从丢失的高频 (HF) 内容，并设计直接在傅立叶域的判别器架构以更好地匹配目标 HF 分布。与最先进的感知 SR 方法 RankSRGAN 和 SRFlow 相比，分别快 2.4 倍和 48 倍。</li></ul></li></ul><h3 id="图像恢复-修复">图像恢复-修复</h3><ul><li><p>Context Encoders</p><ul><li>《Context Encoders: Feature Learning by Inpainting》</li><li>介绍了如何使用GAN的文本编码器进行图片修复或填充空缺，即填补图片中某块缺失的部分。</li></ul></li><li><p>WaveFill</p><ul><li>《WaveFill: A Wavelet-based Generation Network for Image Inpainting》</li><li>引进WaveFill，基于小波修复，将图像分解为多个频段，并分别明确地填充每个频段中的缺失区域。WaveFill 使用离散小波变换 (DWT)  分解图像，自然地保留空间信息。它将L1重建损失应用于分解的低频段，将对抗性损失应用于高频段，从而在完成空间域图像的同时有效地减轻频间冲突。</li></ul></li><li><p>CTSDG</p><ul><li>《Image Inpainting via Conditional Texture and Structure Dual Generation》</li><li>提出一种用于图像修复的新型双流网络，以耦合方式进行结构约束的纹理合成，以及纹理引导的结构重建，可以更好地相互利用以获得更合理的生成。</li></ul></li></ul><h3 id="图像外插值-图像延展">图像外插值-图像延展</h3><ul><li>SemIE<ul><li>《SemIE: Semantically-aware Image Extrapolation》</li><li>对于给定的图像，首先使用语义分割方法获得对象分割图；分割图被输入网络以计算外推语义分割和相应的全景分割图。输入图像和获得的分割图进一步用于生成最终的图像。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;GAN笔记&lt;/h1&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;GAN的思想来自零和博弈理论，由两个部分组成，一个是生成器Generator，随机接收一个随机噪声来生成图像。一个是鉴别器Discriminator，判断一张图像是不是“真实的”，输入是一张图像，输出是该</summary>
      
    
    
    
    <category term="深度学习" scheme="http://outbreak-sen.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="GAN生成对抗模型" scheme="http://outbreak-sen.github.io/tags/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>我的ubuntu环境配置方法</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/%E6%88%91%E7%9A%84ubuntu%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/%E6%88%91%E7%9A%84ubuntu%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95/</id>
    <published>2025-02-09T07:46:28.000Z</published>
    <updated>2025-02-09T07:46:46.920Z</updated>
    
    <content type="html"><![CDATA[<h1>Environment Installition</h1><p>20241101</p><p>[TOC]</p><h2 id="python3-8"><s>Python3.8</s></h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install software-properties-common</span><br><span class="line"><span class="built_in">sudo</span> add-apt-repository ppa:deadsnakes/ppa</span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install python3.8</span><br><span class="line"> <span class="built_in">ls</span> /usr/bin/python* <span class="comment">#查看已安装版本</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> /usr/bin/python3   <span class="comment"># 删除原来的软连接</span></span><br><span class="line">~~<span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/bin/python3.8 /usr/bin/python3~~ <span class="comment">#不要添加python3的软连接，终端打不开，需要进tty终端修复</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/bin/python3.8 /usr/bin/python <span class="comment">#添加python新的软连接</span></span><br><span class="line">python3 --version <span class="comment">#查看版本</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install python3-pip <span class="comment">#设置一下pip</span></span><br><span class="line"><span class="built_in">mkdir</span> ~/.pip&amp;&amp;<span class="built_in">cd</span> ~/.pip</span><br><span class="line"><span class="built_in">sudo</span> gedit pip.conf</span><br><span class="line"><span class="comment"># [global]</span></span><br><span class="line"><span class="comment"># index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span></span><br><span class="line"><span class="comment"># index-index-url = https://mirrors.aliyun.com/pypi/simple/</span></span><br><span class="line"><span class="comment"># [install]</span></span><br><span class="line"><span class="comment"># trusted-host =</span></span><br><span class="line"><span class="comment"># pypi.tuna.tsinghua.edu.cn</span></span><br><span class="line"><span class="built_in">sudo</span> pip3 config <span class="built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple <span class="comment">#或者</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装Anaconda之后默认python和python的版本会出现问题，系统将使用Anaconda的python作为默认python，所以，所以我出现了本地安装了python3.8和python3.10后但是默认python是3.7且无法通过软连接改变，所以需要在软连接下进行修改：</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/littlexiaoshuishui/article/details/82504880</span></span><br><span class="line"><span class="comment"># 暂时找到的方法是在某个终端echo $PATH然后重新通过以下命令赋值，其中删除Anaconda的部分</span></span><br><span class="line">PATH=/opt/ros/humble/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="搜狗拼音">搜狗拼音</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 语言中将汉语安装并提到第一位</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install -f </span><br><span class="line"><span class="built_in">sudo</span> apt install fcitx <span class="comment"># 设置语言从ibus到fcitx4</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> /usr/share/applications/fcitx.desktop /etc/xdg/autostart/#设置fcitx为自动开启</span><br><span class="line"><span class="built_in">sudo</span> dpkg -i sogoupinyin_4.0.1.2800_x86_64.deb </span><br><span class="line"><span class="built_in">sudo</span> apt install libqt5qml5 libqt5quick5 libqt5quickwidgets5 qml-module-qtquick2 libgsettings-qt1</span><br><span class="line">reboot</span><br><span class="line"><span class="comment"># 在右上角设置</span></span><br></pre></td></tr></table></figure><h2 id="kernel5-15"><s>Kernel5.15</s></h2><p>更换版本之后网卡丢失，所以不要降级内核了而启用docker，该部分已弃用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">uname -r #查看当前内核</span><br><span class="line">dpkg --get-selections | grep linux-image #查看可用内核</span><br><span class="line">sudo apt-get install linux-image-5.15-83 linux-headers-5.15-83 linux-image-extra-5.15-83 </span><br><span class="line">grep menuentry /boot/grub/grub.cfg #查看所有可用内核</span><br><span class="line">sudo gedit /etc/default/grub #更改默认内核</span><br><span class="line">sudo update-grub#更新内核文件</span><br><span class="line">reboot #查看是否更新成功</span><br><span class="line">sudo dpkg --purge linux-image-4.15.0-88-generic #卸载其他内核</span><br></pre></td></tr></table></figure><h2 id="nvidia">Nvidia</h2><p>据说现在deb安装，可以直接安装对应版本的nvudia driver，并且不会掉驱动</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 笔记本显示屏幕是核显</span></span><br><span class="line"><span class="comment"># 外接屏幕是独显</span></span><br><span class="line">lsmod | grep nouveau <span class="comment">#查看系统是否启用了nouveau显卡驱动，有内容输出，则说明nouveau已被启用</span></span><br><span class="line"><span class="built_in">sudo</span> vim /etc/modprobe.d/blacklist.conf</span><br><span class="line">    <span class="comment">#---save the following info into file blacklist.conf---</span></span><br><span class="line">    blacklist nouveau</span><br><span class="line">    blacklist lbm-nouveau</span><br><span class="line">    options nouveau modeset=0</span><br><span class="line">    <span class="built_in">alias</span> nouveau off</span><br><span class="line">    <span class="built_in">alias</span> lbm-nouveau off</span><br><span class="line">    <span class="comment">#---end of the info saved----</span></span><br><span class="line"><span class="built_in">sudo</span> update-initramfs -u <span class="comment"># 更新内核</span></span><br><span class="line">reboot <span class="comment">#查看是否更新成功</span></span><br><span class="line">lsmod | grep nouveau <span class="comment">#查看系统是否禁用了nouveau显卡驱动</span></span><br><span class="line">lshw -c video <span class="comment"># 查看显卡型号，在官网https://www.nvidia.cn/Download/index.aspx查找对应的驱动，如果内核不对那就是下载错了，需要下载最新版</span></span><br><span class="line"><span class="comment"># 如果发现编译失败，看一下vim /var/log/nvidia-installer.log，常见错误是使用了gcc11,不符合安装要求，要安装gcc12,不要把gcc卸载了</span></span><br><span class="line"><span class="built_in">sudo</span> apt install gcc-12# 但是更重要的是更新Gcc版本，基本上ubuntu都安装了gcc11和gcc12,所以关键是切换版本</span><br><span class="line"><span class="built_in">sudo</span> ./NVIDIA-Linux-x86_64-535.161.07.run -no-x-check <span class="comment">#安装驱动，并且取消x查看，要安装32适配库</span></span><br><span class="line">nvidia-smi <span class="comment"># nvidia驱动版本号和最大cuda版本，安装驱动后才有</span></span><br><span class="line"><span class="comment"># 之后不要通过software更新驱动</span></span><br><span class="line"><span class="comment"># 独显有用核显有用：删除/etc/X11/xorg.conf</span></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure><h2 id="cuda和cudnn">CUDA和CUDNN</h2><p>据说现在deb安装，可以直接安装对应版本的nvudia driver，并且不会掉驱动</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">用.run的版本的安装方法</span><br><span class="line">以下为部分安装提示</span><br><span class="line">Do you accept the previously <span class="built_in">read</span> EULA?</span><br><span class="line">accept/decline/quit: accept# <span class="comment">#这一条提示不用管它</span></span><br><span class="line">You are attempting to install on an unsupported configuration. Do you wish to <span class="built_in">continue</span>?</span><br><span class="line">(y)es/(n)o [ default is no ]: y</span><br><span class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 384.81?</span><br><span class="line">(y)es/(n)o/(q)uit: n <span class="comment"># 如果在这之前已经安装好更高版本的显卡驱动就不需要再重复安装，如果需要重复安装就选择 yes,此外还需要关闭图形界面。</span></span><br><span class="line">Install the CUDA 9.0 Toolkit?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line">Enter Toolkit Location</span><br><span class="line">[ default is /usr/local/cuda-9.0 ]:/home/usrname/usr/local/cuda-9.0</span><br><span class="line">/usr/local/cuda-9.0 is not writable.</span><br><span class="line">Do you wish to run the installation with ‘<span class="built_in">sudo</span>’?</span><br><span class="line">(y)es/(n)o: y</span><br><span class="line"></span><br><span class="line">Please enter your password:</span><br><span class="line">Do you want to install a symbolic <span class="built_in">link</span> at /usr/local/cuda? <span class="comment"># 是否将安装目录通过软连接的方式 link 到 /usr/local/cuda，yes or no 都可以，取决于你是否使用 /usr/local/cuda 为默认的 cuda 目录。</span></span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line">Install the CUDA 9.0 Samples? <span class="comment">#安装与否没有影响</span></span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装的时候需要切换G++GCC版本</span></span><br><span class="line"><span class="comment"># cuda去官网找sh文件</span></span><br><span class="line"><span class="comment"># 正式开始安装cuda</span></span><br><span class="line"><span class="comment"># cudnn下载deb，dpkg下载</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量到.bashrc</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"></span><br><span class="line">比如：<span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#卸载</span></span><br><span class="line"><span class="comment"># cuda安装时就已经准备好了卸载的接口，卸载程序在`/usr/local/cuda-xx.x/bin`下，需要注意的是cuda10.0及之前的版本卸载程序名为`uninstall_cuda_xx.x.pl`，而cuda10.1及之后的版本卸载程序名为`cuda-uninstaller`</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/cuda-xx.x/bin/</span><br><span class="line"><span class="built_in">sudo</span> ./cuda-uninstaller#或者<span class="built_in">sudo</span> ./uninstall_cuda_xx.x.pl</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -rf /usr/local/cuda-xx.x</span><br><span class="line"><span class="comment">#使用dpkg卸载cudnn</span></span><br><span class="line"><span class="built_in">sudo</span> dpkg -l | grep cudnn</span><br><span class="line"><span class="built_in">sudo</span> dpkg -r libcudnn8-samples</span><br><span class="line"><span class="built_in">sudo</span> dpkg -r libcudnn8-dev</span><br><span class="line"><span class="built_in">sudo</span> dpkg -r libcudnn8</span><br><span class="line"></span><br><span class="line">最后边加了一句<span class="built_in">sudo</span> <span class="built_in">rm</span> -rf /usr/local/cuda-xx.x，这是因为一般情况下cuda都配置了cudnn，在运行卸载程序时只会卸载cuda而不会一并删除cudnn的文件。因为cudnn文件还在的缘故，自己的cuda-xx.x文件夹仍然在，需要手动删除。</span><br></pre></td></tr></table></figure><h2 id="切换gccg-版本">切换GCCG++版本</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">gcc --version</span><br><span class="line">g++ --version <span class="comment"># 版本为11.4，gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载低版本gcc g++，并进行设置，tensorflow和pytorch一般使用4.8</span></span><br><span class="line"><span class="built_in">sudo</span> gedit /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line">增加</span><br><span class="line"></span><br><span class="line">deb http://dk.archive.ubuntu.com/ubuntu/ xenial main</span><br><span class="line">deb http://dk.archive.ubuntu.com/ubuntu/ xenial universe</span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> apt install gcc-4.8 g++-4.8 </span><br><span class="line"><span class="comment"># 使用update-alternatives管理多个版本的gcc g++ python，最后一位是优先级</span></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 1</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.8 1</span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 2</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11.4 2</span><br><span class="line"><span class="comment"># 可以通过以下命令来切换使用的gcc和g++版本</span></span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --config g++</span><br><span class="line"><span class="built_in">sudo</span> update-alternatives --config gcc</span><br></pre></td></tr></table></figure><h2 id="docker卸载">Docker卸载</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除docker残留物，没有就不用卸载了</span></span><br><span class="line">    dpkg -l | grep -i docker</span><br><span class="line"><span class="comment"># 删除io ce</span></span><br><span class="line">    <span class="built_in">sudo</span> apt-get purge -y docker-engine docker docker.io docker-ce</span><br><span class="line">    <span class="built_in">sudo</span> apt-get autoremove -y --purge docker-engine docker docker.io docker-ce</span><br><span class="line"><span class="comment"># 删除参数</span></span><br><span class="line">    <span class="built_in">sudo</span> <span class="built_in">rm</span> -rf /var/lib/docker /etc/docker</span><br><span class="line">    <span class="built_in">sudo</span> <span class="built_in">rm</span> /etc/apparmor.d/docker</span><br><span class="line">    <span class="built_in">sudo</span> groupdel docker</span><br><span class="line">    <span class="built_in">sudo</span> <span class="built_in">rm</span> -rf /var/run/docker.sock</span><br><span class="line"><span class="comment"># 如果使用dpkg的方式安装 发现还未清除docker残留</span></span><br><span class="line">    <span class="built_in">sudo</span> find / -name <span class="string">&quot;*docker*&quot;</span></span><br><span class="line"><span class="comment"># rm 这些项</span></span><br><span class="line">    <span class="built_in">cd</span> /var/lib/dpkg/</span><br><span class="line">    <span class="built_in">sudo</span> gedit status</span><br><span class="line"><span class="comment"># 在status与status-old 文件里查找docker相关的项，删除相关内容。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="docker-desktop-deb安装-更新只需要重新安装deb">Docker Desktop(deb安装，更新只需要重新安装deb)</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装地址：https://docs.docker.com/desktop/install/linux-install/</span></span><br><span class="line"><span class="comment"># for non-Gnome Desktop environments, gnome-terminal must be installed:</span></span><br><span class="line"><span class="comment"># sudo apt install gnome-terminal</span></span><br><span class="line"><span class="comment"># 卸载干净了</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get remove docker docker-engine docker.io containerd runc</span><br><span class="line"><span class="comment"># 首先添加Docker Desktop的apt源</span></span><br><span class="line"><span class="comment"># Add Docker&#x27;s official GPG key:</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install ca-certificates curl</span><br><span class="line"><span class="built_in">sudo</span> install -m 0755 -d /etc/apt/keyrings</span><br><span class="line"><span class="built_in">sudo</span> curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> a+r /etc/apt/keyrings/docker.asc <span class="comment">#a+r表示将读权限授予所有用户，最后的路径则是要修改权限的文件路径。该命令的目的是将GPG密钥文件的读权限授予所有用户，以确保所有用户都能够读取该文件中的密钥信息。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the repository to Apt sources:</span></span><br><span class="line"><span class="built_in">echo</span> \</span><br><span class="line">  <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">  <span class="subst">$(. /etc/os-release &amp;&amp; echo <span class="string">&quot;<span class="variable">$VERSION_CODENAME</span>&quot;</span>)</span> stable&quot;</span> | \</span><br><span class="line">  <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二，下载deb包</span></span><br><span class="line"><span class="comment"># 去官网下载</span></span><br><span class="line"><span class="comment"># 第三，安装deb包</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> dkpg -i ./docker-desktop-4.28.0-amd64.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三，添加用户</span></span><br><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">$USER</span> <span class="comment"># 将当前用户添加到 docker 用户组中，以便您可以在不使用 sudo 的情况下运行 Docker 命令</span></span><br><span class="line">newgrp docker <span class="comment">#此命令用于切换到 docker 用户组。当您运行此命令后，您的 shell 将具有 docker 用户组的权限，建议写到zsh里面</span></span><br><span class="line"></span><br><span class="line">systemctl --user start docker-desktop <span class="comment"># --user 参数用于明确指定您希望在用户级别运行 systemctl 命令</span></span><br><span class="line">systemctl status docker-desktop</span><br><span class="line">systemctl --user stop docker-desktop</span><br><span class="line">docker version</span><br><span class="line"><span class="comment"># 记住一定要加--user，而且不能用sudo，不能用docker（service）沃日，搞了一个下午~！！！！！！！！！！！！！！！！！！！！！！！！！！！！</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## sign in 登录，现在登录需要pass才行，参考https://docs.docker.com/desktop/get-started/#credentials-management-for-linux-users</span></span><br><span class="line">gpg --generate-key</span><br><span class="line"><span class="comment"># 真实姓名： outbreak</span></span><br><span class="line"><span class="comment"># 您选定了此用户标识：“outbreak &lt;1023786231@qq.com&gt;”</span></span><br><span class="line"><span class="comment"># 我们需要生成大量的随机字节。在质数生成期间做些其他操作（敲打键盘、移动鼠标、读写硬盘之类的）将会是一个不错的主意；这会让随机数发生器有更好的机会获得足够的熵。</span></span><br><span class="line"><span class="comment"># gpg: /home/outbreak/.gnupg/trustdb.gpg：建立了信任度数据库</span></span><br><span class="line"><span class="comment"># gpg: 密钥 10B61AB8A00B94FC 被标记为绝对信任</span></span><br><span class="line"><span class="comment"># gpg: 目录‘/home/outbreak/.gnupg/openpgp-revocs.d’已创建</span></span><br><span class="line"><span class="comment"># gpg: 吊销证书已被存储为‘/home/outbreak/.gnupg/openpgp-revocs.d/951E377343482D391981EF4910B61AB8A00B94FC.rev’</span></span><br><span class="line"><span class="comment"># 公钥和私钥已经生成并被签名。</span></span><br><span class="line"><span class="comment"># pub   rsa3072 2024-04-03 [SC] [有效至：2026-04-03]</span></span><br><span class="line"><span class="comment">#       951E377343482D391981EF4910B61AB8A00B94FC</span></span><br><span class="line"><span class="comment"># uid                      outbreak &lt;1023786231@qq.com&gt;</span></span><br><span class="line"><span class="comment"># sub   rsa3072 2024-04-03 [E] [有效至：2026-04-03]</span></span><br><span class="line"><span class="comment"># 然后运行，后面接上pub</span></span><br><span class="line">pass init 951E377343482D391981EF4910B61AB8A00B94FC</span><br><span class="line"></span><br><span class="line"><span class="comment">#卸载 Docker Desktop</span></span><br><span class="line"><span class="built_in">sudo</span> apt purge docker-desktop</span><br><span class="line"><span class="built_in">rm</span> -r <span class="variable">$HOME</span>/.docker/desktop</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> /usr/local/bin/com.docker.cli</span><br></pre></td></tr></table></figure><h2 id="gpg蜜月">GPG蜜月</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install ca-certificates curl gnupg</span><br><span class="line"><span class="comment"># 其中，ca-certificates是一个软件包名称，它包含了一组根证书和中间证书，用于验证HTTPS连接的安全性</span></span><br><span class="line"><span class="comment"># 安装ca-certificates软件包可以确保系统具有最新的根证书列表。</span></span><br><span class="line"><span class="comment"># curl是一个用于在命令行中进行网络请求的工具，它支持多种协议，如HTTP、HTTPS、FTP等；安装curl软件包可以让我们在终端中方便地进行网络请求和下载文件。gnupg是GNU隐私卫士</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="nvidiadocker-apt">NVIDIADocker(APT)</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以通过apt，yun，zypper安装</span></span><br><span class="line"><span class="comment"># 参考https://docs.nvidia.com/datacenter/cloud-native/containertoolkit/latest/install-guide.html</span></span><br><span class="line"><span class="comment"># 安装nvidia驱动，运行nvidia-smi会有输出，</span></span><br><span class="line"><span class="comment"># 查看显卡是否存在 lspci | grep -i nvidia</span></span><br><span class="line"><span class="comment"># /////// 框内是一个命令</span></span><br><span class="line">curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | <span class="built_in">sudo</span> gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \</span><br><span class="line">  &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \</span><br><span class="line">    sed <span class="string">&#x27;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#x27;</span> | \</span><br><span class="line">    <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list</span><br><span class="line"><span class="comment"># /////// 框内是一个命令</span></span><br><span class="line">    <span class="built_in">sudo</span> apt-get update</span><br><span class="line">    <span class="built_in">sudo</span> apt-get install -y nvidia-container-toolkit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置Docker Configure the container runtime by using the nvidia-ctk command:</span></span><br><span class="line"><span class="built_in">sudo</span> nvidia-ctk runtime configure --runtime=docker</span><br><span class="line"><span class="comment"># nvidia-ctk命令修改了/etc/docker/daemon.json中的内容，文件中的内容更新之后Docker就可以使用NVIDIA Container Runtime.</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl restart docker#Restart the Docker daemon</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 如需在没有 sudo 的情况下运行 docker 命令，请创建 docker 组并添加您的用户。 </span></span><br><span class="line"><span class="built_in">sudo</span> groupadd docker</span><br><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">$USER</span></span><br><span class="line"><span class="comment"># 测试 docker run --runtime=nvidia -rm nvidia/cuda:9.0-base nvidia-smi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证 nvidia-docker 安装效果</span></span><br><span class="line">docker run --gpus all --<span class="built_in">rm</span> nvidia/cuda nvidia-smi</span><br><span class="line"><span class="comment"># 会自动下载nvidia、cuda</span></span><br><span class="line"><span class="comment"># 注意：nvidia-docker v2 使用 --runtime=nvidia，而不是 --gpus all。nvidia-docker v1 </span></span><br><span class="line"><span class="comment"># 使用 nvidia-docker 别名，而不是 --runtime=nvidia 或 --gpus all 命令行标记。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="tensorflow-docker">TensorFlow Docker</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在本地主机上安装 Docker。</span></span><br><span class="line"><span class="comment"># 如需在 Linux 上启用 GPU 支持，请安装 NVIDIA Docker 支持。</span></span><br><span class="line"><span class="comment"># 通过 docker -v 检查 Docker 版本。对于 19.03 之前的版本，您需要使用 nvidia-docker2 和 -- runtime=nvidia 标记；对于 19.03 及之后的版本，您将需要使用 nvidia-container-toolkit 软件包和 --gpus all 标记。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下的tag为latest-gpu-jupyter  </span></span><br><span class="line">docker pull tensorflow/tensorflow:latest-gpu-jupyter  </span><br><span class="line"></span><br><span class="line"><span class="comment"># latest：TensorFlow CPU 二进制映像的最新版本。（默认版本）</span></span><br><span class="line"><span class="comment"># nightly：TensorFlow 映像的每夜版。（不稳定）</span></span><br><span class="line"><span class="comment"># version:指定 TensorFlow 二进制映像的版本，例如：2.1.0</span></span><br><span class="line"><span class="comment"># devel :TensorFlow master 开发环境的每夜版。包含 TensorFlow 源代码。devel and custom-op 版本不再支持</span></span><br><span class="line"><span class="comment"># custom-op:于开发 TF 自定义操作的特殊实验性映像。详见此处。devel and custom-op 版本不再支持</span></span><br><span class="line"><span class="comment"># 版本&lt;= 1.15.0 (1.x) and &lt;= 2.1.0 (2.x) 的如果带有-py3的镜像里面有python3(3.5 for Ubuntu 16-based images; 3.6 for Ubuntu 18-based images; 3.8 for Ubuntu 20-based images) </span></span><br><span class="line"><span class="comment"># 版本&lt;= 1.15.0 (1.x) and &lt;= 2.1.0 (2.x) 的如果没有带有-py3的镜像里面只有Python 2.7</span></span><br><span class="line"><span class="comment"># -gpu tags are based on Nvidia CUDA. You need nvidia-docker to run them. </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上述标记下还有二级的tag</span></span><br><span class="line"><span class="comment"># 每个基本标记都有会添加或更改功能的变体：</span></span><br><span class="line"><span class="comment"># 标记变体 说明</span></span><br><span class="line"><span class="comment"># tag-gpu 支持 GPU 的指定标记版本</span></span><br><span class="line"><span class="comment"># tag-jupyter 针对 Jupyter 的指定标记版本</span></span><br><span class="line"></span><br><span class="line">如需在容器内运行在主机上开发的 TensorFlow 程序，请装载主机目录并更改容器的工作目录 (-v hostDir:containerDir -w workDir)</span><br><span class="line">docker run -it --<span class="built_in">rm</span> -v <span class="variable">$PWD</span>:/tmp -w /tmp tensorflow/tensorflow python ./script.py</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="cmake">cmake</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install build-essential libncurses5-dev ninja-build libssl-dev libarchive13 libcurl4 librhash0 libuv1</span><br><span class="line"><span class="comment"># source下载地址https://cmake.org/files/，其中cmake-3.21.4-linux-x86_64.tar.gz是已编译好的，我们要用cmake-3.21.4.tar.gz，里面有bootstrap文件</span></span><br><span class="line"><span class="comment"># 千万不要sudo apt-get autoremove cmake</span></span><br><span class="line">tar -zxvf cmake-3.21.4.tar.gz </span><br><span class="line"><span class="built_in">cd</span> cmake-3.21.4</span><br><span class="line">./bootstrap --generator=Ninja</span><br><span class="line">ninja</span><br><span class="line"><span class="built_in">sudo</span> ninja install</span><br><span class="line">cmake --version</span><br></pre></td></tr></table></figure><h2 id="qt">QT</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sudo权限进入安装（安装在/opt目录下），软件所在目录：/opt/Qt5.12.9/Tools/QtCreator/bin/</span></span><br><span class="line"><span class="built_in">chmod</span> +x qt-opensource-linux-x64-5.12.9.run</span><br><span class="line"><span class="built_in">sudo</span> ./qt-opensource-linux-x64-5.12.9.run#只安装其中的qtcreator和QT5.12里的<span class="built_in">source</span>就可以了</span><br></pre></td></tr></table></figure><p>或者以下的方式安装两个就可以</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install qt5* qttools5-dev</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="gflags">gflags</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apt安装</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libgflags-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># source安装</span></span><br><span class="line"><span class="built_in">cd</span> gflags</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake -DGFLAGS_NAMESPACE=google -DCMAKE_CXX_FLAGS=-fPIC -DBUILD_SHARED_LIBS=ON ..</span><br><span class="line">make -j4</span><br><span class="line"><span class="built_in">sudo</span> make install</span><br><span class="line"><span class="built_in">sudo</span> ldconfig</span><br></pre></td></tr></table></figure><h2 id="glog">glog</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apt安装</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libgoogle-glog-dev </span><br><span class="line"></span><br><span class="line"><span class="comment"># source安装</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/google/glog</span><br><span class="line"><span class="built_in">cd</span> glog</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake -DGFLAGS_NAMESPACE=google -DCMAKE_CXX_FLAGS=-fPIC -DBUILD_SHARED_LIBS=ON ..</span><br><span class="line"></span><br><span class="line">cmakelists-----option (WITH_GTEST <span class="string">&quot;Use googletest&quot;</span> OFF)</span><br><span class="line">make</span><br><span class="line"><span class="built_in">sudo</span> make install</span><br></pre></td></tr></table></figure><h2 id="eigen">eigen</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apt安装</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libeigen3-dev <span class="comment">#默认安装路径/usr/include/eigen3</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/include/eigen3/Eigen /usr/include/Eigen</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r /usr/include/eigen3/Eigen /usr/include</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r /usr/include/eigen3/signature_of_eigen3_matrix_library /usr/include</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r /usr/include/eigen3/unsupported /usr/include</span><br><span class="line"><span class="comment"># source安装</span></span><br><span class="line">tar -xvf eigen-3.4.0.tar.gz</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake .. </span><br><span class="line"><span class="built_in">sudo</span> make install</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/include/eigen3/Eigen /usr/include/Eigen</span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s  /usr/include/eigen3/Eigen /usr/include</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/include/eigen3/signature_of_eigen3_matrix_library /usr/include</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s /usr/include/eigen3/unsupported /usr/include</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ceres">ceres</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 依赖glog和eigen</span></span><br><span class="line"><span class="comment"># 除此之外还依赖 Use ATLAS for BLAS &amp; LAPACK</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libatlas-base-dev</span><br><span class="line"><span class="built_in">mkdir</span> build&amp;&amp;<span class="built_in">cd</span> build</span><br><span class="line">cmake ../</span><br><span class="line">make -j5注意制定内核数，直接-j会导致内存不足而宕机</span><br><span class="line">make <span class="built_in">test</span></span><br><span class="line"><span class="built_in">sudo</span> make install <span class="comment">#不sudo就找不到</span></span><br></pre></td></tr></table></figure><h2 id="zsh">Zsh</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装zsh</span></span><br><span class="line"><span class="built_in">sudo</span> apt install zsh</span><br><span class="line"><span class="comment"># 然后将zsh设置为默认shell：</span></span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$SHELL</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#安装oh-my-zsh</span></span><br><span class="line"><span class="comment"># gitee安装</span></span><br><span class="line"><span class="built_in">sudo</span> apt install curl git</span><br><span class="line">sh -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh)</span>&quot;</span></span><br><span class="line"><span class="comment"># 外网安装</span></span><br><span class="line">wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装Powerlevel10k主题</span></span><br><span class="line">git <span class="built_in">clone</span> --depth=1 https://gitee.com/romkatv/powerlevel10k.git <span class="variable">$&#123;ZSH_CUSTOM:-<span class="variable">$HOME</span>/.oh-my-zsh/custom&#125;</span>/themes/powerlevel10k</span><br><span class="line"><span class="comment"># 配置Powerlevel10k</span></span><br><span class="line"><span class="comment"># vim ~/.zshrc编辑.zshrc，将ZSH_THEME项改为：</span></span><br><span class="line">ZSH_THEME=<span class="string">&quot;powerlevel10k/powerlevel10k&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#安装各种插件</span></span><br><span class="line"><span class="comment">#zsh-autosuggestions</span></span><br><span class="line">git <span class="built_in">clone</span> https://gitee.com/zsh-users/zsh-autosuggestions <span class="variable">$&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;</span>/plugins/zsh-autosuggestions</span><br><span class="line"><span class="comment">#zsh-syntax-highlighting</span></span><br><span class="line"> git <span class="built_in">clone</span> https://gitee.com/zsh-users/zsh-syntax-highlighting.git <span class="variable">$&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;</span>/plugins/zsh-syntax-highlighting</span><br><span class="line"><span class="comment">#使插件生效,上述插件安装完成后，需要修改.zshrc文件，编辑plugins项，修改如下：</span></span><br><span class="line"><span class="comment"># 值得注意的是，根据官方文档，zsh-syntax-highlighting 插件需放在最后</span></span><br><span class="line">plugins=(</span><br><span class="line">  git extract zsh-autosuggestions zsh-syntax-highlighting</span><br><span class="line">)</span><br><span class="line"><span class="comment">#使用source ~/.zshrc命令更新。</span></span><br><span class="line"><span class="comment"># vim ~/.zshrc编辑，添加以下一行</span></span><br><span class="line"><span class="built_in">setopt</span> no_nomatch <span class="comment">#解决无法识别*问题</span></span><br></pre></td></tr></table></figure><h2 id="clash">Clash</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">将 Clash <span class="keyword">for</span> Windows.zip 和 subconverter.zip解压到主目录.</span><br><span class="line"><span class="built_in">cd</span> Clash <span class="keyword">for</span> Windows</span><br><span class="line">./cfw</span><br><span class="line"><span class="built_in">cd</span> ../subconverter</span><br><span class="line">./subconverter  <span class="comment">#运行后不要关闭</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#TUN模式</span></span><br><span class="line">打开Clash，点击General中Service Mode右边Manage，点击install，地球图标变为绿色后说明安装成功</span><br><span class="line">点击TUN Mode右边的开关，启用TUN模式，现在可以打开终端（终端没有设置代理），查看是否成功，上下两条命令的执行结果分别是开启TUN模式前后（代理为全局模式）的结果</span><br><span class="line"></span><br><span class="line"><span class="comment">## global里设置7890，自动开机，proxy设置</span></span><br><span class="line">点击一下sytem proxy</span><br><span class="line">127.0.0.1 7890</span><br><span class="line">127.0.0.1 7890</span><br><span class="line">127.0.0.1 8889</span><br><span class="line">127.0.0.1 1089</span><br><span class="line"></span><br><span class="line">经过调研，现在使用clash verge，</span><br></pre></td></tr></table></figure><h2 id="opencv3-contrib">opencv3+contrib</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install build-essential cmake-curses-gui ninja-build libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg-dev libswscale-dev libtiff5-dev pkg-config libgtk-3*</span><br><span class="line"><span class="comment"># https://github.com/opencv/opencv/releases?page=1</span></span><br><span class="line"><span class="comment"># https://github.com/opencv/opencv_contrib/tags</span></span><br><span class="line"><span class="comment"># 分别下载两个同版本的文件，分别解压，在opencv文件夹下</span></span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">ccmake -G Ninja ..</span><br><span class="line">BUILD_EXAMPLES#编译示例代码</span><br><span class="line">BUILD_PNG(JPEG,TIFF,WEBP,OPENJPEG,JASPER,OPENEXR)#使opencv可以读取相应格式的图片</span><br><span class="line">WITH_QT#使用QT绘制窗口，会提供很多功能，建议开启，需要安装QT5</span><br><span class="line">OPENCV_EXTRA_MODULES_PATH=.opencv_contrib/modules#contrib 的目录，到modules，module可筛选</span><br><span class="line">OPENCV_GENERATE_PKGCONFIG#启用.pc文件生成以及标准 CMake 包，建议开启</span><br><span class="line">OPENCV_sfm设置为OFF因为会因为glog版本报错</span><br><span class="line">ninja</span><br><span class="line"><span class="built_in">sudo</span> ninja install</span><br><span class="line"><span class="built_in">sudo</span> ninja uninstall</span><br><span class="line"></span><br><span class="line"><span class="comment">#卸载时sudo ninja uninstall</span></span><br><span class="line"><span class="comment">#标定板下载https://calib.io/pages/camera-calibration-pattern-generator</span></span><br></pre></td></tr></table></figure><h2 id="ros2-humble">Ros2-humble</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用fishros，其脚本跑的是官方的安装流程</span></span><br><span class="line">wget http://fishros.com/install -O fishros &amp;&amp; . ./fishros</span><br><span class="line"><span class="comment"># 在~/.zshrc中加入</span></span><br><span class="line"><span class="built_in">source</span> /opt/ros/humble/setup.zsh</span><br></pre></td></tr></table></figure><h2 id="moveit-humble"><s>moveit-humble</s></h2><h2 id="realsense2"><s>realsense2</s></h2><h2 id="galaxy相机驱动">Galaxy相机驱动</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> ./Galaxy_camera.run</span><br><span class="line"><span class="built_in">cd</span> Galaxy_camera/inc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> DxImageProc.h /usr/include</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> GxIAPI.h /usr/include</span><br></pre></td></tr></table></figure><h2 id="openvino">Openvino</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一、Openvino2022安装 ubuntu 20.04</span></span><br><span class="line">./l_openvino_toolkit_p_2022.1.0.643_offline.sh</span><br><span class="line">vim ~/.bashrc</span><br><span class="line"><span class="comment">#将.sh文件source</span></span><br><span class="line"><span class="comment">#如果python路径报错，修改setupvars.sh中</span></span><br><span class="line"><span class="comment">#SCRIPT_DIR改为</span></span><br><span class="line">SCRIPT_DIR=<span class="string">&quot;<span class="subst">$(abs_path <span class="string">&quot;<span class="variable">$&#123;(%):-%N&#125;</span>&quot;</span>)</span>&quot;</span> &gt;/dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h1>Openvino2023安装 ubuntu22.04</h1><p>wget <a href="https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB">https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB</a><br>sudo apt-key add GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB<br>echo “deb <a href="https://apt.repos.intel.com/openvino/2023">https://apt.repos.intel.com/openvino/2023</a> ubuntu22 main” | sudo tee /etc/apt/sources.list.d/intel-openvino-2023.list<br>sudo apt update<br>apt-cache search openvino<br>sudo apt install openvino-2023.2.0</p><h2 id="anaconda">Anaconda</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./Anaconda3-2021.11-Linux-x86_64.sh# no sudo</span><br><span class="line">vim ~/.bashrc</span><br><span class="line">vim ~/.zshrc</span><br><span class="line">#调整$PATH的位置</span><br></pre></td></tr></table></figure><h2 id="conda换源">Conda换源</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法一</span></span><br><span class="line">gedit ~/.condarc</span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: <span class="literal">true</span></span><br><span class="line">channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda</span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls <span class="built_in">yes</span> </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/  </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/ </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ </span><br></pre></td></tr></table></figure><h2 id="pip换源">PIP换源</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pip -U</span><br><span class="line">pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><h2 id="vscode">VScode</h2><p>为了解决下载太慢的问题：</p><p><a href="https://blog.csdn.net/weixin_46621570/article/details/128007351">https://blog.csdn.net/weixin_46621570/article/details/128007351</a></p><h2 id="vlc">VLC</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install vlc</span><br></pre></td></tr></table></figure><h2 id="qq">QQ</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> dpkg -i linuxqq_3.2.0-16605_amd64.deb</span><br></pre></td></tr></table></figure><h2 id="飞书">飞书</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i Feishu-linux_x64-6.9.16.deb</span><br></pre></td></tr></table></figure><h2 id="libjpeg-turbo">libjpeg-turbo</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认安装位置/opt/libjpeg-turbo</span></span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake -G<span class="string">&quot;Unix Makefiles&quot;</span> ..</span><br><span class="line">make</span><br><span class="line"><span class="built_in">sudo</span> make install</span><br><span class="line">make uninstall</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用时libjpeg-turbo的安装包没有提供用于CONFIG模式查找包(find_package)的cmake脚本,所以需要自己写</span></span><br><span class="line"><span class="built_in">set</span>(CMAKE_PREFIX_PATH /opt/libjpeg-turbo)</span><br><span class="line">find_package(PkgConfig REQUIRED)</span><br><span class="line">pkg_search_module(TURBOJPEG REQUIRED libturbojpeg)</span><br><span class="line">link_directories(<span class="variable">$&#123;TURBOJPEG_LIBDIR&#125;</span>)</span><br><span class="line">add_executable(tjexample tjexample.c)</span><br><span class="line">target_include_directories(tjexample PUBLIC <span class="variable">$&#123;TURBOJPEG_INCLUDE_DIRS&#125;</span>)</span><br><span class="line">target_link_libraries(tjexample <span class="variable">$&#123;TURBOJPEG_LIBRARIES&#125;</span>)</span><br></pre></td></tr></table></figure><h2 id="labelrobomaster">LabelRobomaster</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install libfuse2 <span class="comment">#22.04不再默认安装fuse</span></span><br></pre></td></tr></table></figure><h2 id="colmap">Colmap</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install \</span><br><span class="line">    git \</span><br><span class="line">    cmake \</span><br><span class="line">    build-essential \</span><br><span class="line">    libboost-program-options-dev \</span><br><span class="line">    libboost-filesystem-dev \</span><br><span class="line">    libboost-graph-dev \</span><br><span class="line">    libboost-system-dev \</span><br><span class="line">    libboost-test-dev \</span><br><span class="line">    libeigen3-dev \</span><br><span class="line">    libsuitesparse-dev \</span><br><span class="line">    libfreeimage-dev \</span><br><span class="line">    libmetis-dev \</span><br><span class="line">    libgoogle-glog-dev \</span><br><span class="line">    libgflags-dev \</span><br><span class="line">    libglew-dev \</span><br><span class="line">    qtbase5-dev \</span><br><span class="line">    libqt5opengl5-dev \</span><br><span class="line">    libcgal-dev</span><br><span class="line">    因为之前已经安装了所以只需要运行：</span><br><span class="line"></span><br><span class="line">git clone https://github.com/colmap/colmap.git</span><br><span class="line">cd colmap</span><br><span class="line">git checkout dev</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake .. -DQt5_DIR=/opt/homebrew/opt/qt@5/lib/cmake/Qt5</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><h2 id="meshlab">meshLab</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 源码安装，弃用</span><br><span class="line">cd /home/outbreak/MVS/meshlab_folder/meshlab/scripts/Linux</span><br><span class="line">zsh 0_setup_env.sh --dont_install_qt # 已经安装了Qt</span><br><span class="line"># 直接登录https://www.meshlab.net/#download下载appImage</span><br><span class="line">    sudo apt install libfuse2</span><br></pre></td></tr></table></figure><h2 id="mve">MVE</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 依赖：</span></span><br><span class="line"><span class="comment"># libjpeg (for MVE, http://www.ijg.org/)</span></span><br><span class="line"><span class="comment"># libpng (for MVE, http://www.libpng.org/pub/png/libpng.html)</span></span><br><span class="line"><span class="comment"># libtiff (for MVE, http://www.libtiff.org/)</span></span><br><span class="line"><span class="comment"># OpenGL (for libogl in MVE and UMVE)</span></span><br><span class="line"><span class="comment"># Qt 5 (for UMVE, http://www.qt.io)</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libjpeg-dev</span><br><span class="line"><span class="built_in">sudo</span> apt-get install libtiff-dev</span><br><span class="line"><span class="built_in">sudo</span> apt-get install libpng-devopenGL</span><br><span class="line">01--首先不可或缺的就是编译器与基本的函式库</span><br><span class="line"><span class="built_in">sudo</span> apt-get install build-essential</span><br><span class="line">02--安装OpenGL Library</span><br><span class="line"><span class="built_in">sudo</span> apt-get install libgl1-mesa-dev</span><br><span class="line">03--安装OpenGL Utilities</span><br><span class="line">// OpenGL Utilities 是一组建构于 OpenGL Library 之上的工具组，</span><br><span class="line">// 提供许多很方便的函式，使 OpenGL 更强大且更容易使用</span><br><span class="line"><span class="built_in">sudo</span> apt-get install libglu1-mesa-dev</span><br><span class="line">04--安装OpenGL Utility Toolkit</span><br><span class="line">// OpenGL Utility Toolkit 是建立在 OpenGL Utilities 上面的工具箱，</span><br><span class="line">// 除了强化了 OpenGL Utilities 的不足之外，也增加了 OpenGL 对于视窗介面支援。</span><br><span class="line"><span class="built_in">sudo</span> apt-get install freeglut3-dev</span><br><span class="line">最后</span><br><span class="line"><span class="built_in">sudo</span> apt-get install libglew-dev libsdl2-dev libsdl2-image-dev libglm-dev libfreetype6-dev</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># To download and build MVE, type:</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/simonfuhrmann/mve.git</span><br><span class="line"><span class="built_in">cd</span> mve</span><br><span class="line">make -j8</span><br><span class="line"><span class="comment"># 将命令写在shell中才可以用其命令行运行</span></span><br><span class="line"><span class="comment"># 一共14个</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/bundle2pset:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/dmrecon:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/featurerecon:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/fssrecon:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/makescene:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/mesh2pset:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/meshalign:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/meshclean:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/meshconvert:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/prebundle:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/scene2pset:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/sceneupgrade:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/sfmrecon:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/home/outbreak/MVS/MVE_folder/mve/apps/umve:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># UMVE是QT界面的GUI界面，没有UMVE就只能用命令行</span></span><br><span class="line"><span class="built_in">cd</span> apps/umve/</span><br><span class="line">qmake &amp;&amp; make -j8</span><br><span class="line">./umve</span><br><span class="line"><span class="comment"># 其运行的pipeline请看对应下的笔记</span></span><br></pre></td></tr></table></figure><h2 id="openmvs"><s>OpenMVS</s></h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最后出现报错，所以未能安装成功</span></span><br><span class="line">需要：</span><br><span class="line">    Eigen version 3.4 or higher</span><br><span class="line">    OpenCV version 2.4 or higher</span><br><span class="line">    Ceres version 1.10 or higher (optional)</span><br><span class="line">    CGAL version 4.2 or higher</span><br><span class="line">    Boost version 1.56 or higher</span><br><span class="line">    VCG VCGLib（注意要安装2020年的版本，参考教程）</span><br><span class="line">    CUDA (optional)</span><br><span class="line">    GLFW (optional)</span><br><span class="line">运行：</span><br><span class="line"><span class="built_in">sudo</span> apt-get update -qq &amp;&amp; <span class="built_in">sudo</span> apt-get install -qq </span><br><span class="line"><span class="comment">#安装Eigen (必需) </span></span><br><span class="line">git <span class="built_in">clone</span> https://gitlab.com/libeigen/eigen.git --branch 3.2 </span><br><span class="line"><span class="built_in">mkdir</span> eigen_build &amp;&amp; <span class="built_in">cd</span> eigen_build </span><br><span class="line">cmake . ../eigen make &amp;&amp; <span class="built_in">sudo</span> make install </span><br><span class="line"><span class="built_in">cd</span> .. </span><br><span class="line"><span class="comment">#安装Boost (必需) </span></span><br><span class="line"><span class="built_in">sudo</span> apt-get -y install libboost-iostreams-dev libboost-program-options-dev libboost-system-dev libboost-serialization-dev  </span><br><span class="line"><span class="comment">#安装OpenCV (必需) </span></span><br><span class="line"><span class="built_in">sudo</span> apt-get -y install libopencv-dev </span><br><span class="line"><span class="comment">#安装CGAL (必需) 是一个开源软件项目，以C++库的形式提供对高效可靠几何算法的轻松访问。CGAL用于各种需要几何计算的领域，如地理信息系统、计算机辅助设计、分子生物学、医学成像、计算机图形学和机器人。该库提供数据结构和算法，如三角图、Voronoi图、多边形和多面体的布尔运算、点集处理、曲线排列、曲面和体积网格生成、几何处理、阿尔法形状、凸包算法、形状重建、AABB和KD树</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get -y install libcgal-dev libcgal-qt5-dev  </span><br><span class="line"><span class="comment">#安装VCGLib (必需) 可视化与计算机图形库（简称VCG）是一个开源的可移植C++模板库，用于利用OpenGL对三角形和四面体网格进行操作、处理和显示。VCGLib使用github托管的git存储库</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/cdcseacave/VCG.git VCG</span><br><span class="line"><span class="built_in">cd</span> VCG &amp;&amp; git <span class="built_in">log</span></span><br><span class="line">git reset --hard 88f12f212a1645d1fa6416592a434c29e63b57f0</span><br><span class="line">VCG库主要由头文件构成(核心部分完全是头文件)而不依赖额外的东西. 只需下载压缩包并解压到一个</span><br><span class="line">文件夹. 例如, 解压到命名为 vcg 的文件夹， 并且设置为编译器的 include 目录. 以后， 你只需要</span><br><span class="line">像 app/sample/ 中的例子那样包含你需要的头文件即可</span><br><span class="line"><span class="comment">#安装Ceres (可选) </span></span><br><span class="line"><span class="built_in">sudo</span> apt-get -y install libatlas-base-dev libsuitesparse-dev </span><br><span class="line">git <span class="built_in">clone</span> https://ceres-solver.googlesource.com/ceres-solver ceres-solver </span><br><span class="line"><span class="built_in">mkdir</span> ceres_build &amp;&amp; <span class="built_in">cd</span> ceres_build </span><br><span class="line">cmake . ../ceres-solver/ -DMINIGLOG=ON -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF </span><br><span class="line">make -j2 &amp;&amp; <span class="built_in">sudo</span> make install </span><br><span class="line"><span class="built_in">cd</span> ..  </span><br><span class="line"><span class="comment">#安装GLFW3 (可选) </span></span><br><span class="line"><span class="built_in">sudo</span> apt-get -y install freeglut3-dev libglew-dev libglfw3-dev  </span><br><span class="line"><span class="comment">#安装OpenMVS </span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/electech6/openMVS_comments.git openMVS </span><br><span class="line"><span class="comment">## OpenMVS的中文注释版</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/electech6/openMVS_comments</span><br><span class="line"><span class="built_in">mkdir</span> openMVS_build &amp;&amp; <span class="built_in">cd</span> openMVS_build </span><br><span class="line">cmake . ../openMVS -DCMAKE_BUILD_TYPE=Release -DVCG_ROOT=<span class="string">&quot;/home/outbreak/DriverCollection/VCG&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果想生成共享库,可以在cmake加如下命令: </span></span><br><span class="line">-DBUILD_SHARED_LIBS=ON  </span><br><span class="line"><span class="comment">#生成 OpenMVS 库文件: </span></span><br><span class="line"><span class="built_in">sudo</span> make -j2 &amp;&amp; <span class="built_in">sudo</span> make install </span><br></pre></td></tr></table></figure><h2 id="openmvg">OpenMVG</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最后出现add_library cannot create imported target &quot;Qt5::QSvgIconPlugin&quot; because another target with the same name already exists，所以未能安装成功</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libpng-dev libjpeg-dev libtiff-dev libxxf86vm1 libxxf86vm-dev libxi-dev libxrandr-dev graphviz  </span><br><span class="line">git <span class="built_in">clone</span> --recursive https://github.com/openMVG/openMVG.git  &amp;&amp; <span class="built_in">cd</span> openMVG</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp;<span class="built_in">cd</span> build </span><br><span class="line">cmake -DCMAKE_BUILD_TYPE=RELEASE ../src/ -DOpenMVG_BUILD_TESTS=ON </span><br><span class="line"><span class="built_in">sudo</span> cmake --build . --target install  </span><br><span class="line"><span class="comment"># test make test ctest --output-on-failure -j </span></span><br><span class="line"><span class="comment"># .bashrcexport PATH=$PATH:/home/work/tools/openMVG_Build/Linux-x86_64-RELEASE/</span></span><br></pre></td></tr></table></figure><h2 id="bundler">Bundler</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install liblapack-dev libblas-dev minpack-dev f2c gfortran jhead imagemagick</span><br><span class="line"><span class="built_in">sudo</span> apt-get install libc6-dev-i386#一个用于编译和链接 C 程序的软件包,SIFT依赖</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/snavely/bundler_sfm.git</span><br><span class="line"><span class="built_in">cd</span> bundler_sfm</span><br><span class="line">make <span class="comment">#最后make[1]: Leaving directory</span></span><br><span class="line"><span class="comment">## 下载的SIFT程序，解压之后将里边的siftDemoV4/sift可执行文件拷贝到bundler_sfm下的bin目录下</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 将jhead文件拷贝到bundler_sfm下的bin目录下</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> /usr/bin/jhead bin/　</span><br><span class="line"><span class="comment">## 将bundler_sfm/bin/目录下生成的libANN_char.so文件拷贝到系统库</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> bin/libANN_char.so /usr/lib/　</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="cmvs-pmvs">CMVS-PMVS</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    PMVS(patch-based multi-view stereo) 是 Yasutaka Furukama 博士写的已知由一组图片和图片对应的相机参数生成 dense reconstruction (稠密的三维模型)的算法。</span><br><span class="line">    CMVS(Clustering Views <span class="keyword">for</span> Multi-view Stereo) 是 PMVS 的改进版，里面包含PMVS。</span><br><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install libgtk2.0-dev libdevil-dev libboost-all-dev libatlas-cpp-0.6-dev libatlas-dev libcminpack-dev libgfortran3 libmetis-edf-dev libparmetis-dev freeglut3-dev libgsl0-dev</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/pmoulon/CMVS-PMVS.git</span><br><span class="line"><span class="built_in">cd</span> CMVS-PMVS/program/</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br><span class="line"><span class="comment">## 生成的可执行文件位于build目录下的main目录中。为了接下来运行方便，我们将生成的可执行文件cmvs、genOption、pmvs2这三个文件拷贝到bundler_sfm目录的bin下</span></span><br></pre></td></tr></table></figure><h2 id="node-js">Node.js</h2><p>官网没有apt安装，实际上有。但是安装出来的不是最新的</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install -y nodejs</span><br></pre></td></tr></table></figure><p>Hexo需要14以下版本才能正常显示localhost</p><p>要安装制定版本在官网下载tar文件node-v20.18.0-linux-x64.tar.xz</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接解压到 /usr/local/ 目录</span></span><br><span class="line"><span class="built_in">sudo</span> tar -xvf node-v14.18.0-linux-x64.tar.xz -C /usr/local/</span><br><span class="line"><span class="comment"># nodejs下bin目录是否有node 和npm文件</span></span><br><span class="line"><span class="comment"># 在zsh下</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/local/node-v14.18.0-linux-x64/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># 建立符号链接</span></span><br><span class="line"><span class="built_in">cd</span> node-v14.18.0-linux-x64</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">ln</span> -s ./bin/npm /usr/local/bin/ </span><br><span class="line"><span class="built_in">ln</span> -s ./bin/node /usr/local/bin/</span><br><span class="line"><span class="comment"># 安装完成</span></span><br><span class="line">node -v</span><br></pre></td></tr></table></figure><p>不知道怎么了失败了，于是决定nvm安装</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash</span><br><span class="line"><span class="comment"># zsh中</span></span><br><span class="line"><span class="built_in">export</span> NVM_DIR=<span class="string">&quot;<span class="variable">$HOME</span>/.nvm&quot;</span></span><br><span class="line">[ -s <span class="string">&quot;<span class="variable">$NVM_DIR</span>/nvm.sh&quot;</span> ] &amp;&amp; \. <span class="string">&quot;<span class="variable">$NVM_DIR</span>/nvm.sh&quot;</span>  <span class="comment"># This loads nvm</span></span><br><span class="line">[ -s <span class="string">&quot;<span class="variable">$NVM_DIR</span>/bash_completion&quot;</span> ] &amp;&amp; \. <span class="string">&quot;<span class="variable">$NVM_DIR</span>/bash_completion&quot;</span>  <span class="comment"># This loads nvm bash_completion</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.zshrc</span><br><span class="line"><span class="comment"># 下载并安装 Node.js（可能需要重启终端）</span></span><br><span class="line">nvm install 22</span><br><span class="line">nvm use 22</span><br><span class="line"><span class="comment"># 验证环境中是否存在正确的 Node.js 版本</span></span><br><span class="line">node -v <span class="comment"># 应该打印 `v22.11.0`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证环境中是否存在正确的 npm 版本</span></span><br><span class="line">npm -v <span class="comment"># 应该打印 `10.9.0`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 逝世使用nvm下载hexo</span></span><br><span class="line"></span><br><span class="line">npm uninstall -g hexo-cli</span><br><span class="line">npm install -g hexo-cli</span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">hexo -v</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ssh-服务器">SSH 服务器</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">用户名 houbosen</span><br><span class="line">密码 Xw2dAOgsBk</span><br><span class="line">端口 1938 </span><br><span class="line">14号机ip 10.68.154.94</span><br></pre></td></tr></table></figure><h2 id="疑难杂症解决">疑难杂症解决</h2><ol><li>ssh connection refused</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install openssh-server </span><br><span class="line"><span class="built_in">sudo</span> apt install openssh-client</span><br></pre></td></tr></table></figure><ol start="2"><li>ssh permission denied</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">有没有可能你们两个的静态IP一样</span><br></pre></td></tr></table></figure><ol start="3"><li>From 192.168.50.6 icmp_seq=1 Destination Host Unreachable</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm /var/lib/NetworkManager/NetworkManager.state</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><ol start="4"><li>/usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to <code>pango_attr_insert_hyphens_new' /usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to </code>pango_attr_overline_new’<br>/usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to <code>pango_coverage_get_type' /usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to </code>pango_item_apply_attrs’<br>/usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to <code>cairo_tag_end' /usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to </code>pango_attr_list_update’<br>/usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to <code>pango_show_flags_get_type' /usr/bin/ld: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined reference to </code>cairo_svg_surface_get_document_unit’<br>爆了一堆librsvg找不到pango和cairo的包，然后重新装</li></ol><p>不知道会出什么问题，所以想直接冲了,</p><p>sudo apt remove librsvg2-2:amd64</p><p>sudo apt remove  librsvg2-common:amd64</p><p>sudo apt remove librsvg2-bin</p><p>sudo apt install librsvg2-2:amd64</p><p>sudo apt  install  librsvg2-common:amd64</p><p>sudo apt install librsvg2-bin</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Environment Installition&lt;/h1&gt;
&lt;p&gt;20241101&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;python3-8&quot;&gt;&lt;s&gt;Python3.8&lt;/s&gt;&lt;/h2&gt;
&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;</summary>
      
    
    
    
    <category term="配置环境" scheme="http://outbreak-sen.github.io/categories/%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
    
    
  </entry>
  
  <entry>
    <title>pyQT的安装和使用</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/pyQT%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/pyQT%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</id>
    <published>2025-02-09T07:21:26.000Z</published>
    <updated>2025-02-10T05:03:19.578Z</updated>
    
    <content type="html"><![CDATA[<h1>PyQT的安装和使用</h1><p>pyQT的安装不需要在官网下载QT安装包，只需要创建conda环境然后pip安装，安装pyQT5-tools之后会安装QT designer，然后就可以可视化设计一个UI，然后通过Pyuic工具就可以转化为一个py文件，这个py文件就是整个工程，py文件中有一个class包含了整个UI设计，然后只需要编辑py文件中这个class的功能即可，编辑子函数。<br>(这个文档非常好)[<a href="https://www.w3ccoo.com/pyqt5/index.html">https://www.w3ccoo.com/pyqt5/index.html</a>]</p><h2 id="vscode-pyqt-installation">VScode+pyQT installation</h2><ol><li><p>安装PyQt</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install PyQt5</span><br><span class="line">pip install PyQt5-tools</span><br></pre></td></tr></table></figure><p>vscode安装PYQT Integration便于使用pyqt</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Pyqt-integration &gt; Qtdesigner: Path</span></span><br><span class="line">\venv_QT\Lib\site-packages\qt5_applications\Qt\bin\designer</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Pyqt-integration &gt; Pyuic: Cmd 用于转化ui格式为py</span></span><br><span class="line">\venv_QT\Scripts\pyuic5</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Pyqt-integration &gt; Pyuic &gt; Compile: Filepath</span></span><br><span class="line">默认是将ui转化好的py文件存在当前目录的ui文件夹下</span><br></pre></td></tr></table></figure></li><li><p>使用Pyuic工具，将 .ui文件转换为 .py文件。</p><ul><li><p>在文件夹栏空白处点击右键点击「PYQT: New Form」启动Qt Designer软件</p></li><li><p>「文件 &gt; 另存为」，把所设计的 .ui文件保存到项目目录下</p></li><li><p>右击 xxx.ui文件「PYQT: Compile Form」调用Pyuic工将 xxx.ui文件转换为 xxx_Ui.py文件，是可以相互转化的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-x 开关向生成的 Python 脚本（来自 XML）添加了少量附加代码，使其成为可自执行的独立应用程序。</span></span><br><span class="line">pyuic5 -x input.py -o output.ui</span><br><span class="line">python -m PyQt6.uic.pyuic -x register.ui -o register.py</span><br></pre></td></tr></table></figure></li></ul></li></ol><ul><li><p>对GUI界面进行修改和调整。在文件夹栏的 .ui文件右击，点击「PYQT: Edit in Designer」，即可启动Qt Designer对GUI界面进行编辑。</p></li><li><p>编辑完成后保存并退出Qt Designer，对.ui文件右击，点击「PYQT: Compile Form」，重新更新一次 xxx_Ui.py文件即可。</p></li></ul><ol start="3"><li><p>使用python编程，调用GUI界面的 .py文件，编写GUI界面各组件的绑定事件函数，如点击某按钮时触发某函数，实现某功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QApplication, QMainWindow</span><br><span class="line"><span class="keyword">import</span> matchingNetworkDesigner_Ui <span class="comment"># import GUI的.py文件 </span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"> app = QApplication(sys.argv) </span><br><span class="line">MainWindow = QMainWindow() </span><br><span class="line">ui = matchingNetworkDesigner_Ui.Ui_MainWindow()<span class="comment"># ui=GUI的py文件名.类名</span></span><br><span class="line"> ui.setupUi(MainWindow)</span><br><span class="line"> ui.L_PB_cal.clicked.connect(L_cal) <span class="comment"># 把函数绑定GUI的按钮的点击事件。</span></span><br><span class="line"> ui.L_PB_reset.clicked.connect(L_reset)<span class="comment"># 按钮名字「L_PB_cal」和「L_PB_reset」在Qt Designer中定义。</span></span><br><span class="line"> MainWindow.show()</span><br><span class="line"> sys.exit(app.exec_())</span><br></pre></td></tr></table></figure></li></ol><h2 id="pyqt-include">PyQT include</h2><table><thead><tr><th>PyQT的模块组成</th><th>其余就是和web，sql，opengl等一些相关的，用不着</th></tr></thead><tbody><tr><td>QtCore</td><td>其他模块使用的核心非 GUI 类</td></tr><tr><td>QtGui</td><td>图形用户界面组件</td></tr><tr><td>QtXml</td><td>处理 XML 的类</td></tr><tr><td>QtWidgets</td><td>用于创建经典桌面样式 UI 的类。</td></tr><tr><td>QtDesigner</td><td>用于扩展 Qt Designer 的类</td></tr></tbody></table><table><thead><tr><th>PyQt5-tools的组成</th><th>其余不用看的</th></tr></thead><tbody><tr><td>assistantQt Assistant</td><td>文档工具</td></tr><tr><td>pyqt5designerQt Designer GUI</td><td>布局工具</td></tr><tr><td>linguist Qt Linguist</td><td>翻译工具</td></tr><tr><td>qmake Qt</td><td>软件构建工具</td></tr><tr><td>pyuic5</td><td>用于从 ui 文件生成代码的 Qt 用户界面编译器</td></tr></tbody></table><h2 id="pyqt-basic-class">PyQT Basic Class</h2><ul><li>QObject 是所有 Qt 对象的基类</li><li>QPaintDevice类是所有可绘制对象的基类。</li><li>QWidget类，派生自 QObject 和 QPaintDevice 类，是所有用户界面对象的基类。一般QWidget就是初始的大页面</li><li>QApplication类管理 GUI 应用程序的主要设置和控制流程包含主事件循环，其实就控制每个页面的关闭开启</li><li>QMainWindow基于 GUI 的应用程序的顶级窗口是由 <strong>QMainWindow</strong> 小部件对象创建的</li></ul><h2 id="qt信号与插槽">QT信号与插槽</h2><p>每个派生自 QObject 类的 PyQt 小部件都可以发出 <strong>“信号”</strong> 以响应一个或多个事件。信号是一个小部件的成员函数，比如点击click（）。信号&quot;连接connect&quot;到一个&quot;插槽function&quot;。 插槽可以是任何可调用的 Python 函数。</p><ul><li><p>可以使用qt designer的Signal/Slot 编辑器（或按 F4）直接添加</p></li><li><pre><code class="language-python">widget.signal.connect(slot_function)button.clicked.connect(slot_function)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 布局管理</span><br><span class="line"></span><br><span class="line">### 绝对布局</span><br><span class="line"></span><br><span class="line">* 设置一个大画面setGeometry(10,10,300,200)，然后里面的button位于move(50,2)</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">def window():</span><br><span class="line">   app = QtGui.QApplication(sys.argv)</span><br><span class="line"></span><br><span class="line">   w = QtGui.QWidget())    </span><br><span class="line">   w.setGeometry(10,10,300,200)</span><br><span class="line">   w.setWindowTitl</span><br><span class="line"></span><br><span class="line">   b = QtGui.QPushButton(w)</span><br><span class="line">   b.setText(&quot;Hello World!&quot;)</span><br><span class="line">   b.move(50,20e(“PyQt”)</span><br><span class="line"></span><br><span class="line">   w.show()</span><br><span class="line">   sys.exit(app.exec_())</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">   window()</span><br></pre></td></tr></table></figure></code></pre></li></ul><h3 id="相对布局">相对布局</h3><ul><li><p>QBoxLayout垂直或水平排列</p><ul><li><p>addWidget()将小部件添加到</p></li><li><p>addStretch()创建空的可拉伸框</p></li><li><p>addLayout()添加另一个嵌套布局</p></li><li><p>vbox = QVBoxLayout()，最后要win.setLayout(vbox)</p></li></ul></li><li><p>QGridLayout以行和列排列</p></li><li><p>QFormLayout创建两列表单</p></li></ul><h2 id="qt组件">qt组件</h2><ul><li><p><a href="https://www.w3ccoo.com/pyqt5/pyqt5_qlabel_widget.html">QLabel</a></p></li><li><p><a href="https://www.w3ccoo.com/pyqt5/pyqt5_qlineedit_widget.html">QLineEdit</a></p></li><li><p><a href="https://www.w3ccoo.com/pyqt5/pyqt5_qpushbutton_widget.html">QPushButton</a></p></li></ul><h2 id="多页面">多页面</h2><p>不止一个界面，如何弹出界面并多页面操作</p><h3 id="简单的提示界面">简单的提示界面</h3><ul><li><p>QDialog</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window</span>():</span><br><span class="line">   app = QApplication(sys.argv)</span><br><span class="line">   w = QWidget()</span><br><span class="line">   btn = QPushButton(w)</span><br><span class="line">   btn.clicked.connect(showdialog)</span><br><span class="line">   w.setWindowTitle(<span class="string">&quot;PyQt Dialog demo&quot;</span>)</span><br><span class="line">   w.show()</span><br><span class="line">   sys.exit(app.exec_())</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">showdialog</span>():</span><br><span class="line">   dlg = QDialog()</span><br><span class="line">   b1 = QPushButton(<span class="string">&quot;ok&quot;</span>,dlg)</span><br></pre></td></tr></table></figure></li><li><p>QMessageBox</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">window</span>():</span><br><span class="line">   app = QApplication(sys.argv)</span><br><span class="line">   w = QWidget()</span><br><span class="line">   b = QPushButton(w)</span><br><span class="line">   b.clicked.connect(showdialog)</span><br><span class="line">   w.setWindowTitle(<span class="string">&quot;PyQt MessageBox demo&quot;</span>)</span><br><span class="line">   w.show()</span><br><span class="line">   sys.exit(app.exec_())</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">showdialog</span>():</span><br><span class="line">   msg = QMessageBox()</span><br><span class="line">   msg.setIcon(QMessageBox.Information)</span><br></pre></td></tr></table></figure></li></ul><h3 id="真正的多页面">真正的多页面</h3><ul><li><p>SDI 单文档接口：显示多个独立的窗口。 这需要更多的内存资源。</p></li><li><p>MDI 多文档接口 ：子窗口相对于彼此放置在主容器内。 容器小部件称为 QMdiArea。</p></li></ul><p>QMdiArea 小部件一般占据 QMainWondow 对象的中心小部件。 该区域中的子窗口是 <strong>QMdiSubWindow</strong> 类的实例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MainWindow</span>(<span class="title class_ inherited__">QMainWindow</span>):</span><br><span class="line">   count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, parent = <span class="literal">None</span></span>):</span><br><span class="line">      <span class="built_in">super</span>(MainWindow, <span class="variable language_">self</span>).__init__(parent)</span><br><span class="line">      <span class="variable language_">self</span>.mdi = QMdiArea()</span><br><span class="line">      <span class="variable language_">self</span>.setWindowTitle(<span class="string">&quot;MDI demo&quot;</span>)</span><br><span class="line">      <span class="variable language_">self</span>.setCentralWidget(<span class="variable language_">self</span>.mdi)</span><br><span class="line">      bar = <span class="variable language_">self</span>.menuBar()</span><br><span class="line"></span><br><span class="line">      file = bar.addMenu(<span class="string">&quot;File&quot;</span>)</span><br><span class="line">      file.addAction(<span class="string">&quot;New&quot;</span>)</span><br><span class="line">      file.triggered[QAction].connect(<span class="variable language_">self</span>.windowaction)</span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">windowaction</span>(<span class="params">self, q</span>): <span class="comment"># 多个menu摁键传入参数</span></span><br><span class="line">      <span class="built_in">print</span> (<span class="string">&quot;triggered&quot;</span>)</span><br><span class="line">      <span class="keyword">if</span> q.text() == <span class="string">&quot;New&quot;</span>:</span><br><span class="line">         MainWindow.count = MainWindow.count+<span class="number">1</span></span><br><span class="line">         sub = QMdiSubWindow()</span><br><span class="line">         sub.setWidget(QTextEdit())</span><br><span class="line">         sub.setWindowTitle(<span class="string">&quot;subwindow&quot;</span>+<span class="built_in">str</span>(MainWindow.count))</span><br><span class="line">         <span class="variable language_">self</span>.mdi.addSubWindow(sub)</span><br><span class="line">         sub.show()</span><br></pre></td></tr></table></figure><h2 id="面向对象地制作gui">面向对象地制作GUI</h2><h1>QSS</h1><p><a href="https://doc.qt.io/qt-5/stylesheet-reference.html">Qt Style Sheets Reference</a></p><p><a href="https://doc.qt.io/qt-5/stylesheet-examples.html">Qt Style Sheets ExamplesQt 官方例子</a></p><p>Qt样式表（以下统称QSS）的术语和语法规则几乎和CSS相同。</p><ul><li><p>类似CSS，QSS每一条都是由一个选择器和一组声明构成：</p><ul><li><p>选择器选出要对哪种控件进行样式修改，</p></li><li><p>每个声明都是键值对，键为属性，值为属性值</p></li></ul></li></ul><h2 id="设置方法">设置方法</h2><ol><li><p>局部设置，用setStyleSheet(QSS)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label1 = QLabel(<span class="string">&#x27;标签1&#x27;</span>, <span class="variable language_">self</span>)</span><br><span class="line">label1.setStyleSheet(<span class="string">&#x27;background-color:green;&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">btn2 = QPushButton(<span class="string">&#x27;按钮2&#x27;</span>, <span class="variable language_">self</span>)</span><br><span class="line">btn2.move(<span class="number">200</span>, <span class="number">100</span>)</span><br><span class="line">btn2.resize(<span class="number">70</span>, <span class="number">30</span>)</span><br><span class="line"><span class="comment">#局部设置</span></span><br><span class="line">btn1.setStyleSheet(<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    QPushButton&#123;</span></span><br><span class="line"><span class="string">        color:red;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    QPushButton:hover&#123;</span></span><br><span class="line"><span class="string">        background-color: green;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li><p>全局设置，把所有的buttun之类的都设置好QSS，然后直接对Mainwindow进行加载</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span> :</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    window = Window()</span><br><span class="line">    QssStyle = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            QPushButton:hover&#123;</span></span><br><span class="line"><span class="string">                    background-color: green;</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">            QPushButton[name=&quot;btn&quot;]:hover&#123;</span></span><br><span class="line"><span class="string">                    background-color: red;</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">            QPushButton#btn:hover&#123;</span></span><br><span class="line"><span class="string">                    background-color: green;</span></span><br><span class="line"><span class="string">                    color:red;</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># # 全局设置</span></span><br><span class="line">    window.setStyleSheet(QssStyle)  <span class="comment"># 当前窗口全局有效</span></span><br><span class="line">    window.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure></li></ol><p>为降低耦合，往往把QSS写在一个单独的style.qss文件中，然后在main.py的QApplication或QMainWindow中加载样式</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">QPushButton &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#555555</span>;</span><br><span class="line">    <span class="attribute">border</span>: none;</span><br><span class="line">    <span class="attribute">color</span>: white;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">14px</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">5px</span> <span class="number">10px</span>;&#125;QPushButton<span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#666666</span>;&#125;QProgressBar &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#444444</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">8px</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">4px</span>;&#125;QProgressBar::chunk &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#777777</span>;&#125;QSlider &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#444444</span>;&#125;QSlider::handle:horizontal &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#666666</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">12px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">12px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: -<span class="number">3px</span> <span class="number">0</span>;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载QSS样式的方法</span></span><br><span class="line">app = QApplication(sys.argv)</span><br><span class="line">window = MainWindow()</span><br><span class="line"></span><br><span class="line">style_file = <span class="string">&#x27;./style.qss&#x27;</span></span><br><span class="line">style_sheet = QSSLoader.read_qss_file(style_file)</span><br><span class="line">window.setStyleSheet(style_sheet)</span><br><span class="line"></span><br><span class="line">window.show()</span><br><span class="line">sys.exit(app.exec_())</span><br></pre></td></tr></table></figure><h2 id="qt-material">Qt-material</h2><p>一个github开源，可以快速设置所有的qss。还有很多其他的快速设置qss的库GTRONICK-QSS，飞扬青云-QSS，QDarkStyleSheet</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install qt-material</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用例子</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5 <span class="keyword">import</span> QtWidgets</span><br><span class="line"><span class="keyword">from</span> qt_material <span class="keyword">import</span> apply_stylesheet</span><br><span class="line"></span><br><span class="line">app = QtWidgets.QApplication(sys.argv)</span><br><span class="line">window = QtWidgets.QMainWindow()</span><br><span class="line"></span><br><span class="line">apply_stylesheet(app, theme=<span class="string">&#x27;dark_teal.xml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">window.show()</span><br><span class="line">app.exec_()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;PyQT的安装和使用&lt;/h1&gt;
&lt;p&gt;pyQT的安装不需要在官网下载QT安装包，只需要创建conda环境然后pip安装，安装pyQT5-tools之后会安装QT designer，然后就可以可视化设计一个UI，然后通过Pyuic工具就可以转化为一个py文件，这个py文件就</summary>
      
    
    
    
    <category term="配置环境" scheme="http://outbreak-sen.github.io/categories/%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
    
    
    <category term="QT" scheme="http://outbreak-sen.github.io/tags/QT/"/>
    
    <category term="python" scheme="http://outbreak-sen.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>我的博客搭建过程和使用</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E5%92%8C%E4%BD%BF%E7%94%A8/</id>
    <published>2025-02-09T07:21:26.000Z</published>
    <updated>2025-02-09T07:37:39.677Z</updated>
    
    <content type="html"><![CDATA[<h1>我的博客搭建过程和使用</h1><h1>搭建过程</h1><h2 id="基础hexo搭建方法">基础Hexo搭建方法</h2><ol><li><p>安装 Node.js与git</p><p>Node.js 是一个开源的、跨平台的 JavaScript 运行环境</p></li><li><p>安装 Hexo和butterfly</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmmirror.com</span><br><span class="line">npm install hexo-cli -g</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> 你要创建站点的目录</span><br><span class="line">hexo init blog</span><br><span class="line"><span class="built_in">cd</span> blog</span><br><span class="line">npm install</span><br><span class="line">git <span class="built_in">clone</span> -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly <span class="comment">#主题要在theme里，可以魔改</span></span><br><span class="line">npm install hexo-renderer-pug hexo-renderer-stylus --save <span class="comment"># pug以及stylus的渲染器</span></span><br><span class="line">npm i hexo-theme-butterfly <span class="comment">#在博客的文件夹下</span></span><br></pre></td></tr></table></figure></li><li><p>创建一个github的page，需要创建“<a href="http://xn--eqr924avxo.github.io">用户名.github.io</a>”仓库，具体搜一下</p><p>这个github page只用于保存生成好的html文件，并不保存博客的原始文件，所以还是创建了一个远程仓库用于保存博客原始文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后改一下config.yml</span></span><br><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repository: git@github.com:outbreak-sen/outbreak-sen.github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure></li></ol><h2 id="使用butterfly主题">使用butterfly主题</h2><p>参考<a href="https://github.com/jerryc127/hexo-theme-butterfly">butterfly的github</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure><p><strong>修改配置文件 config.yml 中的 theme 项为 butterfly，之后也不要编辑config文件了，测试不好使，只编辑_configbutterfly.yml！！！！！</strong></p><p>然后就可以编辑config文件进行美化，这边对config文件进行了注释，然后方便改动</p><h2 id="目录说明">目录说明</h2><p>博客的文件目录和说明如下</p><ul><li>img： 作用未知，往里面存图片没有用啊</li><li>node_modules：nodejs的插件安装位置</li><li>public：编译好的网页将保存在此处，每次hexo clean的时候只更新这里</li><li>scaffolds：保存博客的不同layout，比如post，draft，page的layout，还有其他的layout比如categories，tags是默认的</li><li>source：博客<ul><li>_data：</li><li>_post：这里面是重要的博客单页，每个博客都有标题和兴趣tag，在生成的时候自动分类，不用自己分类到文件夹</li><li>_about：<a href="http://xn--pageindex-u75noo530lef1au11cboxeesg.md">这里就是一个page的index.md</a>，page的layout是&quot;about&quot;，里面是自己的介绍</li><li>archives：按照时间轴进行分类，<a href="http://xn--pageindex-u75noo530lef1au11cboxeesg.md">这里就是一个page的index.md</a>，page的layout是&quot;archives&quot;，不用管，有这个就可以看到分类页</li><li>categories：按照分类进行分类，<a href="http://xn--pageindex-u75noo530lef1au11cboxeesg.md">这里就是一个page的index.md</a>，page的layout是&quot;categories&quot;</li><li>tags：按照兴趣进行分类，<a href="http://xn--pageindex-u75noo530lef1au11cboxeesg.md">这里就是一个page的index.md</a>，page的layout是&quot;tags&quot;</li><li>shuoshuo：需要创建一个对应名称为shuoshuo的tag，然后就可以在此处看到</li><li><strong>这里的每个文件夹本身是不编译的，但是如果在config文件中编写同名目录则网页出现对应目录链接，<a href="http://xn--index-bi1hm7qypbha324cpt1bp2kr5hc03bssb98rxpmda52r3v7rhnrau0z3nx.md">然后点击进链接首先出现的是该目录下的index.md</a>。如果要创建一个图库，则index里编写图如何摆放即可，如果创建一个tegs分类，则index里把type改为tags则自动进入一个按照tag分类的界面。关于笔者，即about页面，其实也是一个page，然后设置好layout为about</strong></li></ul></li><li>themes：<ul><li>butterfly：里面的img目录为主页，人像等配置的默认目录</li></ul></li></ul><h3 id="图片修改">图片修改</h3><p>图片在<code>/themes/butterfly/source/img</code>更改，如果想要纯透明的，可以用png格式的图片,将jpg格式的图片转换为png格式的图片，然后在图片编辑软件中将透明度调成0.0~0.9之间，然后保存为png格式的图片。</p><h3 id="如何优雅插入博客图片">如何优雅插入博客图片</h3><p>有两类图需要插入，一种是博客搭建使用的图片，比如个人头像，背景图像等，另一种是博客中需要插入的图。</p><p>对于第一种，可以创建一个img目录直接插入图像，知否不会改动。或者直接插入到/themes/butterfly/source/img这个目录下，这样编写的路径比较好看但是因为这样插入的是theme文件夹，破坏了原先的主题文件夹，所以我不喜欢。（站点根目录是站点目录的source文件夹里）</p><p>对于第二种，优雅的方法是为每一个文章创建一个资源文件夹，将图片保存其中</p><ul><li>在博客根目录打开<code>_config.yml</code>文件做如下修改： <code>yaml post_asset_folder: true</code></li><li>然后使用<code>hexo n text</code>命令后创建一个使用post布局名为text的文章，你将发现hexo在<code>\source\_post</code>文件夹下创建了一个<code>\text</code>文件夹以及同名的<code>.md</code>文件：</li><li>使用<a href="https://link.zhihu.com/?target=https%3A//www.typora.io/">Typora</a>编辑器，可以在编辑器的文件/偏好设置/图像中进行如下设置：插入图片时：选择复制到制定路径：./${filename}/</li></ul><h3 id="目录和类型">目录和类型</h3><p>每个博客有两个属性，tag指的是内容涉及的话题，categories是指post的分类</p><ul><li><p>博客顶部的Front-matter是保存文章信息的地方，里面写明了文章创建的时间，标签，名字，也可以加入，分类，更改日期，评论系统是否开启等</p></li><li><p>在scaffolds目录下有多个layout文件，<a href="http://xn--draft-dq1hn287awd6a.md">默认为draft.md</a>， <a href="http://page.md">page.md</a>，post.md三个，对应创建博客时候的layout，也对应每个创建的md博客顶部的layout。</p><ul><li><p>所谓page，就是点击一个单页，比如点击categories的时候出现的index.md就是一个page，点击图库出现的收藏了一堆图片的单页就是page</p></li><li><p>使用 <code>draft</code> 布局建立的文章，其博客文章 <code>md</code> 源码位于 <code>source/_drafts</code> 路径下， <code>hexo generate</code> 不会将其编译到 <code>public</code> 目录下，所以 <code>hexo deploy</code> 也不会将其部署发布到博客网站上。Hexo提供了一个预览的方法，就是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo s --draft</span><br><span class="line">hexo publish aaa <span class="comment">#将aaa.md的草稿发布为博客，其中aaa是文章名，不包含.md后缀，该命令的原理也不过是将文章从/source/_drafts移动到/source/_posts而已</span></span><br></pre></td></tr></table></figure></li></ul></li><li><pre><code class="language-yml"># 目录图案menu:  主页: / || fas fa-home  博文 || fa fa-graduation-cap:    分类: /categories/ || fa fa-archive    时间轴: /archives/ || fa fa-folder-open  生活 || fas fa-list:    学习笔记: /shuoshuo/ || fa fa-comments-o    相册: /photos/ || fa fa-camera-retro    影视鉴赏: /movies/ || fas fa-video  关于笔者: /about/ || fas fa-heart# 菜单项后面的 fas fa-home、fa fa-graduation-cap 等是 Font Awesome 图标 的类名，用于在菜单项旁边显示对应的图标。https://fontawesome.com/icons# 在 Butterfly 主题的 _config.yml 中，确保以下配置为 true# fas fa-home：表示一个“家”图标，通常用于“主页”菜单项。# fa fa-graduation-cap：表示一个“毕业帽”图标，通常用于“博文”或“文章”相关的菜单项。# fas fa-list：表示一个“列表”图标，通常用于“生活”或“分类”菜单项。# fas fa-heart：表示一个“心形”图标，通常用于“关于笔者”或“喜欢”菜单项。# fas：表示 Solid 风格（实心图标）。# far：表示 Regular 风格（空心图标）。# fab：表示 Brand 风格（品牌图标，如 GitHub、Twitter 等）。</code></pre></li><li><p>Front-matter示例如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: Hexo 博客配置指南</span><br><span class="line"><span class="built_in">date</span>: 2023-10-01 14:00:00</span><br><span class="line">tags:</span><br><span class="line">  - Hexo</span><br><span class="line">  - Butterfly</span><br><span class="line">categories:</span><br><span class="line">  - 技术</span><br><span class="line">cover: /img/hexo-cover.jpg</span><br><span class="line">top_img: /img/hexo-top.jpg</span><br><span class="line">description: 本文介绍了如何配置 Hexo 和 Butterfly 主题。</span><br><span class="line">---</span><br><span class="line"><span class="comment">## 引言</span></span><br><span class="line">Hexo 是一个快速、简洁且高效的博客框架...</span><br><span class="line"></span><br><span class="line"><span class="comment">## 正文</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></li></ul><h1>使用方法</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hexo new <span class="string">&quot;My New Post&quot;</span> <span class="comment">#创建一个post类型（layout默认为post）的md文档</span></span><br><span class="line">hexo new [layout_name] <span class="string">&quot;post&quot;</span> <span class="comment">#创建一个layout类型的md</span></span><br><span class="line">hexo server <span class="comment"># 启用本地测试部署</span></span><br><span class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server <span class="comment">#删除本地缓存并进行本地测试部署</span></span><br><span class="line">hexo generate <span class="comment">#生成静态文件</span></span><br><span class="line">hexo deploy <span class="comment">#部署到远端，过一会起作用</span></span><br></pre></td></tr></table></figure><h1>config文件的示例</h1><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">This</span> <span class="string">is</span> <span class="string">a</span> <span class="string">部落格</span> <span class="string">of</span> <span class="string">outbreak_sen</span></span><br><span class="line"><span class="attr">subtitle:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Typewriter Effect (开启打字效果)</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># loop (循環打字)</span></span><br><span class="line">  <span class="attr">loop:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># source調用第三方服務,如果没有弹出就等一会</span></span><br><span class="line">  <span class="comment"># source: false 關閉調用</span></span><br><span class="line">  <span class="comment"># source: 1  調用搏天api的隨機語錄（簡體）</span></span><br><span class="line">  <span class="comment"># source: 2  調用一言網的一句話（簡體）</span></span><br><span class="line">  <span class="comment"># source: 3  調用一句網（簡體）</span></span><br><span class="line">  <span class="comment"># source: 4  調用今日詩詞（簡體）</span></span><br><span class="line">  <span class="comment"># subtitle 會先顯示 source , 再顯示 sub 的內容</span></span><br><span class="line">  <span class="attr">source:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># 如果有英文逗号&#x27; , &#x27;,请使用转义字元 &amp;#44;</span></span><br><span class="line">  <span class="comment"># 如果有英文双引号&#x27; &quot; &#x27;,请使用转义字元 &amp;quot;</span></span><br><span class="line">  <span class="comment"># 开头不允許转义字元，如需要，请把整個句子用双引号包住</span></span><br><span class="line">  <span class="comment"># 如果关闭打字效果，subtitle只会现示sub的第一行文字</span></span><br><span class="line">  <span class="attr">sub:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">你在抱怨什么呢</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">为明天到来的事，说人生像是没有意义</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">没有选择会是唯一的路</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">这不是你自己的问题，人终归要好好去生活</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&quot;an interesting man&quot;</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">outbreak_sen</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署URL</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">http://outbreak-sen.github.io</span></span><br><span class="line"><span class="attr">permalink:</span> <span class="string">:year/:month/:day/:title/</span></span><br><span class="line"><span class="attr">permalink_defaults:</span></span><br><span class="line"><span class="attr">pretty_urls:</span></span><br><span class="line">  <span class="attr">trailing_index:</span> <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span></span><br><span class="line">  <span class="attr">trailing_html:</span> <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;.html&#x27; from permalinks</span></span><br><span class="line"><span class="comment"># 导航栏</span></span><br><span class="line"><span class="attr">nav:</span></span><br><span class="line">  <span class="comment"># 导航栏 Logo 图片</span></span><br><span class="line">  <span class="attr">logo:</span> <span class="string">/img/h_beautygirl.png</span></span><br><span class="line">  <span class="comment"># 是否显示标题</span></span><br><span class="line">  <span class="attr">display_title:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 是否固定导航栏</span></span><br><span class="line">  <span class="attr">fixed:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整侧边栏出现位置</span></span><br><span class="line"><span class="attr">aside:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hide:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">button:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">mobile:</span> <span class="literal">false</span> <span class="comment"># display on mobile</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">left</span> <span class="comment"># left or right</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 个人信息</span></span><br><span class="line"><span class="attr">social:</span></span><br><span class="line">  <span class="attr">fab fa-github:</span> <span class="string">https://github.com/outbreak-sen</span> <span class="string">||</span> <span class="string">Github</span></span><br><span class="line">  <span class="attr">fa fa-book-open:</span> <span class="string">https://blog.csdn.net/outbreakrmb</span> <span class="string">||</span> <span class="string">CSDN</span></span><br><span class="line">  <span class="attr">fab fa-qq:</span> <span class="number">1023786231</span> <span class="string">||</span> <span class="string">QQ</span></span><br><span class="line"><span class="comment"># 个人头像设置</span></span><br><span class="line"><span class="attr">avatar:</span></span><br><span class="line">  <span class="comment"># 头像图片链接</span></span><br><span class="line">  <span class="attr">img:</span> <span class="string">./img/head.png</span></span><br><span class="line">  <span class="comment"># 是否启用头像效果头像会一直转圈</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 目录</span></span><br><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">主页:</span> <span class="string">/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-home</span></span><br><span class="line">  <span class="string">博文</span> <span class="string">||</span> <span class="attr">fa fa-graduation-cap:</span></span><br><span class="line">    <span class="string">分类:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-archive</span></span><br><span class="line">    <span class="string">时间轴:</span> <span class="string">/archives/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-folder-open</span></span><br><span class="line">    <span class="string">标签:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-tags</span></span><br><span class="line">  <span class="string">生活</span> <span class="string">||</span> <span class="attr">fas fa-list:</span></span><br><span class="line">    <span class="string">树洞:</span> <span class="string">/shuoshuo/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-camera-retro</span></span><br><span class="line">    <span class="string">作品与鉴赏:</span> <span class="string">/movies/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-video</span></span><br><span class="line">  <span class="string">关于笔者:</span> <span class="string">/about/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-heart</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory</span></span><br><span class="line"><span class="attr">source_dir:</span> <span class="string">source</span></span><br><span class="line"><span class="attr">public_dir:</span> <span class="string">public</span></span><br><span class="line"><span class="attr">tag_dir:</span> <span class="string">tags</span></span><br><span class="line"><span class="attr">archive_dir:</span> <span class="string">archives</span></span><br><span class="line"><span class="attr">category_dir:</span> <span class="string">categories</span></span><br><span class="line"><span class="attr">code_dir:</span> <span class="string">downloads/code</span></span><br><span class="line"><span class="attr">i18n_dir:</span> <span class="string">:lang</span></span><br><span class="line"><span class="attr">skip_render:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码块</span></span><br><span class="line"><span class="attr">code_blocks:</span></span><br><span class="line">  <span class="comment"># 代码块主题: darker / pale night / light / ocean / false</span></span><br><span class="line">  <span class="attr">theme:</span> <span class="string">pale</span> <span class="string">night</span></span><br><span class="line">  <span class="comment"># 是否使用 Mac 风格</span></span><br><span class="line">  <span class="attr">macStyle:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 代码块高度限制（单位: px）</span></span><br><span class="line">  <span class="attr">height_limit:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 是否自动换行</span></span><br><span class="line">  <span class="attr">word_wrap:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 代码块工具栏</span></span><br><span class="line">  <span class="comment"># 是否显示复制按钮</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 是否显示语言标签</span></span><br><span class="line">  <span class="attr">language:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># true: 收缩代码块 | false: 展开代码块 | none: 展开代码块并隐藏按钮</span></span><br><span class="line">  <span class="attr">shrink:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 是否显示全屏显示代码块按钮</span></span><br><span class="line">  <span class="attr">fullpage:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制的内容后面加上版权信息</span></span><br><span class="line"><span class="attr">copy:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># 是否开启网站复制权限</span></span><br><span class="line">  <span class="attr">copyright:</span> <span class="comment"># 复制的内容后面加上版权信息</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">false</span> <span class="comment"># 是否开启复制版权信息添加</span></span><br><span class="line">    <span class="attr">limit_count:</span> <span class="number">50</span> <span class="comment"># 字数限制，当复制文字大于这个字数限制时</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 相关文章，在文章最下面出现推送</span></span><br><span class="line"><span class="attr">related_post:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">limit:</span> <span class="number">6</span> <span class="comment"># Number of posts displayed</span></span><br><span class="line">  <span class="attr">date_type:</span> <span class="string">created</span> <span class="comment"># or created or updated 文章日期顯示創建日或者更新日</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 各种图片</span></span><br><span class="line"><span class="comment"># 图片格式: url(http://xxxxxx.com/xxx.jpg)</span></span><br><span class="line"><span class="comment"># Favicon（网站图）</span></span><br><span class="line"><span class="attr">favicon:</span> <span class="string">/img/h_beautygirl.png</span></span><br><span class="line"><span class="comment"># 禁用所有横幅图片</span></span><br><span class="line"><span class="attr">disable_top_img:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 创建博客单页的时候是否创建一个同名文件夹用于存放图片</span></span><br><span class="line"><span class="attr">yaml post_asset_folder:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># 当没有在front-matter设置top_img和cover的情况下会显示该图，要不然就是每个文章制定的图</span></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"><span class="comment"># title: Hello World        # 标题</span></span><br><span class="line"><span class="comment"># tags: [hello]             # 标签</span></span><br><span class="line"><span class="comment"># categories:               # 分类</span></span><br><span class="line"><span class="comment"># description: hello word~  # 描述</span></span><br><span class="line"><span class="comment"># top_img: /img/hello-1.png # 顶部背景图</span></span><br><span class="line"><span class="comment"># cover: /img/hello-1.png   # 文章封面</span></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"><span class="comment"># 文章详情页的顶部图片</span></span><br><span class="line"><span class="attr">default_top_img:</span> <span class="string">/img/h_beautygirl.png</span></span><br><span class="line"><span class="comment"># 主页封面</span></span><br><span class="line"><span class="attr">index_img:</span> <span class="string">/img/h_beautygirl.png</span></span><br><span class="line"><span class="comment"># 归档页顶部图片</span></span><br><span class="line"><span class="attr">archive_img:</span> <span class="string">/img/h_beautygirl.png</span></span><br><span class="line"><span class="comment"># 标签页顶部图</span></span><br><span class="line"><span class="attr">tag_img:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">这也是一个测试:</span> <span class="string">/img/head.png</span></span><br><span class="line"><span class="comment"># 为每个标签设置横幅图片</span></span><br><span class="line"><span class="comment"># 格式:</span></span><br><span class="line"><span class="comment">#  - 标签名: 图片链接</span></span><br><span class="line"><span class="attr">tag_per_img:</span></span><br><span class="line"><span class="comment"># category页顶部图</span></span><br><span class="line"><span class="attr">category_img:</span></span><br><span class="line"><span class="comment"># 分类页的横幅图片，可以为每个分类设置横幅图片</span></span><br><span class="line"><span class="comment"># 格式:</span></span><br><span class="line"><span class="comment">#  - 分类名: 图片链接</span></span><br><span class="line"><span class="attr">category_per_img:</span></span><br><span class="line"><span class="comment"># 页脚的背景图片</span></span><br><span class="line"><span class="attr">footer_img:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># 网站背景</span></span><br><span class="line"><span class="attr">background:</span> <span class="string">/img/v_beautygirl0.jpeg</span></span><br><span class="line"><span class="comment"># 无法显示的图</span></span><br><span class="line"><span class="attr">error_img:</span></span><br><span class="line">  <span class="attr">flink:</span> <span class="string">./img/friend_404.gif</span></span><br><span class="line">  <span class="attr">post_page:</span> <span class="string">/img/404.jpg</span></span><br><span class="line"><span class="comment"># 图片没加载出来的时候，出现一个动图转转转的文章页样式</span></span><br><span class="line"><span class="attr">lazyload:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">loadingImg:</span> <span class="string">/img/s_beautygirl0.jpeg</span></span><br><span class="line"><span class="comment"># 图片大图查看</span></span><br><span class="line"><span class="attr">medium_zoom:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">fancybox:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># 简单的 404 页面</span></span><br><span class="line"><span class="attr">error_404:</span></span><br><span class="line">  <span class="comment"># 是否启用 404 页面</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 404 页面的副标题</span></span><br><span class="line">  <span class="attr">subtitle:</span> <span class="string">&quot;Page Not Found&quot;</span></span><br><span class="line">  <span class="comment"># 404 页面的卡片背景图片</span></span><br><span class="line">  <span class="attr">background:</span> <span class="string">https://i.loli.net/2020/05/19/aKOcLiyPl2JQdFD.png</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 给文章结尾设置打赏按钮，可以放上收款二维码</span></span><br><span class="line"><span class="attr">reward:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">QR_code:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">img:</span> <span class="string">/img/wechat.jpg</span></span><br><span class="line">      <span class="attr">link:</span></span><br><span class="line">      <span class="attr">text:</span> <span class="string">微信</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">img:</span> <span class="string">/img/alipay.jpg</span></span><br><span class="line">      <span class="attr">link:</span></span><br><span class="line">      <span class="attr">text:</span> <span class="string">支付宝</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># toc 目录</span></span><br><span class="line"><span class="attr">toc:</span></span><br><span class="line">  <span class="attr">post:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">page:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">number:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">expand:</span> <span class="literal">true</span> <span class="comment"># 是否展开</span></span><br><span class="line">  <span class="attr">style_simple:</span> <span class="literal">false</span> <span class="comment"># for post</span></span><br><span class="line">  <span class="attr">scroll_percent:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Typewriter Effect (打字效果)</span></span><br><span class="line"><span class="comment"># https://github.com/disjukr/activate-power-mode</span></span><br><span class="line"><span class="attr">activate_power_mode:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">colorful:</span> <span class="literal">true</span> <span class="comment"># open particle animation (冒光特效)</span></span><br><span class="line">  <span class="attr">shake:</span> <span class="literal">true</span> <span class="comment">#  open shake (抖动特效)</span></span><br><span class="line">  <span class="attr">mobile:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Mouse click effects: fireworks (鼠标点击效果:萤火特效)</span></span><br><span class="line"><span class="attr">fireworks:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">zIndex:</span> <span class="number">9999</span> <span class="comment"># -1 or 9999</span></span><br><span class="line">  <span class="attr">mobile:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Mouse click effects: Heart symbol (鼠标点击效果: 爱心)</span></span><br><span class="line"><span class="attr">click_heart:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">mobile:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Writing</span></span><br><span class="line"><span class="attr">new_post_name:</span> <span class="string">:title.md</span> <span class="comment"># File name of new posts</span></span><br><span class="line"><span class="attr">default_layout:</span> <span class="string">post</span></span><br><span class="line"><span class="attr">titlecase:</span> <span class="literal">false</span> <span class="comment"># Transform title into titlecase</span></span><br><span class="line"><span class="attr">external_link:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># Open external links in new tab</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">site</span> <span class="comment"># Apply to the whole site</span></span><br><span class="line">  <span class="attr">exclude:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="attr">filename_case:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">render_drafts:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">relative_link:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">future:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">syntax_highlighter:</span> <span class="string">highlight.js</span></span><br><span class="line"><span class="attr">highlight:</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">auto_detect:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hljs:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">prismjs:</span></span><br><span class="line">  <span class="attr">preprocess:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Home page setting</span></span><br><span class="line"><span class="comment"># path: Root path for your blogs index page. (default = &#x27;&#x27;)</span></span><br><span class="line"><span class="comment"># per_page: Posts displayed per page. (0 = disable pagination)</span></span><br><span class="line"><span class="comment"># order_by: Posts order. (Order by date descending by default)</span></span><br><span class="line"><span class="attr">index_generator:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">order_by:</span> <span class="string">-date</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Category &amp; Tag</span></span><br><span class="line"><span class="attr">default_category:</span> <span class="string">uncategorized</span></span><br><span class="line"><span class="attr">category_map:</span></span><br><span class="line"><span class="attr">tag_map:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Metadata elements</span></span><br><span class="line"><span class="comment">## https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta</span></span><br><span class="line"><span class="attr">meta_generator:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Date / Time format</span></span><br><span class="line"><span class="comment">## Hexo uses Moment.js to parse and display date</span></span><br><span class="line"><span class="comment">## You can customize the date format as defined in</span></span><br><span class="line"><span class="comment">## http://momentjs.com/docs/#/displaying/format/</span></span><br><span class="line"><span class="attr">date_format:</span> <span class="string">YYYY-MM-DD</span></span><br><span class="line"><span class="attr">time_format:</span> <span class="string">HH:mm:ss</span></span><br><span class="line"><span class="comment">## updated_option supports &#x27;mtime&#x27;, &#x27;date&#x27;, &#x27;empty&#x27;</span></span><br><span class="line"><span class="attr">updated_option:</span> <span class="string">&quot;mtime&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pagination</span></span><br><span class="line"><span class="comment">## Set per_page to 0 to disable pagination</span></span><br><span class="line"><span class="attr">per_page:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">pagination_dir:</span> <span class="string">page</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Include / Exclude file(s)</span></span><br><span class="line"><span class="comment">## include:/exclude: options only apply to the &#x27;source/&#x27; folder</span></span><br><span class="line"><span class="attr">theme:</span> <span class="string">butterfly</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:outbreak-sen/outbreak-sen.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1>使用其他域名</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;我的博客搭建过程和使用&lt;/h1&gt;
&lt;h1&gt;搭建过程&lt;/h1&gt;
&lt;h2 id=&quot;基础hexo搭建方法&quot;&gt;基础Hexo搭建方法&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装 Node.js与git&lt;/p&gt;
&lt;p&gt;Node.js 是一个开源的、跨平台的 JavaScript 运行环</summary>
      
    
    
    
    <category term="配置环境" scheme="http://outbreak-sen.github.io/categories/%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
    
    
    <category term="Hexo" scheme="http://outbreak-sen.github.io/tags/Hexo/"/>
    
    <category term="Hexo-butterfly" scheme="http://outbreak-sen.github.io/tags/Hexo-butterfly/"/>
    
    <category term="nodejs" scheme="http://outbreak-sen.github.io/tags/nodejs/"/>
    
  </entry>
  
  <entry>
    <title>QT的不同开发方式</title>
    <link href="http://outbreak-sen.github.io/2025/02/09/QT%E7%9A%84%E4%B8%8D%E5%90%8C%E5%BC%80%E5%8F%91%E6%96%B9%E5%BC%8F/"/>
    <id>http://outbreak-sen.github.io/2025/02/09/QT%E7%9A%84%E4%B8%8D%E5%90%8C%E5%BC%80%E5%8F%91%E6%96%B9%E5%BC%8F/</id>
    <published>2025-02-09T07:17:22.000Z</published>
    <updated>2025-02-09T08:44:22.655Z</updated>
    
    <content type="html"><![CDATA[<h1>QT 的不同开发方式</h1><p>[TOC]</p><h1>QT的简要介绍</h1><ul><li><p>用类套壳的UI库，同时还提供了一些IDE，UI编辑工具等。</p></li><li><p>同时QT的库中还有3D，图像处理，SQL数据库，音频处理，多线程等多个库，可以替代opencv，opengl做一些开发。</p></li><li><p>可以开发多个平台的软件，同时可以实现在一个平台开发后可以用于其他平台，平台包括安卓，嵌入式，桌面开发</p></li></ul><h1>QT Creator-QT提供的IDE</h1><p>Qt Creator 是 Qt 官方提供的集成开发环境（IDE），支持多种开发方式。</p><ul><li><strong>多语言支持</strong>：支持 C++、QML、Python 等语言。</li><li><strong>集成工具</strong>：包含代码编辑器、调试器、UI 设计器、版本控制等功能。</li><li><strong>跨平台</strong>：支持 Windows、Linux、macOS。</li></ul><h1>QT Designer-QT提供的UI编辑器</h1><p>Qt Designer 是一个可视化工具，用于设计 Qt 应用程序的用户界面。它生成 <code>.ui</code> 文件，可以与 C++、Python 等语言结合使用。</p><ul><li><strong>拖拽式设计</strong>：通过拖拽控件快速构建 UI。</li><li><strong>生成 <code>.ui</code> 文件</strong>：<code>.ui</code> 文件是 XML 格式的界面描述文件，可以在代码中动态加载。</li><li><strong>与代码结合</strong>：通过 <code>uic</code> 工具将 <code>.ui</code> 文件转换为 C++ 或 Python 代码。</li></ul><h1>C++开发方式</h1><p>Qt 最传统和强大的开发方式，使用 C++ 语言直接调用 Qt 的 API。</p><p>开发工具可以使用如下：</p><ul><li><strong>Qt Creator</strong>（最好的方法）：Qt 官方提供的集成开发环境（IDE），支持代码编辑、调试、UI 设计等功能。</li><li><strong>Qt Designer</strong>：用于设计 GUI 界面，生成 <code>.ui</code> 文件，可以与 C++ 代码结合使用，用Designer生成ui文件之后使用其他C++的IDE调用ui中的每个模块编写功能实现，最后合到一起。</li></ul><h1>Python开发方式</h1><h2 id="pyqt">Pyqt</h2><p>提供了完整的 Qt 模块支持。</p><p>pyQT的安装不需要在官网下载QT安装包，只需要创建conda环境然后pip安装，安装pyQT5-tools之后会安装QT designer，然后就可以可视化设计一个UI，然后通过Pyuic工具就可以转化为一个py文件，这个py文件就是整个工程，py文件中有一个class包含了整个UI设计，然后只需要编辑py文件中这个class的功能即可，编辑子函数。</p><p>开发工具可以使用如下：</p><ul><li><strong>Qt Designer</strong>：用于设计 UI，生成 <code>.ui</code> 文件，可以通过 PyQt 或 PySide 加载。</li><li><strong>Qt Creator</strong>：支持 Python 项目的开发。</li><li><strong>第三方 IDE</strong>：如 PyCharm、VS Code 等。</li></ul><h2 id="pyside">PySide</h2><p>与 PyQt 类似，但 API 更接近原生 Qt。</p><h1>QML（Qt Meta-Object Language）</h1><p>QML 是一种声明式语言，用于设计用户界面，与 JavaScript 结合使用，适合开发现代化的、动态的 UI。为了适应手机移动应用开发， Qt5 将 QML 脚本编程提到与传统 C++ 部件编程相同的高度，力推 QML 界面编程，当然 QML 主要用于手机移动应用程序。 QML 包含大量使用手机移动设备的功能模块，比如基本部件（QtQuick 模块）、GPS 定位、渲染特效、蓝牙、NFC、WebkKit 等等。<br>QML 类似于网页设计的 HTML，是一种标记语言，我们可以借助 CSS 对它进行美化，也可以借助 <a href="http://c.biancheng.net/js/">JavaScript</a> 进行交互。有 Web 开发经验的读者学习 QML 将非常轻松。</p><p>以下两个特点很重要</p><ul><li><p>与 C++ 结合：QML 可以与 C++ 后端逻辑结合，实现复杂的业务逻辑。</p></li><li><p>动画和特效：QML 内置了对动画和特效的支持，适合开发动态界面。可以实现富动画和特效的应用程序。</p></li><li><p>适用移动应用程序（如 Android、iOS）</p></li></ul><p>开发工具可以使用如下：</p><ul><li><strong>Qt Creator</strong>（最好的方法）：Qt 官方提供的集成开发环境（IDE），支持代码编辑、调试、UI 设计等功能。</li><li><strong>Qt Quick Designer</strong>：用于设计 QML 界面。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;QT 的不同开发方式&lt;/h1&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1&gt;QT的简要介绍&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用类套壳的UI库，同时还提供了一些IDE，UI编辑工具等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同时QT的库中还有3D，图像处理，SQL数据库，音频处理，</summary>
      
    
    
    
    <category term="配置环境" scheme="http://outbreak-sen.github.io/categories/%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/"/>
    
    
    <category term="QT" scheme="http://outbreak-sen.github.io/tags/QT/"/>
    
    <category term="shell" scheme="http://outbreak-sen.github.io/tags/shell/"/>
    
  </entry>
  
</feed>
